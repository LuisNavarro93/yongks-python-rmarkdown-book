[
["index.html", "Python Bookdown Prerequisites", " Python Bookdown Yong Keh Soon 2019-12-22 Prerequisites "],
["environment-setup.html", "1 Environment Setup 1.1 Notebook Setup 1.2 Libraries 1.3 Magic Functions 1.4 Package Management", " 1 Environment Setup 1.1 Notebook Setup 1.2 Libraries 1.2.1 Built-In Libraries import string import datetime as dt 1.2.2 Common External Libraries import numpy as np import pandas as pd import datetime as dt import matplotlib import matplotlib.pyplot as plt from plydata import define, query, select, group_by, summarize, arrange, head, rename import plotnine from plotnine import * 1.2.3 numpy large multi-dimensional array and matrices High level mathematical funcitons to operate on them Efficient array computation, modeled after matlab Support vectorized array math functions (built on C, hence faster than python for loop and list) 1.2.4 scipy Collection of mathematical algorithms and convenience functions built on the numpy extension Built uponi numpy 1.2.5 Pandas Data manipulation and analysis Offer data structures and operations for manipulating numerical tables and time series Good for analyzing tabular data Use for exploratory data analysis, data pre-processing, statistics and visualization Built upon numpy 1.2.6 scikit-learn Machine learning functions Built on top of scipy 1.2.7 matplotlib Data Visualization 1.3 Magic Functions IPython has a set of predefined ?magic functions? that you can call with a command line style syntax There are two types of magics: Line Magic : prefix with % Work much like OS command-line calls: they get as an argument the rest of the line, where arguments are passed without parentheses or quotes. Lines magics can return results and can be used in the right hand side of an assignment Cell Magic : prefix with %% They are functions that get as an argument not only the rest of the line, but also the lines below it in a separate argument. 1.3.1 List of Magic #%lsmagic 1.3.2 Line Magic Execute magic on each line 1.3.2.1 %timeit Run the line for default 7 times (use -r to specify) Each run has default 100,000,000 loops (use -n to specify) #%timeit -r 2 -n 100 3+1000/0.25*100 1.3.2.2 %matplotlib Output graph inline to frontend (Jupyter Notebook). Therefore is stored in the Notebook document #%matplotlib inline 1.3.2.3 %who Analyse variables of global scope Specify optional type to filter the variables a = 1 type(a) &lt;class ‘int’&gt; #%who int #%who 1.3.3 Cell Magic Execute magic on the entire cell 1.3.3.1 %%timeit Run the line for default 7 times (use -r to specify) Each run has default 100,000,000 loops (use -n to specify) #%%timeit -r 1 -n 10 import time for _ in range(100): time.sleep(0.01)# sleep for 0.01 seconds 1.4 Package Management 1.4.1 Conda 1.4.1.1 Conda Environment #!conda info 1.4.1.2 Package Version system(&quot;conda list&quot;) 1.4.1.3 Package Installation Conda is recommended distribution. To install from official conda channel: conda install &lt;package_name&gt; # always install latest conda install &lt;package_name=version_number&gt; # Example: Install From conda official channel conda install numpy conda install scipy conda install pandas conda install matpotlib conda install scikit-learn conda install seaborn conda install pip To install from conda-forge community channel: conda install -c conda-forge &lt;package_name&gt; conda install -c conda-forge &lt;package_name=version_number&gt; # Example: Install From conda community: conda install -c conda-forge plotnine 1.4.2 PIP PIP is python open repository (not part of conda). Use pip if the package is not available in conda. 1.4.2.1 Package Version #!pip list 1.4.2.2 Package Installation pip install &lt;package_name&gt; pip install plydata "],
["python-fundamental.html", "2 Python Fundamental 2.1 Everything Is Object 2.2 Assignment", " 2 Python Fundamental 2.1 Everything Is Object Every varibales in python are objects Every variable assginment is reference based, that is, each object value is the reference to memory block of data In the below exmaple, a, b and c refer to the same memory location: - Notice when an object assigned to another object, they refer to the same memory location - When two variable refers to the same value, they refer to the same memory location a = 123 b = 123 c = a print (&#39;Data of a =&#39;, a, &#39;\\nData of b =&#39;,b, &#39;\\nData of c =&#39;,c, &#39;\\nID of a = &#39;, id(a), &#39;\\nID of b = &#39;, id(b), &#39;\\nID of c = &#39;, id(c) ) Data of a = 123 Data of b = 123 Data of c = 123 ID of a = 140734447398240 ID of b = 140734447398240 ID of c = 140734447398240 Changing data value (using assignment) changes the reference a = 123 b = a a = 456 # reassignemnt changed a memory reference # b memory reference not changed print (&#39;Data of a =&#39;,a, &#39;\\nData of b =&#39;,b, &#39;\\nID of a = &#39;, id(a), &#39;\\nID of b = &#39;, id(b) ) Data of a = 456 Data of b = 123 ID of a = 670149744 ID of b = 140734447398240 2.2 Assignment 2.2.1 Multiple Assignment Assign multiple variable at the same time with same value. Note that all object created using this method refer to the same memory location. x = y = &#39;same mem loc&#39; print (&#39;x = &#39;, x, &#39;\\ny = &#39;, y, &#39;\\nid(x) = &#39;, id(x), &#39;\\nid(y) = &#39;, id(y) ) x = same mem loc y = same mem loc id(x) = 670336240 id(y) = 670336240 2.2.2 Augmented Assignment x = 1 y = x + 1 y += 1 print (&#39;y = &#39;, y) y = 3 2.2.3 Unpacking Assingment Assign multiple value to multiple variabels at the same time. x,y = 1,3 print (x,y) 1 3 "],
["built-in-data-types.html", "3 Built-in Data Types 3.1 Numbers 3.2 String 3.3 Boolean 3.4 None", " 3 Built-in Data Types 3.1 Numbers Two types of built-in number type, integer and float. 3.1.1 Integer n = 123 type (n) &lt;class ‘int’&gt; 3.1.2 Float f = 123.4 type (f) &lt;class ‘float’&gt; 3.1.3 Number Operators In general, when the operation potentially return float, the result is float type. Otherwise it return integer. Division always return float print(4/2) # return float 2.0 type(4/2) &lt;class ‘float’&gt; Integer Division by integer return inter. Integer division by float return float. print (8//3,&#39;\\n&#39;, # return int 8//3.2) # return float 2 2.0 Remainder by integer return integer. Remainder by float return float print (8%3, &#39;\\n&#39;, # return int 8%3.2) # return float 2 1.5999999999999996 Power return int or float print (2**3) # return int 8 print (2.1**3) # return float 9.261000000000001 print (2**3.1) # return float 8.574187700290345 3.2 String String is an object class ‘str’. It is an ordered collection of letters, an array of object type str import string s = &#39;abcde&#39; print( &#39;\\nvar type = &#39;, type(s), &#39;\\nelems = &#39;,s[0], s[1], s[2], &#39;\\nlen = &#39;, len(s), &#39;\\nelem type = &#39;,type(s[1])) var type = &lt;class ‘str’&gt; elems = a b c len = 5 elem type = &lt;class ‘str’&gt; 3.2.1 Constructor 3.2.1.1 Classical Method class str(object='') my_string = str() ## empty string class str(object=b'', encoding='utf-8', errors='strict') my_string = str(&#39;abc&#39;) 3.2.1.2 Shortcut Method my_string = &#39;abc&#39; 3.2.1.3 Multiline Method my_string = &#39;&#39;&#39; This is me. Yong Keh Soon &#39;&#39;&#39; print(my_string) This is me. Yong Keh Soon Note that the variable contain \\n front and end of the string. my_string ‘is me.Keh Soon’ 3.2.1.4 Immutability String is immuatable. Changing its content will result in error s = &#39;abcde&#39; print (&#39;s : &#39;, id(s)) #s[1] = &#39;z&#39; # immutable, result in error s : 670382320 Changing the variable completley change the reference (for new object) s = &#39;efgh&#39; print (&#39;s : &#39;, id(s)) s : 670365320 3.2.2 Class Constants 3.2.2.1 Letters print( &#39;letters = &#39;, string.ascii_letters, &#39;\\nlowercase = &#39;,string.ascii_lowercase, &#39;\\nuppercase = &#39;,string.ascii_uppercase ) letters = abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ lowercase = abcdefghijklmnopqrstuvwxyz uppercase = ABCDEFGHIJKLMNOPQRSTUVWXYZ 3.2.2.2 Digits string.digits ‘0123456789’ 3.2.2.3 White Spaces string.whitespace ’ 0b0c’ 3.2.3 Instance Methods 3.2.3.1 Substitution : format() By Positional print( &#39;{} + {} = {}&#39;.format(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;), # auto sequence &#39;\\n{0} + {1} = {2}&#39;.format(&#39;aa&#39;, &#39;bb&#39;, &#39;cc&#39;)) # manual sequence a + b = c aa + bb = cc By Name &#39;Coordinates: {latitude}, {longitude}&#39;.format(latitude=&#39;37.24N&#39;, longitude=&#39;-115.81W&#39;) ## constant ‘Coordinates: 37.24N, -115.81W’ By Dictionary Name coord = {&#39;latitude&#39;: &#39;37.24N&#39;, &#39;longitude&#39;: &#39;-115.81W&#39;} ## dictionary key/value &#39;Coordinates: {latitude}, {longitude}&#39;.format(**coord) ‘Coordinates: 37.24N, -115.81W’ Formatting Number Float &#39;{:+f}; {:+f}&#39;.format(3.14, -3.14) # show it always ‘+3.140000; -3.140000’ &#39;{: f}; {: f}&#39;.format(3.14, -3.14) # show a space for positive numbers ’ 3.140000; -3.140000’ &#39;Correct answers: {:.2f}&#39;.format(55676.345345) ‘Correct answers: 55676.35’ Integer, Percentage &#39;{0:,} {0:.2%} {0:,.2%}&#39;.format(1234567890.4455) ‘1,234,567,890.4455 123456789044.55% 123,456,789,044.55%’ Alignment &#39;{0:&lt;20} {0:&lt;&lt;20}&#39;.format(&#39;left aligned&#39;) ‘left aligned left aligned&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;’ &#39;{0:&gt;20} {0:$&gt;20}&#39;.format(&#39;right aligned&#39;) ’ right aligned $$$$$$$right aligned’ &#39;{:^30}&#39;.format(&#39;centered&#39;) # use &#39;*&#39; as a fill char ’ centered ’ 3.2.3.2 Substitution : f-string my_name = &#39;Yong Keh Soon&#39; salary = 11123.346 f&#39;Hello, {my_name}, your salary is {salary:,.2f} !&#39; ‘Hello, Yong Keh Soon, your salary is 11,123.35 !’ 3.2.3.3 Conversion: upper() lower() &#39;myEXEel.xls&#39;.upper() ‘MYEXEEL.XLS’ &#39;myEXEel.xls&#39;.lower() ‘myexeel.xls’ 3.2.3.4 find() pattern position string.find() return position of first occurance. -1 if not found s=&#39;I love karaoke, I know you love it oo&#39; print (s.find(&#39;lov&#39;)) 2 print (s.find(&#39;kemuning&#39;)) -1 3.2.3.5 strip() off blank spaces filename = &#39; myexce l. xls &#39; filename.strip() ‘myexce l. xls’ 3.2.3.6 List Related: split() Splitting delimeter is specified. Observe the empty spaces were conserved in result array animals = &#39;a1,a2 ,a3, a4&#39; animals.split(&#39;,&#39;) [‘a1’, ‘a2’, ‘a3’, ’ a4’] 3.2.3.7 List Related: join() &#39;-&#39;.join([&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;]) ‘1-2-3-4’ 3.2.4 Operator 3.2.4.1 % Old Style Substitution https://docs.python.org/3/library/stdtypes.html#old-string-formatting my_name = &#39;Yong Keh Soon&#39; salary = 11123.346 &#39;Hello, %s, your salary is %.2f !&#39; %(my_name, salary) ‘Hello, Yong Keh Soon, your salary is 11123.35 !’ 3.2.4.2 + Concatenation &#39;this is &#39; + &#39;awesome&#39; ‘this is awesome’ 3.2.4.3 in matching For single string, partial match print( &#39;abc&#39; in &#39;123abcdefg&#39; ) True For list of strings, exact match (even though only one element in list). For partial match, workaround is to convert list to single string print( &#39;abc&#39; in [&#39;abcdefg&#39;], # false &#39;abc&#39; in [&#39;abcdefg&#39;,&#39;123&#39;], # fakse &#39;abc&#39; in [&#39;123&#39;,&#39;abc&#39;,&#39;def&#39;], # true &#39;abc&#39; in str([&#39;123&#39;,&#39;abcdefg&#39;])) # true False False True True 3.2.4.4 Comparitor Comparitor compares the memory address. a=&#39;abc&#39; b=&#39;abc&#39; print(&#39;id(a) = &#39;, id(a), &#39;\\nid(b) = &#39;, id(b), &#39;\\na == b &#39;, a==b) id(a) = 403372216 id(b) = 403372216 a == b True 3.2.5 Iterations string[start:end:step] # default start:0, end:last, step:1 If step is negative (reverse), end value must be lower than start value s = &#39;abcdefghijk&#39; print (s[0]) # first later a print (s[:3]) # first 3 letters abc print (s[2:8 :2]) # stepping ceg print (s[-1]) # last letter k print (s[-3:]) # last three letters ijk print (s[: :-1]) # reverse everything kjihgfedcba print (s[8:2 :-1]) ihgfed print (s[8:2]) # return NOTHING 3.3 Boolean b = False if (b): print (&#39;It is true&#39;) else: print (&#39;It is fake&#39;) It is fake 3.3.1 What is Considered False ? Everything below are false, anything else are true print ( bool(0), # zero bool(None), # none bool(&#39;&#39;), # empty string bool([]), # empty list bool(()), # empty tupple bool(False), # False bool(2-2)) # expression that return any value above False False False False False False False 3.3.2 and operator BEWARE ! and can return different data types If evaluated result is True, the last True Value is returned (because python need to evaluate up to the last value) If evaluated result is False, the first False Value will be returned (because python return it immediately when detecting False value) print (123 and 2 and 1, 123 and [] and 2) 1 [] 3.3.3 not operator not (True) False not (True or False) False not (False) True not (True and False) True ~(False) -1 3.3.4 or operator or can return different data type If evaluated result is True, first True Value will be returned (right hand side value need not be evaluated) If evaluated result is False, last Fasle Value will be returned (need to evalute all items before concluding False) print (1 or 2) 1 print (0 or 1 or 1) 1 print (0 or () or []) [] 3.4 None 3.4.1 None is an Object None is a Python object NonType Any operation to None object will result in error For array data with None elements, verification is required to check through iteration to determine if the item is not None. It is very computaionaly heavy type(None) &lt;class ‘NoneType’&gt; t = np.array([1,2,3,4,5]) t.dtype # its an integer dtype(‘int32’) t1 = np.array([1, 2, 3, 4, 5]) t = np.array([1, 2, 3, None, 4, 5]) t.dtype # it&#39;s an object dtype(‘O’) t1.dtype dtype(‘int32’) 3.4.2 Comparing None Not Prefered Method null_variable = None print( null_variable == None ) True Prefered print( null_variable is None ) True print( null_variable is not None ) False "],
["built-in-data-structure.html", "4 Built-In Data Structure 4.1 Tuple 4.2 List 4.3 Dictionaries 4.4 Sets 4.5 range", " 4 Built-In Data Structure 4.1 Tuple Tuple is an immutable list. Any attempt to change/update tuple will return error. It can contain different types of object. Benefits of tuple against List are: - Faster than list - Protects your data against accidental change - Can be used as key in dictionaries, list can’t 4.1.1 Assignment 4.1.1.1 (item1, item2, item3) This is a formal syntax for defining tuple, items inside ( ) notation t = (1,2,3,&#39;o&#39;,&#39;apple&#39;) t (1, 2, 3, ‘o’, ‘apple’) type(t) &lt;class ‘tuple’&gt; 4.1.1.2 item1, item2, item3 Without ( ) notation, it is also considered as tuple However, some functions may not consider this method 1,2,3,&#39;o&#39;,&#39;apple&#39; (1, 2, 3, ‘o’, ‘apple’) 4.1.2 Accessing print (t[1]) 2 print (type(t[1])) &lt;class ‘int’&gt; print (t[1:3]) (2, 3) type ([t[1:3]]) &lt;class ‘list’&gt; 4.1.3 Duplicating Tuple original = (1,2,3,4,5) copy_test = original print(original) (1, 2, 3, 4, 5) print(copy_test) (1, 2, 3, 4, 5) print(&#39;Original ID: &#39;, id(original)) Original ID: 670227448 print(&#39;Copy ID: &#39;, id(copy_test)) Copy ID: 670227448 4.2 List List is a collection of ordered items, where the items can be different data types You can pack list of items by placing them into [] List is mutable 4.2.1 Creating List 4.2.1.1 Empty List empty = [] # literal assignment method empty = list() # constructor method print (empty) [] 4.2.1.2 Literal Assignment Multiple data types is allowed in a list [123,&#39;abc&#39;,456, None] [123, ‘abc’, 456, None] Constructor Note that list(string) will split the string into letters list(&#39;hello&#39;) [‘h’, ‘e’, ‘l’, ‘l’, ‘o’] 4.2.2 Accessing Items Access specific index number food = [&#39;bread&#39;, &#39;noodle&#39;, &#39;rice&#39;, &#39;biscuit&#39;,&#39;jelly&#39;,&#39;cake&#39;] print (food[2]) # 3rd item rice print (food[-1]) # last item cake Access range of indexes print (food[:4]) # first 3 items [‘bread’, ‘noodle’, ‘rice’, ‘biscuit’] print (food[-3:]) # last 3 items [‘biscuit’, ‘jelly’, ‘cake’] print (food[1:5]) # item 1 to 4 [‘noodle’, ‘rice’, ‘biscuit’, ‘jelly’] print (food[5:2:-1]) # item 3 to 5, reverse order [‘cake’, ‘jelly’, ‘biscuit’] print (food[::-1]) # reverse order [‘cake’, ‘jelly’, ‘biscuit’, ‘rice’, ‘noodle’, ‘bread’] 4.2.3 Methods 4.2.3.1 Remove Item(s) Removal of non-existance item will result in error Search and remove first occurance of an item food = list([&#39;bread&#39;, &#39;noodle&#39;, &#39;rice&#39;, &#39;biscuit&#39;,&#39;jelly&#39;,&#39;cake&#39;,&#39;noodle&#39;]) food.remove(&#39;noodle&#39;) print (food) [‘bread’, ‘rice’, ‘biscuit’, ‘jelly’, ‘cake’, ‘noodle’] Remove last item food.pop() ‘noodle’ print (food) [‘bread’, ‘rice’, ‘biscuit’, ‘jelly’, ‘cake’] Remove item at specific position food.pop(1) # counter start from 0 ‘rice’ print(food) [‘bread’, ‘biscuit’, ‘jelly’, ‘cake’] food.remove(&#39;jelly&#39;) print(food) [‘bread’, ‘biscuit’, ‘cake’] 4.2.3.2 Appending Item (s) Append One Item food.append(&#39;jelly&#39;) print (food) [‘bread’, ‘biscuit’, ‘cake’, ‘jelly’] Append Multiple Items extend() will expand the list/tupple argument and append as multiple items food.extend([&#39;nand&#39;,&#39;puff&#39;]) print (food) [‘bread’, ‘biscuit’, ‘cake’, ‘jelly’, ‘nand’, ‘puff’] 4.2.3.3 Other Methods Reversing the order of the items food.reverse() food [‘puff’, ‘nand’, ‘jelly’, ‘cake’, ‘biscuit’, ‘bread’] Locating the Index Number of An Item food.index(&#39;biscuit&#39;) 4 Count occurance test = [&#39;a&#39;,&#39;a&#39;,&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] test.count(&#39;a&#39;) 3 Sorting The Order of Items food.sort() print (food) [‘biscuit’, ‘bread’, ‘cake’, ‘jelly’, ‘nand’, ‘puff’] 4.2.4 Operator 4.2.4.1 Concatenation Concatenating Lists Two lists can be concatenanted using ‘+’ operator. [&#39;dog&#39;,&#39;cat&#39;,&#39;horse&#39;] + [&#39;elephant&#39;,&#39;tiger&#39;] + [&#39;sheep&#39;] [‘dog’, ‘cat’, ‘horse’, ‘elephant’, ‘tiger’, ‘sheep’] 4.2.5 List is Mutable The reference of list variable won’t change after adding/removing its item food = [&#39;cake&#39;,&#39;jelly&#39;,&#39;roti&#39;,&#39;noodle&#39;] print (&#39;food : &#39;,id(food)) food : 670300744 food += [&#39;salad&#39;,&#39;chicken&#39;] print (&#39;food : &#39;,id(food)) food : 670300744 A function is actually an object, which reference never change, hence mutable def spam (elem, some_list=[&#39;a&#39;,&#39;b&#39;]): some_list.append(elem) return some_list print (spam(1,[&#39;x&#39;])) [‘x’, 1] print (spam(2)) ## second parameter is not passed [‘a’, ‘b’, 2] print (spam(3)) ## notice the default was remembered [‘a’, ‘b’, 2, 3] 4.2.6 Duplicate or Reference Use = : It just copy the refernce. IDs are similar original = [1,2,3,4,5] copy_test = original print(&#39;Original ID: &#39;, id(original)) Original ID: 670369480 print(&#39;Copy ID: &#39;, id(copy_test)) Copy ID: 670369480 original[0]=999 ## change original print(original) [999, 2, 3, 4, 5] print(copy_test) ## copy affected [999, 2, 3, 4, 5] Duplicate A List Object with copy(). Resulting IDs are different original = [1,2,3,4,5] copy_test = original.copy() print(original) [1, 2, 3, 4, 5] print(copy_test) [1, 2, 3, 4, 5] print(&#39;Original ID: &#39;, id(original)) Original ID: 670474120 print(&#39;Copy ID: &#39;, id(copy_test)) Copy ID: 678958664 original[0] = 999 ## change original print(original) [999, 2, 3, 4, 5] print(copy_test) ## copy not affected [1, 2, 3, 4, 5] Passing To Function As Reference def func(x): print (x) print(&#39;ID in Function: &#39;, id(x)) x.append(6) ## modify the refrence my_list = [1,2,3,4,5] print(&#39;ID outside Function: &#39;, id(my_list)) ID outside Function: 678958920 func(my_list) ## call the function, pass the reference [1, 2, 3, 4, 5] ID in Function: 678958920 print(my_list) ## content was altered [1, 2, 3, 4, 5, 6] 4.2.7 List Is Iterable 4.2.7.1 For Loop s = [&#39;abc&#39;,&#39;abcd&#39;,&#39;bcde&#39;,&#39;bcdee&#39;,&#39;cdefg&#39;] for x in s: if &#39;abc&#39; in x: print (x) abc abcd #### List Comprehension This code below is a shorform method of for loop and if. old_list = [&#39;abc&#39;,&#39;abcd&#39;,&#39;bcde&#39;,&#39;bcdee&#39;,&#39;cdefg&#39;] [x for x in old_list if &#39;abc&#39; in x] [‘abc’, ‘abcd’] Compare to traditional version of code below: new_list = [] old_list = [&#39;abc&#39;,&#39;abcd&#39;,&#39;bcde&#39;,&#39;bcdee&#39;,&#39;cdefg&#39;] for x in old_list: if &#39;abc&#39; in x: new_list.append(x) print( new_list ) [‘abc’, ‘abcd’] 4.2.8 Conversion Convert mutable list to immutable tuple with tuple() original = [1,2,3] original_tuple = tuple(original) print( id(original), id(original_tuple)) 678957384 670281160 4.2.9 Built-In Functions Applicable To List Number of Elements len(food) 6 Max Value test = [1,2,3,5,5,3,2,1] m = max(test) test.index(m) ## only first occurance is found 3 4.3 Dictionaries Dictionary is a list of index-value items. 4.3.1 Creating dict Creating dict with literals Simple Dictionary animal_counts = { &#39;cats&#39; : 2, &#39;dogs&#39; : 5, &#39;horses&#39;:4} print (animal_counts) {‘cats’: 2, ‘dogs’: 5, ‘horses’: 4} print( type(animal_counts) ) &lt;class ‘dict’&gt; Dictionary with list animal_names = {&#39;cats&#39;: [&#39;Walter&#39;,&#39;Ra&#39;], &#39;dogs&#39;: [&#39;Jim&#39;,&#39;Roy&#39;,&#39;John&#39;,&#39;Lucky&#39;,&#39;Row&#39;], &#39;horses&#39;: [&#39;Sax&#39;,&#39;Jack&#39;,&#39;Ann&#39;,&#39;Jeep&#39;] } animal_names {‘cats’: [‘Walter’, ‘Ra’], ‘dogs’: [‘Jim’, ‘Roy’, ‘John’, ‘Lucky’, ‘Row’], ‘horses’: [‘Sax’, ‘Jack’, ‘Ann’, ‘Jeep’]} Creating dict From variables cat_names = [&#39;Walter&#39;,&#39;Ra&#39;,&#39;Jim&#39;] dog_names = [&#39;Jim&#39;,&#39;Roy&#39;,&#39;John&#39;,&#39;Lucky&#39;,&#39;Row&#39;] horse_names= [&#39;Sax&#39;,&#39;Jack&#39;,&#39;Ann&#39;,&#39;Jeep&#39;] animal_names = {&#39;cats&#39;: cat_names, &#39;dogs&#39;: dog_names, &#39;horses&#39;: horse_names} animal_names {‘cats’: [‘Walter’, ‘Ra’, ‘Jim’], ‘dogs’: [‘Jim’, ‘Roy’, ‘John’, ‘Lucky’, ‘Row’], ‘horses’: [‘Sax’, ‘Jack’, ‘Ann’, ‘Jeep’]} 4.3.2 Accessing dict Find out the list of keys using keys() print (animal_names.keys()) dict_keys([‘cats’, ‘dogs’, ‘horses’]) print (sorted(animal_names.keys())) [‘cats’, ‘dogs’, ‘horses’] Find out the list of values using values() print (animal_names.values()) dict_values([[‘Walter’, ‘Ra’, ‘Jim’], [‘Jim’, ‘Roy’, ‘John’, ‘Lucky’, ‘Row’], [‘Sax’, ‘Jack’, ‘Ann’, ‘Jeep’]]) print (sorted(animal_names.values())) [[‘Jim’, ‘Roy’, ‘John’, ‘Lucky’, ‘Row’], [‘Sax’, ‘Jack’, ‘Ann’, ‘Jeep’], [‘Walter’, ‘Ra’, ‘Jim’]] Refer a dictionary item using index animal_names[&#39;dogs&#39;] [‘Jim’, ‘Roy’, ‘John’, ‘Lucky’, ‘Row’] Accessing non-existance key natively will return Error ##animal_count[&#39;cow&#39;] Accessing non-existance key with get() will return None print (animal_counts.get(&#39;cow&#39;)) None 4.3.3 Dict are Mutable Use [key] notation to update the content of element. However, if the key is non-existance, this will return error. animal_names[&#39;dogs&#39;] = [&#39;Ali&#39;,&#39;Abu&#39;,&#39;Bakar&#39;] animal_names {‘cats’: [‘Walter’, ‘Ra’, ‘Jim’], ‘dogs’: [‘Ali’, ‘Abu’, ‘Bakar’], ‘horses’: [‘Sax’, ‘Jack’, ‘Ann’, ‘Jeep’]} Use clear() to erase all elements animal_names.clear() 4.4 Sets Set is unordered collection of unique items myset = {&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;a&#39;,&#39;b&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;} print (myset) # notice no repetition values {‘g’, ‘d’, ‘a’, ‘e’, ‘b’, ‘c’, ‘f’} 4.4.1 Membership Test print (&#39;a&#39; in myset) # is member ? True print (&#39;f&#39; not in myset) # is not member ? False 4.4.2 Subset Test Subset Test : &lt;= Proper Subset Test : &lt; mysubset = {&#39;d&#39;,&#39;g&#39;} mysubset &lt;= myset True Proper Subset test that the master set contain at least one element which is not in the subset mysubset = {&#39;b&#39;,&#39;a&#39;,&#39;d&#39;,&#39;c&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;} print (&#39;Is Subset : &#39;, mysubset &lt;= myset) Is Subset : True print (&#39;Is Proper Subet : &#39;, mysubset &lt; myset) Is Proper Subet : False 4.4.3 Union using ‘|’ {&#39;a&#39;,&#39;b&#39;,&#39;c&#39;} | {&#39;e&#39;,&#39;f&#39;} {‘a’, ‘b’, ‘e’, ‘c’, ‘f’} 4.4.4 Intersection using ‘&amp;’ Any elments that exist in both left and right set {&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;} &amp; {&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;} {‘c’, ‘d’} 4.4.5 Difference using ‘-’ Anything in left that is not in right {&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;} - {&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;} {‘a’, ‘b’} 4.5 range range(X) generates sequence of integer object range (lower_bound, upper_bound, step_size) # lower bound is optional, default = 0 # upper bound is not included in result # step is optional, default = 1 Use list() to convert in order to view actual sequence of data r = range(10) # default lower bound =0, step =1 print (type (r)) &lt;class ‘range’&gt; print (r) range(0, 10) print (list(r)) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] More Examples print (list(range(2,8))) # step not specified, default 1 [2, 3, 4, 5, 6, 7] print (&#39;Odds Number : &#39; , list(range(1,10,2))) # generate odds number Odds Number : [1, 3, 5, 7, 9] "],
["control-and-loops.html", "5 Control and Loops 5.1 If Statement 5.2 For Loops 5.3 Generators", " 5 Control and Loops 5.1 If Statement 5.1.1 Multiline If.. Statements price = 102 if price &lt;100: print (&#39;buy&#39;) elif price &lt; 110: print (&#39;hold&#39;) elif price &lt; 120: print (&#39;think about it&#39;) else: print (&#39;sell&#39;) hold print(&#39;end of programming&#39;) end of programming 5.1.2 Single Line If .. Statement price = 70 if price&lt;80: print(&#39;buy&#39;) buy price = 85 &#39;buy&#39; if (price&lt;80) else &#39;dont buy&#39; ‘dont buy’ 5.2 For Loops 5.2.1 Loop thorugh ‘range’ for i in range (1,10,2): print (&#39;Odds Number : &#39;,i) Odds Number : 1 Odds Number : 3 Odds Number : 5 Odds Number : 7 Odds Number : 9 5.2.2 Loop through ‘list’ 5.2.2.1 Standard For Loop letters = [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;] for e in letters: print (&#39;Letter : &#39;,e) Letter : a Letter : b Letter : c Letter : d 5.2.2.2 List Comprehension Iterate through existing list, and build new list based on condition new_list = [expression(i) for i in old_list] s = [&#39;abc&#39;,&#39;abcd&#39;,&#39;bcde&#39;,&#39;bcdee&#39;,&#39;cdefg&#39;] [x.upper() for x in s] [‘ABC’, ‘ABCD’, ‘BCDE’, ‘BCDEE’, ‘CDEFG’] Extend list comprehension can be extended with if condition** new_list = [expression(i) for i in old_list if filter(i)] old_list = [&#39;abc&#39;,&#39;abcd&#39;,&#39;bcde&#39;,&#39;bcdee&#39;,&#39;cdefg&#39;] matching = [ x.upper() for x in old_list if &#39;bcd&#39; in x ] print( matching ) [‘ABCD’, ‘BCDE’, ‘BCDEE’] 5.2.3 Loop Through ‘Dictionary’ Looping through dict will picup key d = {&quot;x&quot;: 1, &quot;y&quot;: 2} for key in d: print (key, d[key]) x 1 y 2 5.3 Generators Generator is lazy, produce items only if asked for, hence more memory efficient Generator is function with ‘yield’ instead of ‘return’ Generator contains one or more yields statement When called, it returns an object (iterator) but does not start execution immediately Methods like iter() and next() are implemented automatically. So we can iterate through the items using next() Once the function yields, the function is paused and the control is transferred to the caller Local variables and their states are remembered between successive calls Finally, when the function terminates, StopIteration is raised automatically on further calls 5.3.1 Basic Generator Function Below example give clear understanding of how generator works def my_gen(): n = 1 print(&#39;This is printed first&#39;) # Generator function contains yield statements yield n n += 1 print(&#39;This is printed second&#39;) yield n n += 1 print(&#39;This is printed at last&#39;) yield n a = my_gen() type(a) &lt;class ‘generator’&gt; next(a) This is printed first 1 next(a) This is printed second 2 5.3.2 Useful Generator Fuction Generator is only useful when it uses for-loop - for-loop within generator - for-loop to iterate through a generator def rev_str(my_str): length = len(my_str) for i in range(length - 1,-1,-1): yield my_str[i] for c in rev_str(&quot;hello&quot;): print(c) o l l e h 5.3.3 Generator Expression Use () to create an annonymous generator function my_list = [1, 3, 6, 10] a = (x**2 for x in my_list) next(a) 1 next(a) 9 sum(a) # sum the power of 6,10 136 5.3.4 Compare to Iterator Class class PowTwo: def __init__(self, max = 0): self.max = max def __iter__(self): self.n = 0 return self def __next__(self): if self.n &gt; self.max: raise StopIteration result = 2 ** self.n self.n += 1 return result Obviously, Generator is more concise and cleaner def PowTwoGen(max = 0): n = 0 while n &lt; max: yield 2 ** n n += 1 "],
["library-and-functions.html", "6 Library and Functions 6.1 Package Source 6.2 Importing Library 6.3 Define Function", " 6 Library and Functions Library are group of functions 6.1 Package Source 6.1.1 Conda Package manager for any language Install binaries 6.1.2 PIP Package manager python only Compile from source Stands for Pip Installs Packages Python’s officially-sanctioned package manager, and is most commonly used to install packages published on the Python Package Index (PyPI) Both pip and PyPI are governed and supported by the Python Packaging Authority (PyPA). 6.2 Importing Library There are two methods to import library functions: Standalone Namespace - import &lt;libName&gt; # access function through: libName.functionName - import &lt;libName&gt; as &lt;shortName&gt; # access function through: shortName.functionName Global Namespace - from &lt;libName&gt; import * # all functions available at global namespace - from &lt;libName&gt; import &lt;functionName&gt; # access function through: functionName - from &lt;libName&gt; import &lt;functionName&gt; as &lt;shortFunctionName&gt; # access function through shortFunctionName 6.2.1 Import Entire Library 6.2.1.1 Import Into Standalone Namespace import math math.sqrt(9) 3.0 Use as for aliasing library name. This is useful if you have conflicting library name import math as m m.sqrt(9) 3.0 6.2.1.2 Import Into Global Name Space All functions in the library accessible through global namespace from &lt;libName&gt; import * 6.2.2 Import Specific Function from math import sqrt print (sqrt(9)) 3.0 Use as for aliasing function name from math import sqrt as sq print (sq(9)) 3.0 6.2.3 Machine Learning Packages alt text 6.3 Define Function 6.3.1 Function Arguments By default, arguments are assigned to function left to right def myfun(x,y): print (&#39;x:&#39;,x) print (&#39;y:&#39;,y) myfun(5,8) x: 5 y: 8 However, you can also specify the argument assigment during function call myfun (y=8,x=5) x: 5 y: 8 Function can have default argement value def myfun(x=1,y=1): # default argument value is 1 print (&#39;x:&#39;,x) print (&#39;y:&#39;,y) myfun(5) # pass only one argument x: 5 y: 1 6.3.2 List Within Function Consider a function is an object, its variable (some_list) is immutable and hence its reference won’t change, even data changes def spam (elem, some_list=[]): some_list.append(elem) return some_list print (spam(1)) [1] print (spam(2)) [1, 2] print (spam(3)) [1, 2, 3] 6.3.3 Return Statement def bigger(x,y): if (x&gt;y): return x else: return y print (bigger(5,8)) 8 6.3.4 No Return Statement if no return statement, python return None def dummy(): print (&#39;This is a dummy function, return no value&#39;) dummy() This is a dummy function, return no value 6.3.5 Return Multiple Value Multiple value is returned as tuple. Use multiple assignment to assign to multiple variable def minmax(x,y,z): return min(x,y,z), max(x,y,z) a,b = minmax(7,8,9) # multiple assignment c = minmax(7,8,9) # tuple print (a,b) 7 9 print (c) (7, 9) 6.3.6 Passing Function as Argument You can pass a function name as an argument to a function def myfun(x,y,f): f(x,y) myfun(&#39;hello&#39;,54,print) hello 54 6.3.7 Arguments args is a tuple 6.3.7.1 Example 1 Error example, too many parameters passed over to function 6.3.7.2 Example 2 First argument goes to x, remaining goes to args as tuple def myfun(x,*args): print (x) print (args) #tuple myfun(1,2,3,4,5,&#39;abc&#39;) 1 (2, 3, 4, 5, ‘abc’) 6.3.7.3 Example 3 First argument goes to x, second argument goest to y, remaining goes to args def myfun(x,y,*args): print (x) print (y) print (args) #tuple myfun(1,2,3) 1 2 (3,) 6.3.7.4 Example 4 def myfun(x,*args, y=9): print (x) print (y) print (args) #tuple myfun(1,2,3,4,5) 1 9 (2, 3, 4, 5) 6.3.7.5 Example 5 All goes to args def myfun(*args): print (args) #tuple myfun(1,2,3,4,5) (1, 2, 3, 4, 5) 6.3.7.6 Example 6 Empty args def myfun(x,y,*args): print (x) print (y) print (args) myfun(1,2) 1 2 () 6.3.8 keyword arguments kwargs is a dictionary 6.3.8.1 Example 1 def foo(**kwargs): print(kwargs) foo(a=1,b=2,c=3) {‘a’: 1, ‘b’: 2, ‘c’: 3} 6.3.8.2 Example 2 def foo(x,**kwargs): print(x) print(kwargs) foo(9,a=1,b=2,c=3) 9 {‘a’: 1, ‘b’: 2, ‘c’: 3} foo(9) #empty dictionary 9 {} 6.3.8.3 Example 3 def foo(a,b,c,d=1): print(a) print(b) print(c) print(d) foo(**{&quot;a&quot;:2,&quot;b&quot;:3,&quot;c&quot;:4}) 2 3 4 1 6.3.9 Mixing *args, **kwargs Always put args before kwargs 6.3.9.1 Example 1 def foo(x,y=1,**kwargs): print (x) print (y) print (kwargs) foo(1,2,c=3,d=4) 1 2 {‘c’: 3, ‘d’: 4} 6.3.9.2 Example 2 def foo(x,y=2,*args,**kwargs): print (x) print (y) print (args) print (kwargs) foo(1,2,3,4,5,c=6,d=7) 1 2 (3, 4, 5) {‘c’: 6, ‘d’: 7} "],
["object-oriented-programming.html", "7 Object Oriented Programming 7.1 Defining Class 7.2 Object Class Assignment 7.3 Calling Method 7.4 Getting Property 7.5 Setting Property", " 7 Object Oriented Programming 7.1 Defining Class Every function within a class must have at least one parameter - self, accept it Use init as the constructor function. init is optional class Person: wallet = 0 # def __init__(self, myname,money=0): # constructor self.name = myname self.wallet=money def say_hi(self): print(&#39;Hello, my name is : &#39;, self.name) def say_bye(self): print(&#39;Goodbye&#39;, Person.ID) def take(self,amount): self.wallet+=amount def balance(self): print(&#39;Wallet Balance:&#39;,self.wallet) 7.2 Object Class Assignment #p = Person() ## this will fail, as the constructor expect a parameter p1 = Person(&#39;Yong&#39;) p2 = Person(&#39;Gan&#39;,200) 7.3 Calling Method p1.say_hi() Hello, my name is : Yong p1.balance() Wallet Balance: 0 p2.say_hi() Hello, my name is : Gan p2.balance() Wallet Balance: 200 7.4 Getting Property p1.wallet 0 p2.wallet 200 7.5 Setting Property p1.wallet = 900 p1.wallet 900 "],
["decorator.html", "8 Decorator 8.1 Definition 8.2 Examples", " 8 Decorator 8.1 Definition Decorator is a function that accept callable as the only argument The main purpose of decarator is to enhance the program of the decorated function It returns a callable 8.2 Examples 8.2.1 Example 1 - Plain decorator function Many times, it is useful to register a function elsewhere - for example, registering a task in a task runner, or a functin with signal handler register is a decarator, it accept decorated as the only argument foo() and bar() are the decorated function of register registry = [] def register(decorated): registry.append(decorated) return decorated @register def foo(): return 3 @register def bar(): return 5 registry [&lt;function foo at 0x00000000287B9048&gt;, &lt;function bar at 0x00000000287AFAE8&gt;] registry[0]() 3 registry[1]() 5 8.2.2 Example 2 - Decorator with Class Extending the use case above register is the decarator, it has only one argument class Registry(object): def __init__(self): self._functions = [] def register(self,decorated): self._functions.append(decorated) return decorated def run_all(self,*args,**kwargs): return_values = [] for func in self._functions: return_values.append(func(*args,**kwargs)) return return_values The decorator will decorate two functions, for both object a and b a = Registry() b = Registry() @a.register def foo(x=3): return x @b.register def bar(x=5): return x @a.register @b.register def bax(x=7): return x Observe the result print (a._functions) [&lt;function foo at 0x00000000287B9D08&gt;, &lt;function bax at 0x00000000287B9E18&gt;] print (b._functions) [&lt;function bar at 0x00000000287B9D90&gt;, &lt;function bax at 0x00000000287B9E18&gt;] print (a.run_all()) [3, 7] print (b.run_all()) [5, 7] print ( a.run_all(x=9) ) [9, 9] print ( b.run_all(x=9) ) [9, 9] "],
["datetime-standard-library.html", "9 datetime Standard Library 9.1 ISO8601 9.2 Module Import 9.3 Class 9.4 date 9.5 date and datetime 9.6 time 9.7 timedelta", " 9 datetime Standard Library This is a built-in library by Python. There is no need to install this library. 9.1 ISO8601 https://en.wikipedia.org/wiki/ISO_8601#Time_zone_designators 9.1.1 Date Time UTC: \"2007-04-05T14:30Z\" #notice Z GMT+8: \"2007-04-05T12:30+08:00 #notice +08:00 GMT+8: \"2007-04-05T12:30+0800 #notice +0800 GMT+8: \"2007-04-05T12:30+08 #notice +08 9.1.2 Date 2019-02-04 #notice no timezone available 9.2 Module Import from datetime import date # module for date object from datetime import time # module for time object from datetime import datetime # module for datetime object from datetime import timedelta 9.3 Class datetime library contain three class of objects: - date (year,month,day) - time (hour,minute,second) - datetime (year,month,day,hour,minute,second) - timedelta: duration between two datetime or date object 9.4 date 9.4.1 Constructor print( date(2000,1,1) ) 2000-01-01 print( date(year=2000,month=1,day=1) ) 2000-01-01 print( type(date(year=2000,month=1,day=1))) &lt;class ‘datetime.date’&gt; 9.4.2 Class Method 9.4.2.1 today This is local date (not UTC) date.today() datetime.date(2019, 12, 22) print( date.today() ) 2019-12-22 9.4.2.2 Convert From ISO fromisoformat strptime is not available for date conversion. It is only for datetime conversion date.fromisoformat(&#39;2011-11-11&#39;) datetime.date(2011, 11, 11) To convert non-iso format date string to date object, convert to datetime first, then to date 9.4.3 Instance Method 9.4.3.1 replace() Replace year/month/day with specified parameter, non specified params will remain unchange. Example below change only month. You can change year or day in combination print( date.today() ) 2019-12-22 print( date.today().replace(month=8) ) 2019-08-22 9.4.3.2 weekday(), isoweekday() For weekday(), Zero being Monday For isoweekday(), Zero being Sunday print( date.today().weekday() ) 6 print( date.today().isoweekday() ) 7 weekdays = [&#39;Mon&#39;,&#39;Tue&#39;,&#39;Wed&#39;,&#39;Thu&#39;,&#39;Fri&#39;,&#39;Sat&#39;,&#39;Sun&#39;] wd = date.today().weekday() print( date.today(), &quot;is day&quot;, wd ,&quot;which is&quot;, weekdays[wd] ) 2019-12-22 is day 6 which is Sun 9.4.3.3 Formating with isoformat() isoformat() return ISO 8601 String (YYYY-MM-DD) date.today().isoformat() # return string ‘2019-12-22’ 9.4.3.4 Formating with strftime For complete directive, see below: https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior date.today().strftime(&quot;%m/%d&quot;) ‘12/22’ 9.4.3.5 isocalendar() isocalendar return a 3-tuple, (ISO year, ISO week number, ISO weekday). date.today().isocalendar() ## return tuple (2019, 51, 7) 9.4.4 Attributes print( date.today().year ) 2019 print( date.today().month ) 12 print( date.today().day ) 22 9.5 date and datetime 9.5.1 Constructor import datetime as dt print( dt.date(2000,1,1,), &#39;\\n&#39;, dt.datetime(2000,1,1,0,0,0), &#39;\\n&#39;, dt.datetime(year=2000,month=1,day=1,hour=23,minute=15,second=55),&#39;\\n&#39;, type(dt.date(2000,1,1)),&#39;\\n&#39;, type(dt.datetime(2000,1,1,0,0,0))) 2000-01-01 2000-01-01 00:00:00 2000-01-01 23:15:55 &lt;class ‘datetime.date’&gt; &lt;class ‘datetime.datetime’&gt; 9.5.2 Class Method 9.5.2.1 now and today Both now() and today() return current system local datetime, no timezone print( dt.datetime.now(), &#39;\\n&#39;, dt.datetime.now().date()) 2019-12-22 21:03:56.505919 2019-12-22 dt.datetime.today() datetime.datetime(2019, 12, 22, 21, 3, 56, 520923) 9.5.2.2 utcnow dt.datetime.utcnow() datetime.datetime(2019, 12, 22, 13, 3, 56, 535920) 9.5.2.3 combine() date and time Apply datetime.combine() module method on both date and time object to get datetime now = dt.datetime.now() dt.datetime.combine(now.date(), now.time()) datetime.datetime(2019, 12, 22, 21, 3, 56, 545919) 9.5.2.4 Convert from String strptime() Use strptime to convert string into datetime object %I : 12-hour %H : 24-hour %M : Minute %p : AM/PM %y : 18 %Y : 2018 %b : Mar %m : month (1 to 12) %d : day datetime.strptime(&#39;2011-02-25&#39;,&#39;%Y-%m-%d&#39;) datetime.datetime(2011, 2, 25, 0, 0) datetime.strptime(&#39;9-01-18&#39;,&#39;%d-%m-%y&#39;) datetime.datetime(2018, 1, 9, 0, 0) datetime.strptime(&#39;09-Mar-2018&#39;,&#39;%d-%b-%Y&#39;) datetime.datetime(2018, 3, 9, 0, 0) datetime.strptime(&#39;2/5/2018 4:49 PM&#39;, &#39;%m/%d/%Y %I:%M %p&#39;) datetime.datetime(2018, 2, 5, 16, 49) 9.5.2.5 Convert from ISO fromisoformat fromisoformat() is intend to be reverse of isoformat() It actually not ISO compliance: when Z or +8 is included at the end of the string, error occur #s = dt.datetime.now().isoformat() dt.datetime.fromisoformat(&quot;2019-02-05T10:22:33&quot;) datetime.datetime(2019, 2, 5, 10, 22, 33) 9.5.3 Instance Method 9.5.3.1 weekday datetime.now().weekday() 6 9.5.3.2 replace datetime.now().replace(year=1999) datetime.datetime(1999, 12, 22, 21, 3, 56, 647921) 9.5.3.3 convert to .time() datetime.now().time() datetime.time(21, 3, 56, 660918) 9.5.3.4 Convert to .date() datetime.now().date() datetime.date(2019, 12, 22) 9.5.3.5 Convert to String str str( datetime.now() ) ‘2019-12-22 21:03:56.687917’ Use strftime() dt.datetime.now().strftime(&#39;%d-%b-%Y&#39;) ‘22-Dec-2019’ dt.datetime.utcnow().strftime(&#39;%Y-%m-%dT%H:%M:%S.%fZ&#39;) ## ISO 8601 UTC ‘2019-12-22T13:03:56.767077Z’ Use isoformat() dt.datetime.utcnow().isoformat() ‘2019-12-22T13:03:56.782919’ 9.5.4 Attributes print( datetime.now().year ) 2019 print( datetime.now().month ) 12 print( datetime.now().day ) 22 print( datetime.now().hour ) 21 print( datetime.now().minute ) 3 9.6 time 9.6.1 Constructor print( time(2) ) #default single arugement, hour 02:00:00 print( time(2,15) ) #default two arguments, hour, minute 02:15:00 print( time(hour=2,minute=15,second=30) ) 02:15:30 9.6.2 Class Method 9.6.2.1 now() There is unfortunately no single function to extract the current time. Use time() function of an datetime object datetime.now().time() datetime.time(21, 3, 56, 867924) 9.6.3 Attributes print( datetime.now().time().hour ) 21 print( datetime.now().time().minute ) 3 print( datetime.now().time().second ) 56 9.7 timedelta years argument is not supported Apply timedelta on datetime object timedelta cannot be applied on time object , because timedelta potentially go beyond single day (24H) delt = timedelta(days=365,minutes=33,seconds=15) now = datetime.now() print (&#39;delt+now : &#39;, now+delt) delt+now : 2020-12-21 21:37:11.951922 "],
["getting-external-data.html", "10 Getting External Data", " 10 Getting External Data "],
["plydata-dplyr-for-python.html", "11 Plydata (dplyr for Python) 11.1 Sample Data 11.2 Column Manipulation 11.3 Sorting (arrange) 11.4 Grouping 11.5 Summarization", " 11 Plydata (dplyr for Python) 11.1 Sample Data n = 200 comp = [&#39;C&#39; + i for i in np.random.randint( 1,4, size = n).astype(str)] # 3x Company dept = [&#39;D&#39; + i for i in np.random.randint( 1,6, size = n).astype(str)] # 5x Department grp = [&#39;G&#39; + i for i in np.random.randint( 1,3, size = n).astype(str)] # 2x Groups value1 = np.random.normal( loc=50 , scale=5 , size = n) value2 = np.random.normal( loc=20 , scale=3 , size = n) #value3 = np.random.normal( loc=5 , scale=30 , size = n) mydf = pd.DataFrame({ &#39;comp&#39;:comp, &#39;dept&#39;:dept, &#39;grp&#39;: grp, &#39;value1&#39;:value1, &#39;value2&#39;:value2 #&#39;value3&#39;:value3 }) mydf.head() comp dept grp value1 value2 0 C2 D4 G1 47.816380 15.963609 1 C2 D4 G1 49.707616 24.745588 2 C1 D2 G2 52.984401 22.509276 3 C2 D5 G1 51.965129 24.633896 4 C3 D4 G1 45.257158 18.093048 11.2 Column Manipulation 11.2.1 Copy Column mydf &gt;&gt; define(newcol = &#39;value1&#39;) # simple method for one column comp dept grp value1 value2 newcol 0 C2 D4 G1 47.816380 15.963609 47.816380 1 C2 D4 G1 49.707616 24.745588 49.707616 2 C1 D2 G2 52.984401 22.509276 52.984401 3 C2 D5 G1 51.965129 24.633896 51.965129 4 C3 D4 G1 45.257158 18.093048 45.257158 5 C1 D5 G1 47.816732 22.537168 47.816732 6 C2 D3 G1 50.357366 22.454217 50.357366 7 C1 D1 G1 56.622866 21.316021 56.622866 8 C3 D5 G2 49.489573 15.884760 49.489573 9 C1 D3 G2 59.373984 20.951895 59.373984 10 C3 D4 G2 45.965512 21.139939 45.965512 11 C2 D2 G2 53.998173 21.740152 53.998173 12 C2 D2 G1 54.295160 22.110877 54.295160 13 C2 D1 G2 52.423175 15.586182 52.423175 14 C2 D2 G2 48.447547 20.763817 48.447547 15 C3 D4 G1 47.165992 22.212034 47.165992 16 C3 D1 G2 48.222485 17.928125 48.222485 17 C2 D1 G2 46.265973 20.176302 46.265973 18 C1 D5 G2 54.503914 21.221542 54.503914 19 C3 D4 G1 50.273414 16.523950 50.273414 20 C2 D5 G2 42.800201 19.098599 42.800201 21 C1 D4 G1 58.076009 23.277066 58.076009 22 C3 D3 G1 49.408077 24.148702 49.408077 23 C1 D3 G1 49.473611 22.290774 49.473611 24 C1 D4 G1 48.906879 19.882433 48.906879 25 C2 D3 G2 54.154854 17.613345 54.154854 26 C1 D5 G2 57.320406 22.790813 57.320406 27 C2 D2 G2 49.536275 20.214184 49.536275 28 C3 D2 G1 52.140971 16.611527 52.140971 29 C3 D4 G1 51.046324 23.306295 51.046324 .. … … .. … … … 170 C2 D1 G2 53.165485 19.534825 53.165485 171 C3 D5 G1 48.920773 24.033770 48.920773 172 C2 D4 G1 50.003703 12.751674 50.003703 173 C2 D5 G2 50.895804 18.694896 50.895804 174 C2 D3 G2 44.832906 21.340106 44.832906 175 C1 D4 G1 55.294440 14.972055 55.294440 176 C3 D3 G1 53.388802 25.415739 53.388802 177 C1 D2 G1 44.988903 18.734241 44.988903 178 C3 D1 G1 49.732999 17.423960 49.732999 179 C1 D3 G1 50.753064 17.665370 50.753064 180 C2 D3 G2 61.858146 21.221843 61.858146 181 C2 D4 G2 47.275445 21.652584 47.275445 182 C3 D2 G2 50.615168 22.156401 50.615168 183 C2 D4 G2 50.536913 23.967611 50.536913 184 C1 D3 G1 39.262099 22.193095 39.262099 185 C1 D1 G2 45.920627 16.704997 45.920627 186 C3 D4 G2 61.505712 19.629430 61.505712 187 C2 D5 G1 49.440885 23.677779 49.440885 188 C3 D2 G1 46.568232 17.687711 46.568232 189 C3 D4 G1 47.157621 19.116926 47.157621 190 C2 D1 G2 50.686139 15.743815 50.686139 191 C3 D3 G2 49.441870 19.285385 49.441870 192 C3 D2 G2 50.574034 17.566371 50.574034 193 C1 D4 G1 46.894366 24.930820 46.894366 194 C2 D5 G1 54.708324 21.083943 54.708324 195 C3 D2 G1 58.669329 22.531686 58.669329 196 C2 D3 G1 47.397428 22.102352 47.397428 197 C2 D5 G1 46.542407 19.631655 46.542407 198 C1 D2 G2 54.723960 18.793730 54.723960 199 C3 D2 G1 41.779611 17.792727 41.779611 [200 rows x 6 columns] mydf &gt;&gt; define ((&#39;newcol1&#39;, &#39;value1&#39;), newcol2=&#39;value2&#39;) # method for muiltiple new columns comp dept grp value1 value2 newcol1 newcol2 0 C2 D4 G1 47.816380 15.963609 47.816380 15.963609 1 C2 D4 G1 49.707616 24.745588 49.707616 24.745588 2 C1 D2 G2 52.984401 22.509276 52.984401 22.509276 3 C2 D5 G1 51.965129 24.633896 51.965129 24.633896 4 C3 D4 G1 45.257158 18.093048 45.257158 18.093048 5 C1 D5 G1 47.816732 22.537168 47.816732 22.537168 6 C2 D3 G1 50.357366 22.454217 50.357366 22.454217 7 C1 D1 G1 56.622866 21.316021 56.622866 21.316021 8 C3 D5 G2 49.489573 15.884760 49.489573 15.884760 9 C1 D3 G2 59.373984 20.951895 59.373984 20.951895 10 C3 D4 G2 45.965512 21.139939 45.965512 21.139939 11 C2 D2 G2 53.998173 21.740152 53.998173 21.740152 12 C2 D2 G1 54.295160 22.110877 54.295160 22.110877 13 C2 D1 G2 52.423175 15.586182 52.423175 15.586182 14 C2 D2 G2 48.447547 20.763817 48.447547 20.763817 15 C3 D4 G1 47.165992 22.212034 47.165992 22.212034 16 C3 D1 G2 48.222485 17.928125 48.222485 17.928125 17 C2 D1 G2 46.265973 20.176302 46.265973 20.176302 18 C1 D5 G2 54.503914 21.221542 54.503914 21.221542 19 C3 D4 G1 50.273414 16.523950 50.273414 16.523950 20 C2 D5 G2 42.800201 19.098599 42.800201 19.098599 21 C1 D4 G1 58.076009 23.277066 58.076009 23.277066 22 C3 D3 G1 49.408077 24.148702 49.408077 24.148702 23 C1 D3 G1 49.473611 22.290774 49.473611 22.290774 24 C1 D4 G1 48.906879 19.882433 48.906879 19.882433 25 C2 D3 G2 54.154854 17.613345 54.154854 17.613345 26 C1 D5 G2 57.320406 22.790813 57.320406 22.790813 27 C2 D2 G2 49.536275 20.214184 49.536275 20.214184 28 C3 D2 G1 52.140971 16.611527 52.140971 16.611527 29 C3 D4 G1 51.046324 23.306295 51.046324 23.306295 .. … … .. … … … … 170 C2 D1 G2 53.165485 19.534825 53.165485 19.534825 171 C3 D5 G1 48.920773 24.033770 48.920773 24.033770 172 C2 D4 G1 50.003703 12.751674 50.003703 12.751674 173 C2 D5 G2 50.895804 18.694896 50.895804 18.694896 174 C2 D3 G2 44.832906 21.340106 44.832906 21.340106 175 C1 D4 G1 55.294440 14.972055 55.294440 14.972055 176 C3 D3 G1 53.388802 25.415739 53.388802 25.415739 177 C1 D2 G1 44.988903 18.734241 44.988903 18.734241 178 C3 D1 G1 49.732999 17.423960 49.732999 17.423960 179 C1 D3 G1 50.753064 17.665370 50.753064 17.665370 180 C2 D3 G2 61.858146 21.221843 61.858146 21.221843 181 C2 D4 G2 47.275445 21.652584 47.275445 21.652584 182 C3 D2 G2 50.615168 22.156401 50.615168 22.156401 183 C2 D4 G2 50.536913 23.967611 50.536913 23.967611 184 C1 D3 G1 39.262099 22.193095 39.262099 22.193095 185 C1 D1 G2 45.920627 16.704997 45.920627 16.704997 186 C3 D4 G2 61.505712 19.629430 61.505712 19.629430 187 C2 D5 G1 49.440885 23.677779 49.440885 23.677779 188 C3 D2 G1 46.568232 17.687711 46.568232 17.687711 189 C3 D4 G1 47.157621 19.116926 47.157621 19.116926 190 C2 D1 G2 50.686139 15.743815 50.686139 15.743815 191 C3 D3 G2 49.441870 19.285385 49.441870 19.285385 192 C3 D2 G2 50.574034 17.566371 50.574034 17.566371 193 C1 D4 G1 46.894366 24.930820 46.894366 24.930820 194 C2 D5 G1 54.708324 21.083943 54.708324 21.083943 195 C3 D2 G1 58.669329 22.531686 58.669329 22.531686 196 C2 D3 G1 47.397428 22.102352 47.397428 22.102352 197 C2 D5 G1 46.542407 19.631655 46.542407 19.631655 198 C1 D2 G2 54.723960 18.793730 54.723960 18.793730 199 C3 D2 G1 41.779611 17.792727 41.779611 17.792727 [200 rows x 7 columns] 11.2.2 New Column from existing Column Without specify the new column name, it will be derived from expression mydf &gt;&gt; define (&#39;value1*2&#39;) comp dept grp value1 value2 value1*2 0 C2 D4 G1 47.816380 15.963609 95.632760 1 C2 D4 G1 49.707616 24.745588 99.415233 2 C1 D2 G2 52.984401 22.509276 105.968802 3 C2 D5 G1 51.965129 24.633896 103.930257 4 C3 D4 G1 45.257158 18.093048 90.514316 5 C1 D5 G1 47.816732 22.537168 95.633464 6 C2 D3 G1 50.357366 22.454217 100.714732 7 C1 D1 G1 56.622866 21.316021 113.245731 8 C3 D5 G2 49.489573 15.884760 98.979147 9 C1 D3 G2 59.373984 20.951895 118.747968 10 C3 D4 G2 45.965512 21.139939 91.931025 11 C2 D2 G2 53.998173 21.740152 107.996345 12 C2 D2 G1 54.295160 22.110877 108.590320 13 C2 D1 G2 52.423175 15.586182 104.846350 14 C2 D2 G2 48.447547 20.763817 96.895095 15 C3 D4 G1 47.165992 22.212034 94.331984 16 C3 D1 G2 48.222485 17.928125 96.444969 17 C2 D1 G2 46.265973 20.176302 92.531945 18 C1 D5 G2 54.503914 21.221542 109.007829 19 C3 D4 G1 50.273414 16.523950 100.546827 20 C2 D5 G2 42.800201 19.098599 85.600403 21 C1 D4 G1 58.076009 23.277066 116.152018 22 C3 D3 G1 49.408077 24.148702 98.816154 23 C1 D3 G1 49.473611 22.290774 98.947222 24 C1 D4 G1 48.906879 19.882433 97.813757 25 C2 D3 G2 54.154854 17.613345 108.309708 26 C1 D5 G2 57.320406 22.790813 114.640811 27 C2 D2 G2 49.536275 20.214184 99.072550 28 C3 D2 G1 52.140971 16.611527 104.281941 29 C3 D4 G1 51.046324 23.306295 102.092649 .. … … .. … … … 170 C2 D1 G2 53.165485 19.534825 106.330969 171 C3 D5 G1 48.920773 24.033770 97.841547 172 C2 D4 G1 50.003703 12.751674 100.007406 173 C2 D5 G2 50.895804 18.694896 101.791608 174 C2 D3 G2 44.832906 21.340106 89.665812 175 C1 D4 G1 55.294440 14.972055 110.588881 176 C3 D3 G1 53.388802 25.415739 106.777605 177 C1 D2 G1 44.988903 18.734241 89.977806 178 C3 D1 G1 49.732999 17.423960 99.465999 179 C1 D3 G1 50.753064 17.665370 101.506128 180 C2 D3 G2 61.858146 21.221843 123.716292 181 C2 D4 G2 47.275445 21.652584 94.550890 182 C3 D2 G2 50.615168 22.156401 101.230335 183 C2 D4 G2 50.536913 23.967611 101.073827 184 C1 D3 G1 39.262099 22.193095 78.524198 185 C1 D1 G2 45.920627 16.704997 91.841254 186 C3 D4 G2 61.505712 19.629430 123.011423 187 C2 D5 G1 49.440885 23.677779 98.881770 188 C3 D2 G1 46.568232 17.687711 93.136465 189 C3 D4 G1 47.157621 19.116926 94.315243 190 C2 D1 G2 50.686139 15.743815 101.372278 191 C3 D3 G2 49.441870 19.285385 98.883740 192 C3 D2 G2 50.574034 17.566371 101.148068 193 C1 D4 G1 46.894366 24.930820 93.788732 194 C2 D5 G1 54.708324 21.083943 109.416648 195 C3 D2 G1 58.669329 22.531686 117.338658 196 C2 D3 G1 47.397428 22.102352 94.794856 197 C2 D5 G1 46.542407 19.631655 93.084814 198 C1 D2 G2 54.723960 18.793730 109.447919 199 C3 D2 G1 41.779611 17.792727 83.559222 [200 rows x 6 columns] Specify the new column name mydf &gt;&gt; define(value3 = &#39;value1*2&#39;) comp dept grp value1 value2 value3 0 C2 D4 G1 47.816380 15.963609 95.632760 1 C2 D4 G1 49.707616 24.745588 99.415233 2 C1 D2 G2 52.984401 22.509276 105.968802 3 C2 D5 G1 51.965129 24.633896 103.930257 4 C3 D4 G1 45.257158 18.093048 90.514316 5 C1 D5 G1 47.816732 22.537168 95.633464 6 C2 D3 G1 50.357366 22.454217 100.714732 7 C1 D1 G1 56.622866 21.316021 113.245731 8 C3 D5 G2 49.489573 15.884760 98.979147 9 C1 D3 G2 59.373984 20.951895 118.747968 10 C3 D4 G2 45.965512 21.139939 91.931025 11 C2 D2 G2 53.998173 21.740152 107.996345 12 C2 D2 G1 54.295160 22.110877 108.590320 13 C2 D1 G2 52.423175 15.586182 104.846350 14 C2 D2 G2 48.447547 20.763817 96.895095 15 C3 D4 G1 47.165992 22.212034 94.331984 16 C3 D1 G2 48.222485 17.928125 96.444969 17 C2 D1 G2 46.265973 20.176302 92.531945 18 C1 D5 G2 54.503914 21.221542 109.007829 19 C3 D4 G1 50.273414 16.523950 100.546827 20 C2 D5 G2 42.800201 19.098599 85.600403 21 C1 D4 G1 58.076009 23.277066 116.152018 22 C3 D3 G1 49.408077 24.148702 98.816154 23 C1 D3 G1 49.473611 22.290774 98.947222 24 C1 D4 G1 48.906879 19.882433 97.813757 25 C2 D3 G2 54.154854 17.613345 108.309708 26 C1 D5 G2 57.320406 22.790813 114.640811 27 C2 D2 G2 49.536275 20.214184 99.072550 28 C3 D2 G1 52.140971 16.611527 104.281941 29 C3 D4 G1 51.046324 23.306295 102.092649 .. … … .. … … … 170 C2 D1 G2 53.165485 19.534825 106.330969 171 C3 D5 G1 48.920773 24.033770 97.841547 172 C2 D4 G1 50.003703 12.751674 100.007406 173 C2 D5 G2 50.895804 18.694896 101.791608 174 C2 D3 G2 44.832906 21.340106 89.665812 175 C1 D4 G1 55.294440 14.972055 110.588881 176 C3 D3 G1 53.388802 25.415739 106.777605 177 C1 D2 G1 44.988903 18.734241 89.977806 178 C3 D1 G1 49.732999 17.423960 99.465999 179 C1 D3 G1 50.753064 17.665370 101.506128 180 C2 D3 G2 61.858146 21.221843 123.716292 181 C2 D4 G2 47.275445 21.652584 94.550890 182 C3 D2 G2 50.615168 22.156401 101.230335 183 C2 D4 G2 50.536913 23.967611 101.073827 184 C1 D3 G1 39.262099 22.193095 78.524198 185 C1 D1 G2 45.920627 16.704997 91.841254 186 C3 D4 G2 61.505712 19.629430 123.011423 187 C2 D5 G1 49.440885 23.677779 98.881770 188 C3 D2 G1 46.568232 17.687711 93.136465 189 C3 D4 G1 47.157621 19.116926 94.315243 190 C2 D1 G2 50.686139 15.743815 101.372278 191 C3 D3 G2 49.441870 19.285385 98.883740 192 C3 D2 G2 50.574034 17.566371 101.148068 193 C1 D4 G1 46.894366 24.930820 93.788732 194 C2 D5 G1 54.708324 21.083943 109.416648 195 C3 D2 G1 58.669329 22.531686 117.338658 196 C2 D3 G1 47.397428 22.102352 94.794856 197 C2 D5 G1 46.542407 19.631655 93.084814 198 C1 D2 G2 54.723960 18.793730 109.447919 199 C3 D2 G1 41.779611 17.792727 83.559222 [200 rows x 6 columns] Define multiple new columns in one go. Observe there are three ways to specify the new columns mydf &gt;&gt; define(&#39;value1*2&#39;,(&#39;newcol2&#39;,&#39;value2*2&#39;),newcol3=&#39;value2*3&#39;) comp dept grp ... value1*2 newcol2 newcol3 0 C2 D4 G1 … 95.632760 31.927219 47.890828 1 C2 D4 G1 … 99.415233 49.491177 74.236765 2 C1 D2 G2 … 105.968802 45.018552 67.527828 3 C2 D5 G1 … 103.930257 49.267792 73.901688 4 C3 D4 G1 … 90.514316 36.186095 54.279143 5 C1 D5 G1 … 95.633464 45.074335 67.611503 6 C2 D3 G1 … 100.714732 44.908435 67.362652 7 C1 D1 G1 … 113.245731 42.632042 63.948063 8 C3 D5 G2 … 98.979147 31.769520 47.654280 9 C1 D3 G2 … 118.747968 41.903790 62.855685 10 C3 D4 G2 … 91.931025 42.279879 63.419818 11 C2 D2 G2 … 107.996345 43.480304 65.220455 12 C2 D2 G1 … 108.590320 44.221753 66.332630 13 C2 D1 G2 … 104.846350 31.172365 46.758547 14 C2 D2 G2 … 96.895095 41.527634 62.291451 15 C3 D4 G1 … 94.331984 44.424068 66.636102 16 C3 D1 G2 … 96.444969 35.856249 53.784374 17 C2 D1 G2 … 92.531945 40.352603 60.528905 18 C1 D5 G2 … 109.007829 42.443083 63.664625 19 C3 D4 G1 … 100.546827 33.047900 49.571850 20 C2 D5 G2 … 85.600403 38.197198 57.295797 21 C1 D4 G1 … 116.152018 46.554133 69.831199 22 C3 D3 G1 … 98.816154 48.297403 72.446105 23 C1 D3 G1 … 98.947222 44.581548 66.872322 24 C1 D4 G1 … 97.813757 39.764866 59.647300 25 C2 D3 G2 … 108.309708 35.226689 52.840034 26 C1 D5 G2 … 114.640811 45.581627 68.372440 27 C2 D2 G2 … 99.072550 40.428367 60.642551 28 C3 D2 G1 … 104.281941 33.223054 49.834581 29 C3 D4 G1 … 102.092649 46.612590 69.918886 .. … … .. … … … … 170 C2 D1 G2 … 106.330969 39.069650 58.604475 171 C3 D5 G1 … 97.841547 48.067539 72.101309 172 C2 D4 G1 … 100.007406 25.503348 38.255022 173 C2 D5 G2 … 101.791608 37.389791 56.084687 174 C2 D3 G2 … 89.665812 42.680211 64.020317 175 C1 D4 G1 … 110.588881 29.944110 44.916165 176 C3 D3 G1 … 106.777605 50.831478 76.247218 177 C1 D2 G1 … 89.977806 37.468482 56.202723 178 C3 D1 G1 … 99.465999 34.847921 52.271881 179 C1 D3 G1 … 101.506128 35.330740 52.996111 180 C2 D3 G2 … 123.716292 42.443686 63.665529 181 C2 D4 G2 … 94.550890 43.305169 64.957753 182 C3 D2 G2 … 101.230335 44.312801 66.469202 183 C2 D4 G2 … 101.073827 47.935221 71.902832 184 C1 D3 G1 … 78.524198 44.386191 66.579286 185 C1 D1 G2 … 91.841254 33.409994 50.114991 186 C3 D4 G2 … 123.011423 39.258861 58.888291 187 C2 D5 G1 … 98.881770 47.355557 71.033336 188 C3 D2 G1 … 93.136465 35.375422 53.063133 189 C3 D4 G1 … 94.315243 38.233852 57.350777 190 C2 D1 G2 … 101.372278 31.487630 47.231446 191 C3 D3 G2 … 98.883740 38.570769 57.856154 192 C3 D2 G2 … 101.148068 35.132743 52.699114 193 C1 D4 G1 … 93.788732 49.861640 74.792460 194 C2 D5 G1 … 109.416648 42.167885 63.251828 195 C3 D2 G1 … 117.338658 45.063372 67.595058 196 C2 D3 G1 … 94.794856 44.204705 66.307057 197 C2 D5 G1 … 93.084814 39.263309 58.894964 198 C1 D2 G2 … 109.447919 37.587461 56.381191 199 C3 D2 G1 … 83.559222 35.585455 53.378182 [200 rows x 8 columns] 11.2.3 Select Column(s) mydf2 = mydf &gt;&gt; define(newcol1=&#39;value1&#39;,newcol2=&#39;value2&#39;) mydf2.info() &lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 200 entries, 0 to 199 Data columns (total 7 columns): comp 200 non-null object dept 200 non-null object grp 200 non-null object value1 200 non-null float64 value2 200 non-null float64 newcol1 200 non-null float64 newcol2 200 non-null float64 dtypes: float64(4), object(3) memory usage: 11.0+ KB 11.2.3.1 By Column Names Exact Coumn Name mydf2 &gt;&gt; select (&#39;comp&#39;,&#39;dept&#39;,&#39;value1&#39;) comp dept value1 0 C2 D4 47.816380 1 C2 D4 49.707616 2 C1 D2 52.984401 3 C2 D5 51.965129 4 C3 D4 45.257158 5 C1 D5 47.816732 6 C2 D3 50.357366 7 C1 D1 56.622866 8 C3 D5 49.489573 9 C1 D3 59.373984 10 C3 D4 45.965512 11 C2 D2 53.998173 12 C2 D2 54.295160 13 C2 D1 52.423175 14 C2 D2 48.447547 15 C3 D4 47.165992 16 C3 D1 48.222485 17 C2 D1 46.265973 18 C1 D5 54.503914 19 C3 D4 50.273414 20 C2 D5 42.800201 21 C1 D4 58.076009 22 C3 D3 49.408077 23 C1 D3 49.473611 24 C1 D4 48.906879 25 C2 D3 54.154854 26 C1 D5 57.320406 27 C2 D2 49.536275 28 C3 D2 52.140971 29 C3 D4 51.046324 .. … … … 170 C2 D1 53.165485 171 C3 D5 48.920773 172 C2 D4 50.003703 173 C2 D5 50.895804 174 C2 D3 44.832906 175 C1 D4 55.294440 176 C3 D3 53.388802 177 C1 D2 44.988903 178 C3 D1 49.732999 179 C1 D3 50.753064 180 C2 D3 61.858146 181 C2 D4 47.275445 182 C3 D2 50.615168 183 C2 D4 50.536913 184 C1 D3 39.262099 185 C1 D1 45.920627 186 C3 D4 61.505712 187 C2 D5 49.440885 188 C3 D2 46.568232 189 C3 D4 47.157621 190 C2 D1 50.686139 191 C3 D3 49.441870 192 C3 D2 50.574034 193 C1 D4 46.894366 194 C2 D5 54.708324 195 C3 D2 58.669329 196 C2 D3 47.397428 197 C2 D5 46.542407 198 C1 D2 54.723960 199 C3 D2 41.779611 [200 rows x 3 columns] Column Name Starts With … mydf2 &gt;&gt; select (&#39;comp&#39;, startswith=&#39;val&#39;) comp value1 value2 0 C2 47.816380 15.963609 1 C2 49.707616 24.745588 2 C1 52.984401 22.509276 3 C2 51.965129 24.633896 4 C3 45.257158 18.093048 5 C1 47.816732 22.537168 6 C2 50.357366 22.454217 7 C1 56.622866 21.316021 8 C3 49.489573 15.884760 9 C1 59.373984 20.951895 10 C3 45.965512 21.139939 11 C2 53.998173 21.740152 12 C2 54.295160 22.110877 13 C2 52.423175 15.586182 14 C2 48.447547 20.763817 15 C3 47.165992 22.212034 16 C3 48.222485 17.928125 17 C2 46.265973 20.176302 18 C1 54.503914 21.221542 19 C3 50.273414 16.523950 20 C2 42.800201 19.098599 21 C1 58.076009 23.277066 22 C3 49.408077 24.148702 23 C1 49.473611 22.290774 24 C1 48.906879 19.882433 25 C2 54.154854 17.613345 26 C1 57.320406 22.790813 27 C2 49.536275 20.214184 28 C3 52.140971 16.611527 29 C3 51.046324 23.306295 .. … … … 170 C2 53.165485 19.534825 171 C3 48.920773 24.033770 172 C2 50.003703 12.751674 173 C2 50.895804 18.694896 174 C2 44.832906 21.340106 175 C1 55.294440 14.972055 176 C3 53.388802 25.415739 177 C1 44.988903 18.734241 178 C3 49.732999 17.423960 179 C1 50.753064 17.665370 180 C2 61.858146 21.221843 181 C2 47.275445 21.652584 182 C3 50.615168 22.156401 183 C2 50.536913 23.967611 184 C1 39.262099 22.193095 185 C1 45.920627 16.704997 186 C3 61.505712 19.629430 187 C2 49.440885 23.677779 188 C3 46.568232 17.687711 189 C3 47.157621 19.116926 190 C2 50.686139 15.743815 191 C3 49.441870 19.285385 192 C3 50.574034 17.566371 193 C1 46.894366 24.930820 194 C2 54.708324 21.083943 195 C3 58.669329 22.531686 196 C2 47.397428 22.102352 197 C2 46.542407 19.631655 198 C1 54.723960 18.793730 199 C3 41.779611 17.792727 [200 rows x 3 columns] Column Name Ends With … mydf2 &gt;&gt; select (&#39;comp&#39;,endswith=(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;)) comp value1 value2 newcol1 newcol2 0 C2 47.816380 15.963609 47.816380 15.963609 1 C2 49.707616 24.745588 49.707616 24.745588 2 C1 52.984401 22.509276 52.984401 22.509276 3 C2 51.965129 24.633896 51.965129 24.633896 4 C3 45.257158 18.093048 45.257158 18.093048 5 C1 47.816732 22.537168 47.816732 22.537168 6 C2 50.357366 22.454217 50.357366 22.454217 7 C1 56.622866 21.316021 56.622866 21.316021 8 C3 49.489573 15.884760 49.489573 15.884760 9 C1 59.373984 20.951895 59.373984 20.951895 10 C3 45.965512 21.139939 45.965512 21.139939 11 C2 53.998173 21.740152 53.998173 21.740152 12 C2 54.295160 22.110877 54.295160 22.110877 13 C2 52.423175 15.586182 52.423175 15.586182 14 C2 48.447547 20.763817 48.447547 20.763817 15 C3 47.165992 22.212034 47.165992 22.212034 16 C3 48.222485 17.928125 48.222485 17.928125 17 C2 46.265973 20.176302 46.265973 20.176302 18 C1 54.503914 21.221542 54.503914 21.221542 19 C3 50.273414 16.523950 50.273414 16.523950 20 C2 42.800201 19.098599 42.800201 19.098599 21 C1 58.076009 23.277066 58.076009 23.277066 22 C3 49.408077 24.148702 49.408077 24.148702 23 C1 49.473611 22.290774 49.473611 22.290774 24 C1 48.906879 19.882433 48.906879 19.882433 25 C2 54.154854 17.613345 54.154854 17.613345 26 C1 57.320406 22.790813 57.320406 22.790813 27 C2 49.536275 20.214184 49.536275 20.214184 28 C3 52.140971 16.611527 52.140971 16.611527 29 C3 51.046324 23.306295 51.046324 23.306295 .. … … … … … 170 C2 53.165485 19.534825 53.165485 19.534825 171 C3 48.920773 24.033770 48.920773 24.033770 172 C2 50.003703 12.751674 50.003703 12.751674 173 C2 50.895804 18.694896 50.895804 18.694896 174 C2 44.832906 21.340106 44.832906 21.340106 175 C1 55.294440 14.972055 55.294440 14.972055 176 C3 53.388802 25.415739 53.388802 25.415739 177 C1 44.988903 18.734241 44.988903 18.734241 178 C3 49.732999 17.423960 49.732999 17.423960 179 C1 50.753064 17.665370 50.753064 17.665370 180 C2 61.858146 21.221843 61.858146 21.221843 181 C2 47.275445 21.652584 47.275445 21.652584 182 C3 50.615168 22.156401 50.615168 22.156401 183 C2 50.536913 23.967611 50.536913 23.967611 184 C1 39.262099 22.193095 39.262099 22.193095 185 C1 45.920627 16.704997 45.920627 16.704997 186 C3 61.505712 19.629430 61.505712 19.629430 187 C2 49.440885 23.677779 49.440885 23.677779 188 C3 46.568232 17.687711 46.568232 17.687711 189 C3 47.157621 19.116926 47.157621 19.116926 190 C2 50.686139 15.743815 50.686139 15.743815 191 C3 49.441870 19.285385 49.441870 19.285385 192 C3 50.574034 17.566371 50.574034 17.566371 193 C1 46.894366 24.930820 46.894366 24.930820 194 C2 54.708324 21.083943 54.708324 21.083943 195 C3 58.669329 22.531686 58.669329 22.531686 196 C2 47.397428 22.102352 47.397428 22.102352 197 C2 46.542407 19.631655 46.542407 19.631655 198 C1 54.723960 18.793730 54.723960 18.793730 199 C3 41.779611 17.792727 41.779611 17.792727 [200 rows x 5 columns] Column Name Contains … mydf2 &gt;&gt; select(&#39;comp&#39;, contains=(&#39;col&#39;,&#39;val&#39;)) comp value1 value2 newcol1 newcol2 0 C2 47.816380 15.963609 47.816380 15.963609 1 C2 49.707616 24.745588 49.707616 24.745588 2 C1 52.984401 22.509276 52.984401 22.509276 3 C2 51.965129 24.633896 51.965129 24.633896 4 C3 45.257158 18.093048 45.257158 18.093048 5 C1 47.816732 22.537168 47.816732 22.537168 6 C2 50.357366 22.454217 50.357366 22.454217 7 C1 56.622866 21.316021 56.622866 21.316021 8 C3 49.489573 15.884760 49.489573 15.884760 9 C1 59.373984 20.951895 59.373984 20.951895 10 C3 45.965512 21.139939 45.965512 21.139939 11 C2 53.998173 21.740152 53.998173 21.740152 12 C2 54.295160 22.110877 54.295160 22.110877 13 C2 52.423175 15.586182 52.423175 15.586182 14 C2 48.447547 20.763817 48.447547 20.763817 15 C3 47.165992 22.212034 47.165992 22.212034 16 C3 48.222485 17.928125 48.222485 17.928125 17 C2 46.265973 20.176302 46.265973 20.176302 18 C1 54.503914 21.221542 54.503914 21.221542 19 C3 50.273414 16.523950 50.273414 16.523950 20 C2 42.800201 19.098599 42.800201 19.098599 21 C1 58.076009 23.277066 58.076009 23.277066 22 C3 49.408077 24.148702 49.408077 24.148702 23 C1 49.473611 22.290774 49.473611 22.290774 24 C1 48.906879 19.882433 48.906879 19.882433 25 C2 54.154854 17.613345 54.154854 17.613345 26 C1 57.320406 22.790813 57.320406 22.790813 27 C2 49.536275 20.214184 49.536275 20.214184 28 C3 52.140971 16.611527 52.140971 16.611527 29 C3 51.046324 23.306295 51.046324 23.306295 .. … … … … … 170 C2 53.165485 19.534825 53.165485 19.534825 171 C3 48.920773 24.033770 48.920773 24.033770 172 C2 50.003703 12.751674 50.003703 12.751674 173 C2 50.895804 18.694896 50.895804 18.694896 174 C2 44.832906 21.340106 44.832906 21.340106 175 C1 55.294440 14.972055 55.294440 14.972055 176 C3 53.388802 25.415739 53.388802 25.415739 177 C1 44.988903 18.734241 44.988903 18.734241 178 C3 49.732999 17.423960 49.732999 17.423960 179 C1 50.753064 17.665370 50.753064 17.665370 180 C2 61.858146 21.221843 61.858146 21.221843 181 C2 47.275445 21.652584 47.275445 21.652584 182 C3 50.615168 22.156401 50.615168 22.156401 183 C2 50.536913 23.967611 50.536913 23.967611 184 C1 39.262099 22.193095 39.262099 22.193095 185 C1 45.920627 16.704997 45.920627 16.704997 186 C3 61.505712 19.629430 61.505712 19.629430 187 C2 49.440885 23.677779 49.440885 23.677779 188 C3 46.568232 17.687711 46.568232 17.687711 189 C3 47.157621 19.116926 47.157621 19.116926 190 C2 50.686139 15.743815 50.686139 15.743815 191 C3 49.441870 19.285385 49.441870 19.285385 192 C3 50.574034 17.566371 50.574034 17.566371 193 C1 46.894366 24.930820 46.894366 24.930820 194 C2 54.708324 21.083943 54.708324 21.083943 195 C3 58.669329 22.531686 58.669329 22.531686 196 C2 47.397428 22.102352 47.397428 22.102352 197 C2 46.542407 19.631655 46.542407 19.631655 198 C1 54.723960 18.793730 54.723960 18.793730 199 C3 41.779611 17.792727 41.779611 17.792727 [200 rows x 5 columns] 11.2.3.2 Specify Column Range mydf2 &gt;&gt; select (&#39;comp&#39;, slice(&#39;value1&#39;,&#39;newcol2&#39;)) comp value1 value2 newcol1 newcol2 0 C2 47.816380 15.963609 47.816380 15.963609 1 C2 49.707616 24.745588 49.707616 24.745588 2 C1 52.984401 22.509276 52.984401 22.509276 3 C2 51.965129 24.633896 51.965129 24.633896 4 C3 45.257158 18.093048 45.257158 18.093048 5 C1 47.816732 22.537168 47.816732 22.537168 6 C2 50.357366 22.454217 50.357366 22.454217 7 C1 56.622866 21.316021 56.622866 21.316021 8 C3 49.489573 15.884760 49.489573 15.884760 9 C1 59.373984 20.951895 59.373984 20.951895 10 C3 45.965512 21.139939 45.965512 21.139939 11 C2 53.998173 21.740152 53.998173 21.740152 12 C2 54.295160 22.110877 54.295160 22.110877 13 C2 52.423175 15.586182 52.423175 15.586182 14 C2 48.447547 20.763817 48.447547 20.763817 15 C3 47.165992 22.212034 47.165992 22.212034 16 C3 48.222485 17.928125 48.222485 17.928125 17 C2 46.265973 20.176302 46.265973 20.176302 18 C1 54.503914 21.221542 54.503914 21.221542 19 C3 50.273414 16.523950 50.273414 16.523950 20 C2 42.800201 19.098599 42.800201 19.098599 21 C1 58.076009 23.277066 58.076009 23.277066 22 C3 49.408077 24.148702 49.408077 24.148702 23 C1 49.473611 22.290774 49.473611 22.290774 24 C1 48.906879 19.882433 48.906879 19.882433 25 C2 54.154854 17.613345 54.154854 17.613345 26 C1 57.320406 22.790813 57.320406 22.790813 27 C2 49.536275 20.214184 49.536275 20.214184 28 C3 52.140971 16.611527 52.140971 16.611527 29 C3 51.046324 23.306295 51.046324 23.306295 .. … … … … … 170 C2 53.165485 19.534825 53.165485 19.534825 171 C3 48.920773 24.033770 48.920773 24.033770 172 C2 50.003703 12.751674 50.003703 12.751674 173 C2 50.895804 18.694896 50.895804 18.694896 174 C2 44.832906 21.340106 44.832906 21.340106 175 C1 55.294440 14.972055 55.294440 14.972055 176 C3 53.388802 25.415739 53.388802 25.415739 177 C1 44.988903 18.734241 44.988903 18.734241 178 C3 49.732999 17.423960 49.732999 17.423960 179 C1 50.753064 17.665370 50.753064 17.665370 180 C2 61.858146 21.221843 61.858146 21.221843 181 C2 47.275445 21.652584 47.275445 21.652584 182 C3 50.615168 22.156401 50.615168 22.156401 183 C2 50.536913 23.967611 50.536913 23.967611 184 C1 39.262099 22.193095 39.262099 22.193095 185 C1 45.920627 16.704997 45.920627 16.704997 186 C3 61.505712 19.629430 61.505712 19.629430 187 C2 49.440885 23.677779 49.440885 23.677779 188 C3 46.568232 17.687711 46.568232 17.687711 189 C3 47.157621 19.116926 47.157621 19.116926 190 C2 50.686139 15.743815 50.686139 15.743815 191 C3 49.441870 19.285385 49.441870 19.285385 192 C3 50.574034 17.566371 50.574034 17.566371 193 C1 46.894366 24.930820 46.894366 24.930820 194 C2 54.708324 21.083943 54.708324 21.083943 195 C3 58.669329 22.531686 58.669329 22.531686 196 C2 47.397428 22.102352 47.397428 22.102352 197 C2 46.542407 19.631655 46.542407 19.631655 198 C1 54.723960 18.793730 54.723960 18.793730 199 C3 41.779611 17.792727 41.779611 17.792727 [200 rows x 5 columns] 11.2.4 Drop Column(s) mydf2 &gt;&gt; select(&#39;newcol1&#39;,&#39;newcol2&#39;,drop=True) comp dept grp value1 value2 0 C2 D4 G1 47.816380 15.963609 1 C2 D4 G1 49.707616 24.745588 2 C1 D2 G2 52.984401 22.509276 3 C2 D5 G1 51.965129 24.633896 4 C3 D4 G1 45.257158 18.093048 5 C1 D5 G1 47.816732 22.537168 6 C2 D3 G1 50.357366 22.454217 7 C1 D1 G1 56.622866 21.316021 8 C3 D5 G2 49.489573 15.884760 9 C1 D3 G2 59.373984 20.951895 10 C3 D4 G2 45.965512 21.139939 11 C2 D2 G2 53.998173 21.740152 12 C2 D2 G1 54.295160 22.110877 13 C2 D1 G2 52.423175 15.586182 14 C2 D2 G2 48.447547 20.763817 15 C3 D4 G1 47.165992 22.212034 16 C3 D1 G2 48.222485 17.928125 17 C2 D1 G2 46.265973 20.176302 18 C1 D5 G2 54.503914 21.221542 19 C3 D4 G1 50.273414 16.523950 20 C2 D5 G2 42.800201 19.098599 21 C1 D4 G1 58.076009 23.277066 22 C3 D3 G1 49.408077 24.148702 23 C1 D3 G1 49.473611 22.290774 24 C1 D4 G1 48.906879 19.882433 25 C2 D3 G2 54.154854 17.613345 26 C1 D5 G2 57.320406 22.790813 27 C2 D2 G2 49.536275 20.214184 28 C3 D2 G1 52.140971 16.611527 29 C3 D4 G1 51.046324 23.306295 .. … … .. … … 170 C2 D1 G2 53.165485 19.534825 171 C3 D5 G1 48.920773 24.033770 172 C2 D4 G1 50.003703 12.751674 173 C2 D5 G2 50.895804 18.694896 174 C2 D3 G2 44.832906 21.340106 175 C1 D4 G1 55.294440 14.972055 176 C3 D3 G1 53.388802 25.415739 177 C1 D2 G1 44.988903 18.734241 178 C3 D1 G1 49.732999 17.423960 179 C1 D3 G1 50.753064 17.665370 180 C2 D3 G2 61.858146 21.221843 181 C2 D4 G2 47.275445 21.652584 182 C3 D2 G2 50.615168 22.156401 183 C2 D4 G2 50.536913 23.967611 184 C1 D3 G1 39.262099 22.193095 185 C1 D1 G2 45.920627 16.704997 186 C3 D4 G2 61.505712 19.629430 187 C2 D5 G1 49.440885 23.677779 188 C3 D2 G1 46.568232 17.687711 189 C3 D4 G1 47.157621 19.116926 190 C2 D1 G2 50.686139 15.743815 191 C3 D3 G2 49.441870 19.285385 192 C3 D2 G2 50.574034 17.566371 193 C1 D4 G1 46.894366 24.930820 194 C2 D5 G1 54.708324 21.083943 195 C3 D2 G1 58.669329 22.531686 196 C2 D3 G1 47.397428 22.102352 197 C2 D5 G1 46.542407 19.631655 198 C1 D2 G2 54.723960 18.793730 199 C3 D2 G1 41.779611 17.792727 [200 rows x 5 columns] mydf &gt;&gt; rename( {&#39;val.1&#39; : &#39;value1&#39;, &#39;val.2&#39; : &#39;value2&#39; }) comp dept grp val.1 val.2 0 C2 D4 G1 47.816380 15.963609 1 C2 D4 G1 49.707616 24.745588 2 C1 D2 G2 52.984401 22.509276 3 C2 D5 G1 51.965129 24.633896 4 C3 D4 G1 45.257158 18.093048 5 C1 D5 G1 47.816732 22.537168 6 C2 D3 G1 50.357366 22.454217 7 C1 D1 G1 56.622866 21.316021 8 C3 D5 G2 49.489573 15.884760 9 C1 D3 G2 59.373984 20.951895 10 C3 D4 G2 45.965512 21.139939 11 C2 D2 G2 53.998173 21.740152 12 C2 D2 G1 54.295160 22.110877 13 C2 D1 G2 52.423175 15.586182 14 C2 D2 G2 48.447547 20.763817 15 C3 D4 G1 47.165992 22.212034 16 C3 D1 G2 48.222485 17.928125 17 C2 D1 G2 46.265973 20.176302 18 C1 D5 G2 54.503914 21.221542 19 C3 D4 G1 50.273414 16.523950 20 C2 D5 G2 42.800201 19.098599 21 C1 D4 G1 58.076009 23.277066 22 C3 D3 G1 49.408077 24.148702 23 C1 D3 G1 49.473611 22.290774 24 C1 D4 G1 48.906879 19.882433 25 C2 D3 G2 54.154854 17.613345 26 C1 D5 G2 57.320406 22.790813 27 C2 D2 G2 49.536275 20.214184 28 C3 D2 G1 52.140971 16.611527 29 C3 D4 G1 51.046324 23.306295 .. … … .. … … 170 C2 D1 G2 53.165485 19.534825 171 C3 D5 G1 48.920773 24.033770 172 C2 D4 G1 50.003703 12.751674 173 C2 D5 G2 50.895804 18.694896 174 C2 D3 G2 44.832906 21.340106 175 C1 D4 G1 55.294440 14.972055 176 C3 D3 G1 53.388802 25.415739 177 C1 D2 G1 44.988903 18.734241 178 C3 D1 G1 49.732999 17.423960 179 C1 D3 G1 50.753064 17.665370 180 C2 D3 G2 61.858146 21.221843 181 C2 D4 G2 47.275445 21.652584 182 C3 D2 G2 50.615168 22.156401 183 C2 D4 G2 50.536913 23.967611 184 C1 D3 G1 39.262099 22.193095 185 C1 D1 G2 45.920627 16.704997 186 C3 D4 G2 61.505712 19.629430 187 C2 D5 G1 49.440885 23.677779 188 C3 D2 G1 46.568232 17.687711 189 C3 D4 G1 47.157621 19.116926 190 C2 D1 G2 50.686139 15.743815 191 C3 D3 G2 49.441870 19.285385 192 C3 D2 G2 50.574034 17.566371 193 C1 D4 G1 46.894366 24.930820 194 C2 D5 G1 54.708324 21.083943 195 C3 D2 G1 58.669329 22.531686 196 C2 D3 G1 47.397428 22.102352 197 C2 D5 G1 46.542407 19.631655 198 C1 D2 G2 54.723960 18.793730 199 C3 D2 G1 41.779611 17.792727 [200 rows x 5 columns] Combined Method Combine both assignment and dictionary method mydf &gt;&gt; rename( {&#39;val.1&#39; : &#39;value1&#39;, &#39;val.2&#39; : &#39;value2&#39; }, group = &#39;grp&#39; ) comp dept group val.1 val.2 0 C2 D4 G1 47.816380 15.963609 1 C2 D4 G1 49.707616 24.745588 2 C1 D2 G2 52.984401 22.509276 3 C2 D5 G1 51.965129 24.633896 4 C3 D4 G1 45.257158 18.093048 5 C1 D5 G1 47.816732 22.537168 6 C2 D3 G1 50.357366 22.454217 7 C1 D1 G1 56.622866 21.316021 8 C3 D5 G2 49.489573 15.884760 9 C1 D3 G2 59.373984 20.951895 10 C3 D4 G2 45.965512 21.139939 11 C2 D2 G2 53.998173 21.740152 12 C2 D2 G1 54.295160 22.110877 13 C2 D1 G2 52.423175 15.586182 14 C2 D2 G2 48.447547 20.763817 15 C3 D4 G1 47.165992 22.212034 16 C3 D1 G2 48.222485 17.928125 17 C2 D1 G2 46.265973 20.176302 18 C1 D5 G2 54.503914 21.221542 19 C3 D4 G1 50.273414 16.523950 20 C2 D5 G2 42.800201 19.098599 21 C1 D4 G1 58.076009 23.277066 22 C3 D3 G1 49.408077 24.148702 23 C1 D3 G1 49.473611 22.290774 24 C1 D4 G1 48.906879 19.882433 25 C2 D3 G2 54.154854 17.613345 26 C1 D5 G2 57.320406 22.790813 27 C2 D2 G2 49.536275 20.214184 28 C3 D2 G1 52.140971 16.611527 29 C3 D4 G1 51.046324 23.306295 .. … … … … … 170 C2 D1 G2 53.165485 19.534825 171 C3 D5 G1 48.920773 24.033770 172 C2 D4 G1 50.003703 12.751674 173 C2 D5 G2 50.895804 18.694896 174 C2 D3 G2 44.832906 21.340106 175 C1 D4 G1 55.294440 14.972055 176 C3 D3 G1 53.388802 25.415739 177 C1 D2 G1 44.988903 18.734241 178 C3 D1 G1 49.732999 17.423960 179 C1 D3 G1 50.753064 17.665370 180 C2 D3 G2 61.858146 21.221843 181 C2 D4 G2 47.275445 21.652584 182 C3 D2 G2 50.615168 22.156401 183 C2 D4 G2 50.536913 23.967611 184 C1 D3 G1 39.262099 22.193095 185 C1 D1 G2 45.920627 16.704997 186 C3 D4 G2 61.505712 19.629430 187 C2 D5 G1 49.440885 23.677779 188 C3 D2 G1 46.568232 17.687711 189 C3 D4 G1 47.157621 19.116926 190 C2 D1 G2 50.686139 15.743815 191 C3 D3 G2 49.441870 19.285385 192 C3 D2 G2 50.574034 17.566371 193 C1 D4 G1 46.894366 24.930820 194 C2 D5 G1 54.708324 21.083943 195 C3 D2 G1 58.669329 22.531686 196 C2 D3 G1 47.397428 22.102352 197 C2 D5 G1 46.542407 19.631655 198 C1 D2 G2 54.723960 18.793730 199 C3 D2 G1 41.779611 17.792727 [200 rows x 5 columns] 11.3 Sorting (arrange) Use ‘-colName’ for decending mydf &gt;&gt; arrange(&#39;comp&#39;, &#39;-value1&#39;) comp dept grp value1 value2 103 C1 D5 G1 60.872021 19.281203 9 C1 D3 G2 59.373984 20.951895 148 C1 D3 G1 58.891197 20.527156 21 C1 D4 G1 58.076009 23.277066 26 C1 D5 G2 57.320406 22.790813 64 C1 D5 G1 57.299485 19.101406 33 C1 D1 G2 57.043036 22.773746 7 C1 D1 G1 56.622866 21.316021 36 C1 D2 G2 55.513058 20.902208 158 C1 D3 G1 55.317377 16.347295 175 C1 D4 G1 55.294440 14.972055 109 C1 D2 G2 55.082110 16.870142 198 C1 D2 G2 54.723960 18.793730 18 C1 D5 G2 54.503914 21.221542 67 C1 D5 G2 54.494052 21.202681 73 C1 D5 G1 53.987450 23.775273 63 C1 D1 G2 53.844250 16.678934 146 C1 D3 G2 53.131674 18.244052 2 C1 D2 G2 52.984401 22.509276 168 C1 D4 G1 52.777960 18.745338 164 C1 D3 G1 52.429250 18.513940 92 C1 D2 G2 52.376755 17.459091 34 C1 D3 G1 52.316232 17.742649 112 C1 D5 G2 51.798074 21.295442 30 C1 D3 G1 51.322880 22.943093 38 C1 D5 G2 51.122701 21.452558 156 C1 D5 G2 51.032950 23.684437 143 C1 D5 G1 50.895820 19.289481 179 C1 D3 G1 50.753064 17.665370 47 C1 D4 G2 50.291417 18.288234 .. … … .. … … 22 C3 D3 G1 49.408077 24.148702 108 C3 D2 G1 49.244619 15.607786 160 C3 D3 G1 49.177958 17.816576 94 C3 D2 G1 49.028467 16.752250 171 C3 D5 G1 48.920773 24.033770 76 C3 D1 G1 48.690905 19.584708 77 C3 D5 G2 48.599685 20.092609 82 C3 D5 G2 48.542368 17.863828 65 C3 D5 G1 48.342669 21.156628 16 C3 D1 G2 48.222485 17.928125 90 C3 D3 G1 47.734152 17.661349 159 C3 D5 G1 47.727502 21.059530 107 C3 D4 G1 47.650548 18.584971 88 C3 D5 G1 47.383727 24.466035 15 C3 D4 G1 47.165992 22.212034 189 C3 D4 G1 47.157621 19.116926 140 C3 D3 G2 46.839575 19.153606 49 C3 D3 G2 46.817011 20.609973 133 C3 D5 G1 46.806003 20.293066 188 C3 D2 G1 46.568232 17.687711 120 C3 D2 G2 46.520096 24.601528 10 C3 D4 G2 45.965512 21.139939 59 C3 D3 G1 45.358920 20.660286 4 C3 D4 G1 45.257158 18.093048 142 C3 D1 G2 44.453627 18.626296 121 C3 D3 G1 44.114015 23.081650 97 C3 D1 G1 43.223851 22.146652 31 C3 D5 G2 43.131038 20.170618 199 C3 D2 G1 41.779611 17.792727 71 C3 D4 G1 37.982967 20.024415 [200 rows x 5 columns] 11.4 Grouping mydf.info() &lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 200 entries, 0 to 199 Data columns (total 5 columns): comp 200 non-null object dept 200 non-null object grp 200 non-null object value1 200 non-null float64 value2 200 non-null float64 dtypes: float64(2), object(3) memory usage: 7.9+ KB gdf = mydf &gt;&gt; group_by(&#39;comp&#39;,&#39;dept&#39;) type(gdf) &lt;class ‘plydata.types.GroupedDataFrame’&gt; 11.5 Summarization 11.5.1 Simple Method Passing Multiple Expressions gdf &gt;&gt; summarize(&#39;n()&#39;,&#39;sum(value1)&#39;,&#39;mean(value2)&#39;) comp dept n() sum(value1) mean(value2) 0 C2 D4 14 720.606378 19.374994 1 C1 D2 9 456.147345 19.295508 2 C2 D5 13 645.832549 19.891566 3 C3 D4 19 970.532244 19.904632 4 C1 D5 16 816.800288 20.609187 5 C2 D3 18 918.498790 19.685877 6 C1 D1 10 488.113862 19.328734 7 C3 D5 20 1027.947354 20.372429 8 C1 D3 15 755.423360 19.591963 9 C2 D2 11 548.769214 20.928611 10 C2 D1 11 583.348095 17.990480 11 C3 D1 8 390.987942 19.326450 12 C1 D4 13 627.771432 19.676561 13 C3 D3 11 535.765521 20.121995 14 C3 D2 12 608.450883 19.222120 11.5.2 Specify Summarized Column Name Assignment Method - Passing colName=‘expression’** - Column name cannot contain special character gdf &gt;&gt; summarize(count=&#39;n()&#39;,v1sum=&#39;sum(value1)&#39;,v2_mean=&#39;mean(value2)&#39;) comp dept count v1sum v2_mean 0 C2 D4 14 720.606378 19.374994 1 C1 D2 9 456.147345 19.295508 2 C2 D5 13 645.832549 19.891566 3 C3 D4 19 970.532244 19.904632 4 C1 D5 16 816.800288 20.609187 5 C2 D3 18 918.498790 19.685877 6 C1 D1 10 488.113862 19.328734 7 C3 D5 20 1027.947354 20.372429 8 C1 D3 15 755.423360 19.591963 9 C2 D2 11 548.769214 20.928611 10 C2 D1 11 583.348095 17.990480 11 C3 D1 8 390.987942 19.326450 12 C1 D4 13 627.771432 19.676561 13 C3 D3 11 535.765521 20.121995 14 C3 D2 12 608.450883 19.222120 Tuple Method (‘colName’,‘expression’) Use when the column name contain special character gdf &gt;&gt; summarize((&#39;count&#39;,&#39;n()&#39;),(&#39;v1.sum&#39;,&#39;sum(value1)&#39;),(&#39;s2.sum&#39;,&#39;sum(value2)&#39;),v2mean=np.mean(value2)) comp dept count v1.sum s2.sum v2mean 0 C2 D4 14 720.606378 271.249910 19.754601 1 C1 D2 9 456.147345 173.659570 19.754601 2 C2 D5 13 645.832549 258.590355 19.754601 3 C3 D4 19 970.532244 378.188002 19.754601 4 C1 D5 16 816.800288 329.746986 19.754601 5 C2 D3 18 918.498790 354.345785 19.754601 6 C1 D1 10 488.113862 193.287342 19.754601 7 C3 D5 20 1027.947354 407.448585 19.754601 8 C1 D3 15 755.423360 293.879449 19.754601 9 C2 D2 11 548.769214 230.214718 19.754601 10 C2 D1 11 583.348095 197.895279 19.754601 11 C3 D1 8 390.987942 154.611603 19.754601 12 C1 D4 13 627.771432 255.795289 19.754601 13 C3 D3 11 535.765521 221.341946 19.754601 14 C3 D2 12 608.450883 230.665439 19.754601 11.5.3 Number of Rows in Group n() : total rows in group n_unique() : total of rows with unique value gdf &gt;&gt; summarize(count=&#39;n()&#39;, va11_unique=&#39;n_unique(value1)&#39;) comp dept count va11_unique 0 C2 D4 14 14 1 C1 D2 9 9 2 C2 D5 13 13 3 C3 D4 19 19 4 C1 D5 16 16 5 C2 D3 18 18 6 C1 D1 10 10 7 C3 D5 20 20 8 C1 D3 15 15 9 C2 D2 11 11 10 C2 D1 11 11 11 C3 D1 8 8 12 C1 D4 13 13 13 C3 D3 11 11 14 C3 D2 12 12 "],
["numpy-1.html", "12 numpy 12.1 Environment Setup 12.2 Module Import 12.3 Data Types 12.4 Numpy Array 12.5 Random Numbers 12.6 Sampling (Integer) 12.7 NaN : Missing Numerical Data", " 12 numpy Best array data manipulation, fast numpy array allows only single data type, unlike list Support matrix operation 12.1 Environment Setup from IPython.core.display import display, HTML display(HTML(&quot;&lt;style&gt;.container { width:75% !important; margin-left:350px; }&lt;/style&gt;&quot;)) #%matplotlib inline &lt;IPython.core.display.HTML object&gt; import pandas as pd import matplotlib.pyplot as plt import math pd.set_option( &#39;display.notebook_repr_html&#39;, False) # render Series and DataFrame as text, not HTML pd.set_option( &#39;display.max_column&#39;, 10) # number of columns pd.set_option( &#39;display.max_rows&#39;, 10) # number of rows pd.set_option( &#39;display.width&#39;, 90) # number of characters per row 12.2 Module Import import numpy as np np.__version__ ## other modules ‘1.17.1’ from datetime import datetime from datetime import date from datetime import time 12.3 Data Types 12.3.1 NumPy Data Types NumPy supports a much greater variety of numerical types than Python does. This makes numpy much more powerful https://www.numpy.org/devdocs/user/basics.types.html Integer: np.int8, np.int16, np.int32, np.uint8, np.uint16, np.uint32 Float: np.float32, np.float64 12.3.2 int32/64 np.int is actually python standard int x = np.int(13) y = int(13) print( type(x) ) &lt;class ‘int’&gt; print( type(y) ) &lt;class ‘int’&gt; np.int32/64 are NumPy specific x = np.int32(13) y = np.int64(13) print( type(x) ) &lt;class ‘numpy.int32’&gt; print( type(y) ) &lt;class ‘numpy.int64’&gt; 12.3.3 float32/64 x = np.float(13) y = float(13) print( type(x) ) &lt;class ‘float’&gt; print( type(y) ) &lt;class ‘float’&gt; x = np.float32(13) y = np.float64(13) print( type(x) ) &lt;class ‘numpy.float32’&gt; print( type(y) ) &lt;class ‘numpy.float64’&gt; 12.3.4 bool np.bool is actually python standard bool x = np.bool(True) print( type(x) ) &lt;class ‘bool’&gt; print( type(True) ) &lt;class ‘bool’&gt; 12.3.5 str np.str is actually python standard str x = np.str(&quot;ali&quot;) print( type(x) ) &lt;class ‘str’&gt; x = np.str_(&quot;ali&quot;) print( type(x) ) &lt;class ‘numpy.str_’&gt; 12.3.6 datetime64 Unlike python standard datetime library, there is no seperation of date, datetime and time. There is no time equivalent object NumPy only has one object: datetime64 object . 12.3.6.1 Constructor From String Note that the input string cannot be ISO8601 compliance, meaning any timezone related information at the end of the string (such as Z or +8) will result in error. np.datetime64(&#39;2005-02&#39;) numpy.datetime64(‘2005-02’) np.datetime64(&#39;2005-02-25&#39;) numpy.datetime64(‘2005-02-25’) np.datetime64(&#39;2005-02-25T03:30&#39;) numpy.datetime64(‘2005-02-25T03:30’) From datetime np.datetime64( date.today() ) numpy.datetime64(‘2019-12-22’) np.datetime64( datetime.now() ) numpy.datetime64(‘2019-12-22T21:03:58.428923’) 12.3.6.2 Instance Method Convert to datetime using astype() dt64 = np.datetime64(&quot;2019-01-31&quot; ) dt64.astype(datetime) datetime.date(2019, 1, 31) 12.4 Numpy Array 12.4.1 Concept Structure - NumPy provides an N-dimensional array type, the ndarray - ndarray is homogenous: every item takes up the same size block of memory, and all blocks - For each ndarray, there is a seperate dtype object, which describe ndarray data type - An item extracted from an array, e.g., by indexing, is represented by a Python object whose type is one of the array scalar types built in NumPy. The array scalars allow easy manipulation of also more complicated arrangements of data. 12.4.2 Constructor By default, numpy.array autodetect its data types based on most common denominator 12.4.2.1 dType: int, float Notice example below auto detected as int32 data type x = np.array( (1,2,3,4,5) ) print(x) [1 2 3 4 5] print(&#39;Type: &#39;, type(x)) Type: &lt;class ‘numpy.ndarray’&gt; print(&#39;dType:&#39;, x.dtype) dType: int32 Notice example below auto detected as float64 data type x = np.array( (1,2,3,4.5,5) ) print(x) [1. 2. 3. 4.5 5. ] print(&#39;Type: &#39;, type(x)) Type: &lt;class ‘numpy.ndarray’&gt; print(&#39;dType:&#39;, x.dtype) dType: float64 You can specify dtype to specify desired data types. NumPy will auto convert the data into specifeid types. Observe below that we convert float into integer x = np.array( (1,2,3,4.5,5), dtype=&#39;int&#39; ) print(x) [1 2 3 4 5] print(&#39;Type: &#39;, type(x)) Type: &lt;class ‘numpy.ndarray’&gt; print(&#39;dType:&#39;, x.dtype) dType: int32 12.4.2.2 dType: datetime64 Specify dtype is necessary to ensure output is datetime type. If not, output is generic object type. From str x = np.array([&#39;2007-07-13&#39;, &#39;2006-01-13&#39;, &#39;2010-08-13&#39;], dtype=&#39;datetime64&#39;) print(x) [‘2007-07-13’ ‘2006-01-13’ ‘2010-08-13’] print(&#39;Type: &#39;, type(x)) Type: &lt;class ‘numpy.ndarray’&gt; print(&#39;dType:&#39;, x.dtype) dType: datetime64[D] From datetime x = np.array([datetime(2019,1,12), datetime(2019,1,14),datetime(2019,3,3)], dtype=&#39;datetime64&#39;) print(x) [‘2019-01-12T00:00:00.000000’ ‘2019-01-14T00:00:00.000000’ ‘2019-03-03T00:00:00.000000’] print(&#39;Type: &#39;, type(x)) Type: &lt;class ‘numpy.ndarray’&gt; print(&#39;dType:&#39;, x.dtype) dType: datetime64[us] print(&#39;\\nElement Type:&#39;,type(x[1])) Element Type: &lt;class ‘numpy.datetime64’&gt; 12.4.2.3 2D Array x = np.array([range(10),np.arange(10)]) x array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]) 12.4.3 Dimensions 12.4.3.1 Differentiating Dimensions 1-D array is array of single list 2-D array is array made of list containing lists (each row is a list) 2-D single row array is array with list containing just one list 12.4.3.2 1-D Array Observe that the shape of the array is (5,). It seems like an array with 5 rows, empty columns ! What it really means is 5 items single dimension. arr = np.array(range(5)) print (arr) [0 1 2 3 4] print (arr.shape) (5,) print (arr.ndim) 1 12.4.3.3 2-D Array arr = np.array([range(5),range(5,10),range(10,15)]) print (arr) [[ 0 1 2 3 4] [ 5 6 7 8 9] [10 11 12 13 14]] print (arr.shape) (3, 5) print (arr.ndim) 2 12.4.3.4 2-D Array - Single Row arr = np.array([range(5)]) print (arr) [[0 1 2 3 4]] print (arr.shape) (1, 5) print (arr.ndim) 2 12.4.3.5 2-D Array : Single Column Using array slicing method with newaxis at COLUMN, will turn 1D array into 2D of single column arr = np.arange(5)[:, np.newaxis] print (arr) [[0] [1] [2] [3] [4]] print (arr.shape) (5, 1) print (arr.ndim) 2 Using array slicing method with newaxis at ROW, will turn 1D array into 2D of single row arr = np.arange(5)[np.newaxis,:] print (arr) [[0 1 2 3 4]] print (arr.shape) (1, 5) print (arr.ndim) 2 12.4.4 Class Method 12.4.4.1 arange() Generate array with a sequence of numbers np.arange(10) array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 12.4.4.2 ones() np.ones(10) # One dimension, default is float array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) np.ones((2,5),&#39;int&#39;) #Two dimensions array([[1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]) 12.4.4.3 zeros() np.zeros( 10 ) # One dimension, default is float array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) np.zeros((2,5),&#39;int&#39;) # 2 rows, 5 columns of ZERO array([[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]) 12.4.4.4 where() On 1D array numpy.where() returns the items matching the criteria ar1 = np.array(range(10)) print( ar1 ) [0 1 2 3 4 5 6 7 8 9] print( np.where(ar1&gt;5) ) (array([6, 7, 8, 9], dtype=int64),) On 2D array, where() return array of row index and col index for matching elements ar = np.array([(1,2,3,4,5),(11,12,13,14,15),(21,22,23,24,25)]) print (&#39;Data : \\n&#39;, ar) Data : [[ 1 2 3 4 5] [11 12 13 14 15] [21 22 23 24 25]] np.where(ar&gt;13) (array([1, 1, 2, 2, 2, 2, 2], dtype=int64), array([3, 4, 0, 1, 2, 3, 4], dtype=int64)) 12.4.4.5 Logical Methods numpy.logical_or Perform or operation on two boolean array, generate new resulting boolean arrays ar = np.arange(10) print( ar==3 ) # boolean array 1 [False False False True False False False False False False] print( ar==6 ) # boolean array 2 [False False False False False False True False False False] print( np.logical_or(ar==3,ar==6 ) ) # resulting boolean [False False False True False False True False False False] numpy.logical_and Perform and operation on two boolean array, generate new resulting boolean arrays ar = np.arange(10) print( ar==3 ) # boolean array 1 [False False False True False False False False False False] print( ar==6 ) # boolean array 2 [False False False False False False True False False False] print( np.logical_and(ar==3,ar==6 ) ) # resulting boolean [False False False False False False False False False False] 12.4.5 Instance Method 12.4.5.1 astype() conversion Convert to from datetime64 to datetime ar1 = np.array([&#39;2007-07-13&#39;, &#39;2006-01-13&#39;, &#39;2010-08-13&#39;], dtype=&#39;datetime64&#39;) print( type(ar1) ) ## a numpy array &lt;class ‘numpy.ndarray’&gt; print( ar1.dtype ) ## dtype is a numpy data type datetime64[D] After convert to datetime (non-numpy object, the dtype becomes generic ‘object’. ar2 = ar1.astype(datetime) print( type(ar2) ) ## still a numpy array &lt;class ‘numpy.ndarray’&gt; print( ar2.dtype ) ## dtype becomes generic &#39;object&#39; object 12.4.5.2 reshape() reshape ( row numbers, col numbers ) Sample Data a = np.array([range(5), range(10,15), range(20,25), range(30,35)]) a array([[ 0, 1, 2, 3, 4], [10, 11, 12, 13, 14], [20, 21, 22, 23, 24], [30, 31, 32, 33, 34]]) Resphepe 1-Dim to 2-Dim np.arange(12) # 1-D Array array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) np.arange(12).reshape(3,4) # 2-D Array array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) Respahe 2-Dim to 2-Dim np.array([range(5), range(10,15)]) # 2-D Array array([[ 0, 1, 2, 3, 4], [10, 11, 12, 13, 14]]) np.array([range(5), range(10,15)]).reshape(5,2) # 2-D Array array([[ 0, 1], [ 2, 3], [ 4, 10], [11, 12], [13, 14]]) Reshape 2-Dimension to 2-Dim (of single row) - Change 2x10 to 1x10 - Observe [[ ]], and the number of dimension is stll 2, don’t be fooled np.array( [range(0,5), range(5,10)]) # 2-D Array array([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]) np.array( [range(0,5), range(5,10)]).reshape(1,10) # 2-D Array array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]) Reshape 1-Dim Array to 2-Dim Array (single column) np.arange(8) array([0, 1, 2, 3, 4, 5, 6, 7]) np.arange(8).reshape(8,1) array([[0], [1], [2], [3], [4], [5], [6], [7]]) A better method, use newaxis, easier because no need to input row number as parameter np.arange(8)[:,np.newaxis] array([[0], [1], [2], [3], [4], [5], [6], [7]]) Reshape 1-Dim Array to 2-Dim Array (single row) np.arange(8) array([0, 1, 2, 3, 4, 5, 6, 7]) np.arange(8)[np.newaxis,:] array([[0, 1, 2, 3, 4, 5, 6, 7]]) 12.4.6 Element Selection 12.4.6.1 Sample Data x1 = np.array( (0,1,2,3,4,5,6,7,8)) x2 = np.array(( (1,2,3,4,5), (11,12,13,14,15), (21,22,23,24,25))) print(x1) [0 1 2 3 4 5 6 7 8] print(x2) [[ 1 2 3 4 5] [11 12 13 14 15] [21 22 23 24 25]] 12.4.6.2 1-Dimension All indexing starts from 0 (not 1) Choosing Single Element does not return array print( x1[0] ) ## first element 0 print( x1[-1] ) ## last element 8 print( x1[3] ) ## third element from start 3 3 print( x1[-3] ) ## third element from end 6 Selecting multiple elments return ndarray print( x1[:3] ) ## first 3 elements [0 1 2] print( x1[-3:]) ## last 3 elements [6 7 8] print( x1[3:] ) ## all except first 3 elements [3 4 5 6 7 8] print( x1[:-3] ) ## all except last 3 elements [0 1 2 3 4 5] print( x1[1:4] ) ## elemnt 1 to 4 (not including 4) [1 2 3] 12.4.6.3 2-Dimension Indexing with [ row_positoins, row_positions ], index starts with 0 x[1:3, 1:4] # row 1 to 2 column 1 to 3 array([[1, 2, 3]]) 12.4.7 Attributes 12.4.7.1 dtype ndarray contain a property called dtype, whcih tell us the type of underlying items a = np.array( (1,2,3,4,5), dtype=&#39;float&#39; ) a.dtype dtype(‘float64’) print(a.dtype) float64 print( type(a[1])) &lt;class ‘numpy.float64’&gt; 12.4.7.2 dim dim returns the number of dimensions of the NumPy array. Example below shows 2-D array x = np.array(( (1,2,3,4,5), (11,12,13,14,15), (21,22,23,24,25))) x.ndim 2 12.4.7.3 shape shape return a type of (rows, cols) x = np.array(( (1,2,3,4,5), (11,12,13,14,15), (21,22,23,24,25))) x.shape (3, 5) np.identity(5) array([[1., 0., 0., 0., 0.], [0., 1., 0., 0., 0.], [0., 0., 1., 0., 0.], [0., 0., 0., 1., 0.], [0., 0., 0., 0., 1.]]) 12.4.8 Operations 12.4.8.1 Arithmetic Sample Date ar = np.arange(10) print( ar ) [0 1 2 3 4 5 6 7 8 9] * ar = np.arange(10) print (ar) [0 1 2 3 4 5 6 7 8 9] print (ar*2) [ 0 2 4 6 8 10 12 14 16 18] **+ and -** ar = np.arange(10) print (ar+2) [ 2 3 4 5 6 7 8 9 10 11] print (ar-2) [-2 -1 0 1 2 3 4 5 6 7] 12.4.8.2 Comparison Sample Data ar = np.arange(10) print( ar ) [0 1 2 3 4 5 6 7 8 9] == print( ar==3 ) [False False False True False False False False False False] &gt;, &gt;=, &lt;, &lt;= print( ar&gt;3 ) [False False False False True True True True True True] print( ar&lt;=3 ) [ True True True True False False False False False False] 12.5 Random Numbers 12.5.1 Uniform Distribution 12.5.1.1 Random Integer (with Replacement) randint() Return random integers from low (inclusive) to high (exclusive) np.random.randint( low ) # generate an integer, i, which i &lt; low np.random.randint( low, high ) # generate an integer, i, which low &lt;= i &lt; high np.random.randint( low, high, size=1) # generate an ndarray of integer, single dimension np.random.randint( low, high, size=(r,c)) # generate an ndarray of integer, two dimensions np.random.randint( 10 ) 9 np.random.randint( 10, 20 ) 19 np.random.randint( 10, high=20, size=5) # single dimension array([13, 15, 17, 14, 16]) np.random.randint( 10, 20, (3,5) ) # two dimensions array([[16, 11, 12, 14, 16], [17, 14, 13, 17, 12], [19, 13, 19, 11, 10]]) 12.5.1.2 Random Integer (with or without replacement) numpy.random .choice( a, size, replace=True) # sampling from a, # if a is integer, then it is assumed sampling from arange(a) # if a is an 1-D array, then sampling from this array np.random.choice(10,5, replace=False) # take 5 samples from 0:19, without replacement array([7, 8, 9, 5, 3]) np.random.choice( np.arange(10,20), 5, replace=False) array([14, 19, 15, 13, 16]) 12.5.1.3 Random Float randf() Generate float numbers in between 0.0 and 1.0 np.random.ranf(size=None) np.random.ranf(4) array([0.48214304, 0.93009409, 0.97368948, 0.55016102]) uniform() Return random float from low (inclusive) to high (exclusive) np.random.uniform( low ) # generate an float, i, which f &lt; low np.random.uniform( low, high ) # generate an float, i, which low &lt;= f &lt; high np.random.uniform( low, high, size=1) # generate an array of float, single dimension np.random.uniform( low, high, size=(r,c)) # generate an array of float, two dimensions np.random.uniform( 2 ) 1.260274240861766 np.random.uniform( 2,5, size=(4,4) ) array([[3.62051119, 4.51235222, 3.83553729, 2.40912924], [2.74878384, 4.65846879, 4.09580402, 2.67386628], [3.72611866, 4.34786699, 3.60266092, 2.75219597], [3.91618416, 2.81032814, 4.80920227, 3.78112933]]) 12.5.2 Normal Distribution numpy. random.randn (n_items) # 1-D standard normal (mean=0, stdev=1) numpy. random.randn (nrows, ncols) # 2-D standard normal (mean=0, stdev=1) numpy. random.standard_normal( size=None ) # default to mean = 0, stdev = 1, non-configurable numpy. random.normal ( loc=0, scale=1, size=None) # loc = mean, scale = stdev, size = dimension 12.5.2.1 Standard Normal Distribution Generate random normal numbers with gaussion distribution (mean=0, stdev=1) One Dimension np.random.standard_normal(3) array([-0.99683893, 0.29187804, -1.5318888 ]) np.random.randn(3) array([-0.35596143, -1.08946971, -1.07748668]) Two Dimensions np.random.randn(2,4) array([[-0.22682334, 0.86688802, -1.26069151, -0.8530729 ], [-0.44810396, -0.16790092, 2.42268003, 0.40942539]]) np.random.standard_normal((2,4)) array([[ 1.76749815, 0.75525878, 0.46844962, -0.98046484], [ 1.34776075, -0.29722393, 1.6827465 , 0.13634213]]) Observe: randn(), standard_normal() and normal() are able to generate standard normal numbers np.random.seed(15) print (np.random.randn(5)) [-0.31232848 0.33928471 -0.15590853 -0.50178967 0.23556889] np.random.seed(15) print (np.random.normal ( size = 5 )) # stdev and mean not specified, default to standard normal [-0.31232848 0.33928471 -0.15590853 -0.50178967 0.23556889] np.random.seed(15) print (np.random.standard_normal (size=5)) [-0.31232848 0.33928471 -0.15590853 -0.50178967 0.23556889] 12.5.2.2 Normal Distribution (Non-Standard) np.random.seed(125) np.random.normal( loc = 12, scale=1.25, size=(3,3)) array([[11.12645382, 12.01327885, 10.81651695], [12.41091248, 12.39383072, 11.49647195], [ 8.70837035, 12.25246312, 11.49084235]]) 12.5.2.3 Linear Spacing numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None) # endpoint: If True, stop is the last sample, otherwise it is not included Include Endpoint Step = Gap divide by (number of elements minus 1) (2/(10-1)) np.linspace(1,3,10) #default endpont=True array([1. , 1.22222222, 1.44444444, 1.66666667, 1.88888889, 2.11111111, 2.33333333, 2.55555556, 2.77777778, 3. ]) Does Not Include Endpoint Step = Gap divide by (number of elements minus 1) (2/(101)) np.linspace(1,3,10,endpoint=False) array([1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4, 2.6, 2.8]) 12.6 Sampling (Integer) random.choice( a, size=None, replace=True, p=None) # a=integer, return &lt;size&gt; integers &lt; a random.choice( a, size=None, replace=True, p=None) # a=array-like, return &lt;size&gt; integers picked from list a np.random.choice (100, size=10) array([58, 0, 84, 50, 89, 32, 87, 30, 66, 92]) np.random.choice( [1,3,5,7,9,11,13,15,17,19,21,23], size=10, replace=False) array([ 5, 1, 23, 17, 3, 13, 15, 9, 21, 7]) 12.7 NaN : Missing Numerical Data You should be aware that NaN is a bit like a data virus?it infects any other object it touches t = np.array([1, np.nan, 3, 4]) t.dtype dtype(‘float64’) Regardless of the operation, the result of arithmetic with NaN will be another NaN 1 + np.nan nan t.sum(), t.mean(), t.max() (nan, nan, nan) np.nansum(t), np.nanmean(t), np.nanmax(t) (8.0, 2.6666666666666665, 4.0) "],
["pandas-1.html", "13 pandas 13.1 Environment Setup 13.2 Modules Import 13.3 Pandas Objects 13.4 Class Method 13.5 Timestamp 13.6 Series 13.7 DataFrame 13.8 Categories 13.9 Dummies 13.10 Getting External Data 13.11 GroupBy 13.12 Concat 13.13 Fundamental Analysis 13.14 Missing Data 13.15 Pandas DateTime 13.16 DateTimeIndex", " 13 pandas 13.1 Environment Setup from IPython.core.display import display, HTML display(HTML(&quot;&lt;style&gt;.container { width:70% !important; margin-left:350px; }&lt;/style&gt;&quot;)) &lt;IPython.core.display.HTML object&gt; 13.2 Modules Import import pandas as pd ## Other Libraries import numpy as np import datetime as dt from datetime import datetime from datetime import date 13.2.1 Display Setup It is good idea to configure output setup as prefered pd.set_option( &#39;display.notebook_repr_html&#39;, False) # render Series and DataFrame as text, not HTML pd.set_option( &#39;display.max_column&#39;, 10) # number of columns pd.set_option( &#39;display.max_rows&#39;, 10) # number of rows pd.set_option( &#39;display.width&#39;, 80) # number of characters per row 13.3 Pandas Objects 13.3.1 Pandas Data Types pandas.Timestamp pandas.Timedelta pandas.Period pandas.Interval pandas.DateTimeIndex 13.3.2 Pandas Data Structure Type Dimension Size Value Constructor Series 1 Immutable Mutable pandas.DataFrame( data, index, dtype, copy) DataFrame 2 Mutable Mutable pandas.DataFrame( data, index, columns, dtype, copy) Panel 3 Mutable Mutable data can be ndarray, list, constants index must be unique and same length as data. Can be integer or string dtype if none, it will be inferred copy copy data. Default false 13.4 Class Method 13.4.1 Conversion: to_datetime() Source can be string, date, datetime object 13.4.1.1 From List to DateTimeIndex dti = pd.to_datetime([&#39;2011-01-03&#39;, # from string date(2018,4,13), # from date datetime(2018,3,1,7,30)] # from datetime ) print(dti) DatetimeIndex([‘2011-01-03 00:00:00’, ‘2018-04-13 00:00:00’, ‘2018-03-01 07:30:00’], dtype=‘datetime64[ns]’, freq=None) print(&#39;\\nObject Type: &#39;,type(dti)) Object Type: &lt;class ‘pandas.core.indexes.datetimes.DatetimeIndex’&gt; print(&#39;Object dtype: &#39;, dti.dtype) Object dtype: datetime64[ns] print(&#39;\\nElement Type: &#39;,type(dti[1])) Element Type: &lt;class ‘pandas._libs.tslibs.timestamps.Timestamp’&gt; 13.4.1.2 From List to Series to Series sdt = pd.to_datetime(pd.Series([&#39;2011-01-03&#39;, # from string date(2018,4,13), # from date datetime(2018,3,1,7,30)]# from datetime )) print(sdt) 0 2011-01-03 00:00:00 1 2018-04-13 00:00:00 2 2018-03-01 07:30:00 dtype: datetime64[ns] print(&#39;\\nObject Type: &#39;,type(sdt)) Object Type: &lt;class ‘pandas.core.series.Series’&gt; print(&#39;Object dtype: &#39;, sdt.dtype) Object dtype: datetime64[ns] print(&#39;\\nElement Type: &#39;,type(sdt[1])) Element Type: &lt;class ‘pandas._libs.tslibs.timestamps.Timestamp’&gt; 13.4.1.3 From Scalar to Timestamp print( pd.to_datetime(&#39;2011-01-03&#39;)) # from string 2011-01-03 00:00:00 print( pd.to_datetime(date(2011,1,3))) # from date 2011-01-03 00:00:00 print( pd.to_datetime(datetime(2011,1,3,5,30))) # from datetime 2011-01-03 05:30:00 print(&#39;\\nElement Type: &#39;, type(pd.to_datetime(datetime(2011,1,3,5,30)))) Element Type: &lt;class ‘pandas._libs.tslibs.timestamps.Timestamp’&gt; 13.4.2 Generate Timestamp Sequence 13.4.2.1 date_range() Return DateTimeIndex object Generate sequence of HOURS ## Specify start, Periods, Frequency ## Start from Date Only pd.date_range(&#39;2018-01-01&#39;, periods=3, freq=&#39;H&#39;) DatetimeIndex([‘2018-01-01 00:00:00’, ‘2018-01-01 01:00:00’, ‘2018-01-01 02:00:00’], dtype=‘datetime64[ns]’, freq=‘H’) ## Start from DateTime dti = pd.date_range(datetime(2018,1,1,12,30), periods=3, freq=&#39;H&#39;) print(dti) DatetimeIndex([‘2018-01-01 12:30:00’, ‘2018-01-01 13:30:00’, ‘2018-01-01 14:30:00’], dtype=‘datetime64[ns]’, freq=‘H’) print(type(dti)) &lt;class ‘pandas.core.indexes.datetimes.DatetimeIndex’&gt; print(dti.dtype) datetime64[ns] print(type(dti[1])) &lt;class ‘pandas._libs.tslibs.timestamps.Timestamp’&gt; ## Specify start, End and Frequency dti = pd.date_range(start=&#39;2018-01-03-1230&#39;, end=&#39;2018-01-03-18:30&#39;, freq=&#39;H&#39;) print(dti) DatetimeIndex([‘2018-01-03 12:30:00’, ‘2018-01-03 13:30:00’, ‘2018-01-03 14:30:00’, ‘2018-01-03 15:30:00’, ‘2018-01-03 16:30:00’, ‘2018-01-03 17:30:00’, ‘2018-01-03 18:30:00’], dtype=‘datetime64[ns]’, freq=‘H’) Generate sequence of DAYS pd.date_range(date(2018,1,2), periods=3, freq=&#39;D&#39;) DatetimeIndex([‘2018-01-02’, ‘2018-01-03’, ‘2018-01-04’], dtype=‘datetime64[ns]’, freq=‘D’) pd.date_range(&#39;2018-01-01-1230&#39;, periods=4, freq=&#39;D&#39;) DatetimeIndex([‘2018-01-01 12:30:00’, ‘2018-01-02 12:30:00’, ‘2018-01-03 12:30:00’, ‘2018-01-04 12:30:00’], dtype=‘datetime64[ns]’, freq=‘D’) Generate sequence of Start of Month pd.date_range(&#39;2018-01&#39;, periods=4, freq=&#39;MS&#39;) DatetimeIndex([‘2018-01-01’, ‘2018-02-01’, ‘2018-03-01’, ‘2018-04-01’], dtype=‘datetime64[ns]’, freq=‘MS’) pd.date_range(datetime(2018,1,3,12,30), periods=4, freq=&#39;MS&#39;) DatetimeIndex([‘2018-02-01 12:30:00’, ‘2018-03-01 12:30:00’, ‘2018-04-01 12:30:00’, ‘2018-05-01 12:30:00’], dtype=‘datetime64[ns]’, freq=‘MS’) Generate sequence of End of Month dti = pd.date_range(&#39;2018-02&#39;, periods=4, freq=&#39;M&#39;) dti DatetimeIndex([‘2018-02-28’, ‘2018-03-31’, ‘2018-04-30’, ‘2018-05-31’], dtype=‘datetime64[ns]’, freq=‘M’) 13.4.3 Frequency Table (crosstab) crosstab returns Dataframe Object crosstab( index = &lt;SeriesObj&gt;, columns = &lt;new_colName&gt; ) # one dimension table crosstab( index = &lt;SeriesObj&gt;, columns = &lt;SeriesObj&gt; ) # two dimension table crosstab( index = &lt;SeriesObj&gt;, columns = [&lt;SeriesObj1&gt;, &lt;SeriesObj2&gt;] ) # multi dimension table crosstab( index = &lt;SeriesObj&gt;, columns = &lt;SeriesObj&gt;, margines=True ) # add column and row margins 13.4.3.1 Sample Data n = 200 comp = [&#39;C&#39; + i for i in np.random.randint( 1,4, size = n).astype(str)] # 3x Company dept = [&#39;D&#39; + i for i in np.random.randint( 1,6, size = n).astype(str)] # 5x Department grp = [&#39;G&#39; + i for i in np.random.randint( 1,3, size = n).astype(str)] # 2x Groups value1 = np.random.normal( loc=50 , scale=5 , size = n) value2 = np.random.normal( loc=20 , scale=3 , size = n) value3 = np.random.normal( loc=5 , scale=30 , size = n) mydf = pd.DataFrame({ &#39;comp&#39;:comp, &#39;dept&#39;:dept, &#39;grp&#39;: grp, &#39;value1&#39;:value1, &#39;value2&#39;:value2, &#39;value3&#39;:value3 }) mydf.head() comp dept grp value1 value2 value3 0 C1 D2 G2 63.434839 24.762085 14.037684 1 C3 D2 G1 48.319613 18.965650 -30.215550 2 C2 D1 G1 52.776620 21.003838 49.610150 3 C3 D5 G1 44.648475 23.730746 20.963278 4 C2 D5 G2 45.309311 16.353753 15.269688 13.4.3.2 One DimensionTable print( pd.crosstab(index=mydf.comp, columns=&#39;counter&#39;) ) col_0 counter comp C1 76 C2 57 C3 67 type ( pd.crosstab(index=mydf.comp, columns=&#39;counter&#39;)) &lt;class ‘pandas.core.frame.DataFrame’&gt; 13.4.3.3 Two Dimension Table pd.crosstab(index=mydf.comp, columns=mydf.dept) dept D1 D2 D3 D4 D5 comp C1 19 20 12 12 13 C2 11 17 10 7 12 C3 11 14 13 13 16 13.4.3.4 Higher Dimension Table tb = pd.crosstab(index=mydf.comp, columns=[mydf.dept, mydf.grp]) print( tb ) dept D1 D2 D3 D4 D5 grp G1 G2 G1 G2 G1 G2 G1 G2 G1 G2 comp C1 10 9 9 11 3 9 4 8 9 4 C2 4 7 7 10 4 6 5 2 2 10 C3 3 8 5 9 3 10 6 7 9 7 tb.columns MultiIndex(levels=[[‘D1’, ‘D2’, ‘D3’, ‘D4’, ‘D5’], [‘G1’, ‘G2’]], labels=[[0, 0, 1, 1, 2, 2, 3, 3, 4, 4], [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]], names=[‘dept’, ‘grp’]) Get the subdataframe under D2 tb[&#39;D2&#39;] grp G1 G2 comp C1 9 11 C2 7 10 C3 5 9 13.4.3.5 Getting Margin Sum of each row and each column is created at the end. tb = pd.crosstab(index=mydf.dept, columns=mydf.grp, margins=True) tb grp G1 G2 All dept D1 17 24 41 D2 21 30 51 D3 10 25 35 D4 15 17 32 D5 20 21 41 All 83 117 200 print(tb.loc[:,&#39;All&#39;] ) # row total, return a Series dept D1 41 D2 51 D3 35 D4 32 D5 41 All 200 Name: All, dtype: int64 print(type(tb.loc[:,&#39;All&#39;])) &lt;class ‘pandas.core.series.Series’&gt; print(tb.loc[&#39;All&#39;]) # column total, return a Series grp G1 83 G2 117 All 200 Name: All, dtype: int64 print(type(tb.loc[&#39;All&#39;])) &lt;class ‘pandas.core.series.Series’&gt; 13.4.3.6 Getting Proportion Use matrix operation divide for each cells over the margin tb/tb.loc[&#39;All&#39;] grp G1 G2 All dept D1 0.204819 0.205128 0.205 D2 0.253012 0.256410 0.255 D3 0.120482 0.213675 0.175 D4 0.180723 0.145299 0.160 D5 0.240964 0.179487 0.205 All 1.000000 1.000000 1.000 13.4.3.7 Reseting Index When creating a crosstab, column specified by index will become index To convert it to normal column, use reset_index() DataFrameObj.reset_index( inpalce=False ) 13.5 Timestamp This is an enhanced version to datetime standard library. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html#pandas.Timestamp 13.5.1 Constructor 13.5.1.1 From Number print( pd.Timestamp(year=2017, month=1, day=1) ) #date-like numbers 2017-01-01 00:00:00 print( pd.Timestamp(2017,1,1) ) # date-like numbers 2017-01-01 00:00:00 print( pd.Timestamp(2017,12,11,5,45)) # datetime-like numbers 2017-12-11 05:45:00 print( pd.Timestamp(2017,12,11,5,45,55,999)) # + microseconds 2017-12-11 05:45:55.000999 print( pd.Timestamp(2017,12,11,5,45,55,999,8)) # + nanoseconds 2017-12-11 05:45:55.000999008 print( type(pd.Timestamp(2017,12,11,5,45,55,999,8))) &lt;class ‘pandas._libs.tslibs.timestamps.Timestamp’&gt; 13.5.1.2 From String Observe that pandas support many string input format Year Month Day, default no timezone print( pd.Timestamp(&#39;2017-12-11&#39;)) # date-like string: year-month-day 2017-12-11 00:00:00 print( pd.Timestamp(&#39;2017 12 11&#39;)) # date-like string: year-month-day 2017-12-11 00:00:00 print( pd.Timestamp(&#39;2017 Dec 11&#39;)) # date-like string: year-month-day 2017-12-11 00:00:00 print( pd.Timestamp(&#39;Dec 11, 2017&#39;)) # date-like string: year-month-day 2017-12-11 00:00:00 YMD Hour Minute Second Ms print( pd.Timestamp(&#39;2017-12-11 0545&#39;)) ## hour minute 2017-12-11 05:45:00 print( pd.Timestamp(&#39;2017-12-11-05:45&#39;)) 2017-12-11 05:45:00 print( pd.Timestamp(&#39;2017-12-11T0545&#39;)) 2017-12-11 05:45:00 print( pd.Timestamp(&#39;2017-12-11 054533&#39;)) ## hour minute seconds 2017-12-11 05:45:33 print( pd.Timestamp(&#39;2017-12-11 05:45:33&#39;)) 2017-12-11 05:45:33 Timezone print( pd.Timestamp(&#39;2017-01-01T0545Z&#39;)) # GMT 2017-01-01 05:45:00+00:00 print( pd.Timestamp(&#39;2017-01-01T0545+9&#39;)) # GMT+9 2017-01-01 05:45:00+09:00 print( pd.Timestamp(&#39;2017-01-01T0545+0800&#39;)) # GMT+0800 2017-01-01 05:45:00+08:00 13.5.1.3 From Standard Library datetime and date Object print( pd.Timestamp(date(2017,3,5)) ) # from date 2017-03-05 00:00:00 print( pd.Timestamp(datetime(2017,3,5,4,30))) # from datetime 2017-03-05 04:30:00 print( pd.Timestamp(datetime(2017,3,5,4,30), tz=&#39;Asia/Kuala_Lumpur&#39;)) # from datetime, + tz 2017-03-05 04:30:00+08:00 13.5.2 Attributes ts = pd.Timestamp(&#39;2017-01-01T054533+0800&#39;) # GMT+0800 print( ts.month ) 1 print( ts.day ) 1 print( ts.year ) 2017 print( ts.hour ) 5 print( ts.minute) 45 print( ts.second) 33 print( ts.microsecond) 0 print( ts.nanosecond) 0 print( ts.tz) pytz.FixedOffset(480) ts1 = pd.Timestamp(datetime(2017,3,5,4,30), tz=&#39;Asia/Kuala_Lumpur&#39;) # from datetime, + tz ts2 = pd.Timestamp(&#39;2017-01-01T054533+0800&#39;) # GMT+0800 ts3 = pd.Timestamp(&#39;2017-01-01T0545&#39;) print( ts1.tz ) Asia/Kuala_Lumpur print( ts2.tz ) pytz.FixedOffset(480) print( ts3.tz ) None 13.5.3 Operator 13.5.4 Instance Methods 13.5.4.1 Useful Methods ts = pd.Timestamp(2017,1,1) print( ts.weekday() ) 6 print( ts.isoweekday() ) 7 13.5.4.2 Convert To datetime Use to_pydatetime() to convert into standard library datetime.datetime, optionally to datetime.date ts = pd.Timestamp(2017,1,10,7,30,52) # to datetime.datetime ts.to_pydatetime() datetime.datetime(2017, 1, 10, 7, 30, 52) ts = pd.Timestamp(2017,1,10,7,30,52) # to datetime.date ts.to_pydatetime().date() datetime.date(2017, 1, 10) 13.5.4.3 Convert To numpy Use to_datetime64() to convert into numpy.datetime64 ts = pd.Timestamp(2017,1,10,7,30,52) ts.to_datetime64() numpy.datetime64(‘2017-01-10T07:30:52.000000000’) 13.5.4.4 Formatting with strftime Use strftime() to customize string format. For complete directive, see below: https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior ts = pd.Timestamp(2017,1,10,7,30,52) ts.strftime(&quot;%m/%d&quot;) ‘01/10’ 13.5.4.5 Add Timezone Add timezone to tz-naive or tz-non-existance object. Clock will not be shifted as there is no original offset ts = pd.Timestamp(2017,1,10,10,34) ## No timezone ts = ts.tz_localize(&#39;Asia/Kuala_Lumpur&#39;) ## Add timezone ts Timestamp(‘2017-01-10 10:34:00+0800’, tz=‘Asia/Kuala_Lumpur’) 13.5.4.6 Convert Timezone Convert timezone to tz-aware object. The clock will be shifted according to the offset ts = pd.Timestamp(2017,1,10,10,34) ## No timezone ts = ts.tz_localize(&#39;Asia/Kuala_Lumpur&#39;) ## Add timezone ts = ts.tz_convert(&#39;UTC&#39;) ## Convert timezone ts Timestamp(‘2017-01-10 02:34:00+0000’, tz=‘UTC’) 13.5.4.7 Removing TImezone ts = pd.Timestamp(2017,1,10,10,34) ## No timezone ts = ts.tz_localize(&#39;Asia/Kuala_Lumpur&#39;) ## Add timezone ts = ts.tz_localize(None) ## Convert timezone ts Timestamp(‘2017-01-10 10:34:00’) 13.5.4.8 Formatting with isoformat Use isoformat() to format ISO string (without timezone) ts.isoformat() ‘2017-01-10T10:34:00’ 13.5.4.9 ceil print( ts.ceil(freq=&#39;D&#39;) ) # ceiling to day 2017-01-11 00:00:00 13.5.4.10 replace() ts.replace(year=2000, month=1,day=1) Timestamp(‘2000-01-01 10:34:00’) 13.6 Series Series allows different data types (object class) as its element 13.6.1 Constructor 13.6.1.1 Empty Series Passing empty parameter result in empty series s = pd.Series() print (s) Series([], dtype: float64) type(s) &lt;class ‘pandas.core.series.Series’&gt; 13.6.1.2 From Scalar If data is a scalar value, an index must be provided. The value will be repeated to match the length of index pd.Series( 99, index = [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;]) a 99 b 99 c 99 d 99 dtype: int64 13.6.1.3 From array-like From list pd.Series([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;]) # from Python list 0 a 1 b 2 c 3 d 4 e dtype: object From numpy.array If index is not specified, default to 0 and continue incrementally pd.Series(np.array([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;])) # from np.array 0 a 1 b 2 c 3 d 4 e dtype: object From DateTimeIndex dti = pd.date_range(&#39;2011-1-1&#39;,&#39;2011-1-3&#39;) dti DatetimeIndex([‘2011-01-01’, ‘2011-01-02’, ‘2011-01-03’], dtype=‘datetime64[ns]’, freq=‘D’) pd.Series(pd.date_range(&#39;2011-1-1&#39;,&#39;2011-1-3&#39;)) 0 2011-01-01 1 2011-01-02 2 2011-01-03 dtype: datetime64[ns] 13.6.1.4 From Dictionary The dictionary key will be the index If index sequence is not specified, then the Series will be automatically sorted according to the key pd.Series({&#39;a&#39; : 0., &#39;c&#39; : 1., &#39;b&#39; : 2.}) # from Python dict, autosort by default key a 0.0 c 1.0 b 2.0 dtype: float64 If index sequence is specifeid, then Series will forllow the index order Objerve that missing data (index without value) will be marked as NaN pd.Series({&#39;a&#39; : 0., &#39;c&#39; : 1., &#39;b&#39; : 2.},index = [&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;]) # from Python Dict, index specified, no auto sort a 0.0 b 2.0 c 1.0 d NaN dtype: float64 13.6.1.5 Specify Index pd.Series([&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;], index=[10,20,30,40,50]) 10 a 20 b 30 c 40 d 50 e dtype: object 13.6.1.6 Mix Element Types dType will be ‘object’ when there were mixture of classes ser = pd.Series([&#39;a&#39;,1,2,3]) print(&#39;Object Type : &#39;, type(ser)) Object Type : &lt;class ‘pandas.core.series.Series’&gt; print(&#39;Object dType: &#39;, ser.dtype) Object dType: object print(&#39;Element 1 Type: &#39;,type(ser[0])) Element 1 Type: &lt;class ‘str’&gt; print(&#39;Elmeent 2 Type: &#39;,type(ser[1])) Elmeent 2 Type: &lt;class ‘int’&gt; 13.6.1.7 Specify Data Types ser1 = pd.Series([1,2,3]) ser2 = pd.Series([1,2,3], dtype=&quot;int8&quot;) ser3 = pd.Series([1,2,3], dtype=&quot;object&quot;) print(ser1, ser1.dtype) 0 1 1 2 2 3 dtype: int64 int64 print(ser2, ser2.dtype) 0 1 1 2 2 3 dtype: int8 int8 print(ser3, ser3.dtype) 0 1 1 2 2 3 dtype: object object 13.6.2 Accessing Series series ( single/list/range_of_row_label/number ) # can cause confusion series.loc ( single/list/range_of_row_label ) series.iloc( single/list/range_of_row_number ) 13.6.2.1 Sample Data s = pd.Series([1,2,3,4,5],index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;]) s a 1 b 2 c 3 d 4 e 5 dtype: int64 13.6.2.2 by Row Number(s) Single Item s.iloc[1] 2 Multiple Items s.iloc[[1,3]] b 2 d 4 dtype: int64 Range (First 3) s.iloc[:3] a 1 b 2 c 3 dtype: int64 Range (Last 3) s.iloc[-3:] c 3 d 4 e 5 dtype: int64 Range (in between) s.iloc[2:3] c 3 dtype: int64 13.6.2.3 by Index(es) Single Label s.loc[&#39;c&#39;] # or ... s[[&#39;c&#39;]] 3 Multiple Labels s.loc[[&#39;b&#39;,&#39;c&#39;]] b 2 c 3 dtype: int64 ** Range of Labels ** s.loc[&#39;b&#39;:&#39;d&#39;] b 2 c 3 d 4 dtype: int64 13.6.2.4 Filtering Criteria Use logical array to filter s = pd.Series(range(1,8)) s[s&lt;5] 0 1 1 2 2 3 3 4 dtype: int64 Use logical array with where s.where(s&gt;4) 0 NaN 1 NaN 2 NaN 3 NaN 4 5.0 5 6.0 6 7.0 dtype: float64 s.where(s&gt;4,None) 0 None 1 None 2 None 3 None 4 5 5 6 6 7 dtype: object 13.6.3 Modifying Series 13.6.3.1 by Row Number(s) s = pd.Series(range(1,7), index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;]) s[2] = 999 s[[3,4]] = 888,777 s a 1 b 2 c 999 d 888 e 777 f 6 dtype: int64 13.6.3.2 by Index(es) s = pd.Series(range(1,7), index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;]) s[&#39;e&#39;] = 888 s[[&#39;c&#39;,&#39;d&#39;]] = 777,888 s a 1 b 2 c 777 d 888 e 888 f 6 dtype: int64 13.6.4 Series Attributes 13.6.4.1 The Data s = pd.Series([1,2,3,4,5],index=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;],name=&#39;SuperHero&#39;) 13.6.4.2 index s.index Index([‘a’, ‘b’, ‘c’, ‘d’, ‘e’], dtype=‘object’) 13.6.4.3 dtype s.dtype dtype(‘int64’) 13.6.4.4 Dimensions print(s) a 1 b 2 c 3 d 4 e 5 Name: SuperHero, dtype: int64 print( s.size ) 5 print( s.shape ) (5,) print( s.ndim ) 1 13.6.4.5 .name s.name ‘SuperHero’ 13.6.5 Instance Methods 13.6.5.1 .reset_index () Resetting index will: - Convert index to a normal column, header is ‘index’ - Index renumbered to ,1,2,3 - Retrun DataFrame (became two columns) print(s) a 1 b 2 c 3 d 4 e 5 Name: SuperHero, dtype: int64 print(s.reset_index()) index SuperHero 0 a 1 1 b 2 2 c 3 3 d 4 4 e 5 13.6.5.2 Structure Conversion Use values() to convert into `numpy.ndarray type(s.values) &lt;class ‘numpy.ndarray’&gt; Use to_list() to convert into standard python `list ## 13.6.5.3 DataType Conversion Use astype() to convert to another numpy supproted datatypes Warning: casting to incompatible type will result in error ser = pd.Series([1, 2], dtype=&#39;int32&#39;) ser 0 1 1 2 dtype: int32 ser.astype(&#39;int8&#39;) 0 1 1 2 dtype: int8 13.6.6 Series Operators The result of applying operator (arithmetic or logic) to Series object returns a new Series object 13.6.6.1 Arithmetic Operator s1 = pd.Series( [100,200,300,400,500] ) s2 = pd.Series( [10, 20, 30, 40, 50] ) Apply To One Series Object 100 - s2 0 90 1 80 2 70 3 60 4 50 dtype: int64 Apply To Two Series Objects s1 - s2 0 90 1 180 2 270 3 360 4 450 dtype: int64 13.6.6.2 Logic Operator Apply logic operator to a Series return a new Series of boolean result This can be used for Series or DataFrame filtering bs = pd.Series(range(0,10)) bs 0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 dtype: int64 print (bs&gt;3) 0 False 1 False 2 False 3 False 4 True 5 True 6 True 7 True 8 True 9 True dtype: bool print (type (bs&gt;3)) &lt;class ‘pandas.core.series.Series’&gt; ~((bs&gt;3) &amp; (bs&lt;8)) 0 True 1 True 2 True 3 True 4 False 5 False 6 False 7 False 8 True 9 True dtype: bool 13.6.7 Series String Accesor .str If the underlying data is str type, then pandas exposed various properties and methos through str accessor. This chapter focus on various functions that can be applied to entire Series data SeriesObj.str.operatorFunction() Pandas str Method Nearly all Python’s built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas str methods that mirror Python string methods: len() lower() translate() islower() ljust() upper() startswith() isupper() rjust() find() endswith() isnumeric() center() rfind() isalnum() isdecimal() zfill() index() isalpha() split() strip() rindex() isdigit() rsplit() rstrip() capitalize() isspace() partition() lstrip() swapcase() istitle() rpartition() 13.6.7.1 Splitting s = pd.Series([&#39;a_b_c&#39;, &#39;c_d_e&#39;, np.nan, &#39;f_g_h_i_j&#39;]) s 0 a_b_c 1 c_d_e 2 NaN 3 f_g_h_i_j dtype: object str.split() By default, split will split the string into array s.str.split(&#39;_&#39;) 0 [a, b, c] 1 [c, d, e] 2 NaN 3 [f, g, h, i, j] dtype: object After split, select rows to return print( s.str.split(&#39;_&#39;).get(1) ) [‘c’, ‘d’, ‘e’] print( s.str.split(&#39;_&#39;)[1] ) [‘c’, ‘d’, ‘e’] str.split( expand=True, n= ) split and expand=True will return a dataframe instead of series print( s.str.split(&#39;_&#39;, expand=True) ) 0 1 2 3 4 0 a b c None None 1 c d e None None 2 NaN NaN NaN NaN NaN 3 f g h i j It is possible to limit the number of columns splitted print( s.str.split(&#39;_&#39;, expand=True, n=1) ) 0 1 0 a b_c 1 c d_e 2 NaN NaN 3 f g_h_i_j str.rsplit() rsplit stands for reverse split, it works the same way, except it is reversed print( s.str.rsplit(&#39;_&#39;, expand=True, n=1) ) 0 1 0 a_b c 1 c_d e 2 NaN NaN 3 f_g_h_i j 13.6.7.2 Matching monte = pd.Series([&#39;Graham Chapman&#39;, &#39;John Cleese&#39;, &#39;Terry Gilliam&#39;, &#39;Eric Idle&#39;, &#39;Terry Jones&#39;, &#39;Michael Palin&#39;]) monte 0 Graham Chapman 1 John Cleese 2 Terry Gilliam 3 Eric Idle 4 Terry Jones 5 Michael Palin dtype: object startwith monte.str.startswith(&#39;T&#39;) 0 False 1 False 2 True 3 False 4 True 5 False dtype: bool monte.str.split() 0 [Graham, Chapman] 1 [John, Cleese] 2 [Terry, Gilliam] 3 [Eric, Idle] 4 [Terry, Jones] 5 [Michael, Palin] dtype: object Slicing monte.str[0:3] 0 Gra 1 Joh 2 Ter 3 Eri 4 Ter 5 Mic dtype: object monte.str[0:-1] 0 Graham Chapma 1 John Clees 2 Terry Gillia 3 Eric Idl 4 Terry Jone 5 Michael Pali dtype: object s = pd.Series([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;Aaba&#39;, &#39;Baca&#39;, np.nan, &#39;CABA&#39;, &#39;dog&#39;, &#39;cat&#39;]) 13.6.7.3 Case Conversion SeriesObj.str.upper() SeriesObj.str.lower() s.str.upper() 0 A 1 B 2 C 3 AABA 4 BACA 5 NaN 6 CABA 7 DOG 8 CAT dtype: object 13.6.7.4 Number of Characters s.str.len() 0 1.0 1 1.0 2 1.0 3 4.0 4 4.0 5 NaN 6 4.0 7 3.0 8 3.0 dtype: float64 d=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] names = pd.Series(data=d) names.str.capitalize() 0 A 1 B 2 C dtype: object 13.6.7.5 String Indexing s = pd.Series([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;Aaba&#39;, &#39;Baca&#39;, np.nan,&#39;CABA&#39;, &#39;dog&#39;, &#39;cat&#39;]) s 0 A 1 B 2 C 3 Aaba 4 Baca 5 NaN 6 CABA 7 dog 8 cat dtype: object s.str[1] # return char-1 (second char) of every item 0 NaN 1 NaN 2 NaN 3 a 4 a 5 NaN 6 A 7 o 8 a dtype: object 13.6.7.6 Splitting Sample Data s = pd.Series([&#39;a_b_c&#39;, &#39;c_d_e&#39;, np.nan, &#39;f_g_h&#39;]) Splitting base on a a delimieter Result is a SeriesObj with list of splitted characters sp = s.str.split(&#39;_&#39;) sp 0 [a, b, c] 1 [c, d, e] 2 NaN 3 [f, g, h] dtype: object Retrieving Split Result Use .str.get() to retrieve splitted elments sp.str.get(-1) 0 c 1 e 2 NaN 3 h dtype: object Alternatively, use str[ ] for the same result sp.str[-1] 0 c 1 e 2 NaN 3 h dtype: object 13.6.7.7 Split and Expand Into DataFrame s.str.split(&#39;_&#39;,expand=True, n=5) # limit expansion into n columns 0 1 2 0 a b c 1 c d e 2 NaN NaN NaN 3 f g h 13.6.7.8 Series Substring Extraction Sample Data s = pd.Series([&#39;a1&#39;, &#39;b2&#39;, &#39;c3&#39;]) s 0 a1 1 b2 2 c3 dtype: object Extract absed on regex matching … to improve … type(s.str.extract(&#39;([ab])(\\d)&#39;, expand=False)) &lt;class ‘pandas.core.frame.DataFrame’&gt; 13.6.8 Series DateTime Accessor .dt If the underlying data is datetime64 type, then pandas exposed various properties and methos through dt accessor. 13.6.8.1 Sample Data s = pd.Series([ datetime(2000,1,1,0,0,0), datetime(1999,12,15,12,34,55), datetime(2020,3,8,5,7,12), datetime(2018,1,1,0,0,0), datetime(2003,3,4,5,6,7) ]) s 0 2000-01-01 00:00:00 1 1999-12-15 12:34:55 2 2020-03-08 05:07:12 3 2018-01-01 00:00:00 4 2003-03-04 05:06:07 dtype: datetime64[ns] 13.6.8.2 Convert To datetime.datetime Use to_pydatetime() to convert into numpy.array of standard library datetime.datetime pdt = s.dt.to_pydatetime() print( type(pdt) ) &lt;class ‘numpy.ndarray’&gt; pdt array([datetime.datetime(2000, 1, 1, 0, 0), datetime.datetime(1999, 12, 15, 12, 34, 55), datetime.datetime(2020, 3, 8, 5, 7, 12), datetime.datetime(2018, 1, 1, 0, 0), datetime.datetime(2003, 3, 4, 5, 6, 7)], dtype=object) datetime.date Use dt.date to convert into pandas.Series of standard library datetime.date Is it possible to have a pandas.Series of datetime.datetime ? No, because Pandas want it as its own Timestamp. sdt = s.dt.date print( type(sdt[1] )) &lt;class ‘datetime.date’&gt; print( type(sdt)) &lt;class ‘pandas.core.series.Series’&gt; sdt 0 2000-01-01 1 1999-12-15 2 2020-03-08 3 2018-01-01 4 2003-03-04 dtype: object 13.6.8.3 Timestamp Attributes A Series::DateTime object support below properties: - date - month - day - year - dayofweek - dayofyear - weekday - weekday_name - quarter - daysinmonth - hour - minute Full list below: https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetimelike-properties s.dt.date 0 2000-01-01 1 1999-12-15 2 2020-03-08 3 2018-01-01 4 2003-03-04 dtype: object s.dt.month 0 1 1 12 2 3 3 1 4 3 dtype: int64 s.dt.dayofweek 0 5 1 2 2 6 3 0 4 1 dtype: int64 s.dt.weekday 0 5 1 2 2 6 3 0 4 1 dtype: int64 s.dt.weekday_name 0 Saturday 1 Wednesday 2 Sunday 3 Monday 4 Tuesday dtype: object s.dt.quarter 0 1 1 4 2 1 3 1 4 1 dtype: int64 s.dt.daysinmonth 0 31 1 31 2 31 3 31 4 31 dtype: int64 s.dt.time # extract time as time Object 0 00:00:00 1 12:34:55 2 05:07:12 3 00:00:00 4 05:06:07 dtype: object s.dt.hour # extract hour as integer 0 0 1 12 2 5 3 0 4 5 dtype: int64 s.dt.minute # extract minute as integer 0 0 1 34 2 7 3 0 4 6 dtype: int64 13.7 DataFrame 13.7.1 Constructor 13.7.1.1 From Row Oriented Data (List of Lists) Create from List of Lists DataFrame( [row_list1, row_list2, row_list3] ) DataFrame( [row_list1, row_list2, row_list3], column=columnName_list ) DataFrame( [row_list1, row_list2, row_list3], index=row_label_list ) Basic DataFrame with default Row Label and Column Header pd.DataFrame ([[101,&#39;Alice&#39;,40000,2017], [102,&#39;Bob&#39;, 24000, 2017], [103,&#39;Charles&#39;,31000,2017]] ) 0 1 2 3 0 101 Alice 40000 2017 1 102 Bob 24000 2017 2 103 Charles 31000 2017 Specify Column Header during Creation pd.DataFrame ([[101,&#39;Alice&#39;,40000,2017], [102,&#39;Bob&#39;, 24000, 2017], [103,&#39;Charles&#39;,31000,2017]], columns = [&#39;empID&#39;,&#39;name&#39;,&#39;salary&#39;,&#39;year&#39;]) empID name salary year 0 101 Alice 40000 2017 1 102 Bob 24000 2017 2 103 Charles 31000 2017 Specify Row Label during Creation pd.DataFrame ([[101,&#39;Alice&#39;,40000,2017], [102,&#39;Bob&#39;, 24000, 2017], [103,&#39;Charles&#39;,31000,2017]], index = [&#39;r1&#39;,&#39;r2&#39;,&#39;r3&#39;] ) 0 1 2 3 r1 101 Alice 40000 2017 r2 102 Bob 24000 2017 r3 103 Charles 31000 2017 13.7.1.2 From Row Oriented Data (List of Dictionary) DataFrame( [dict1, dict2, dict3] ) DataFrame( [row_list1, row_list2, row_list3], column=np.arrange ) DataFrame( [row_list1, row_list2, row_list3], index=row_label_list ) by default,keys will become collumn names, and autosorted Default Column Name Follow Dictionary Key Note missing info as NaN pd.DataFrame ([{&quot;name&quot;:&quot;Yong&quot;, &quot;id&quot;:1,&quot;zkey&quot;:101},{&quot;name&quot;:&quot;Gan&quot;,&quot;id&quot;:2}]) id name zkey 0 1 Yong 101.0 1 2 Gan NaN Specify Index pd.DataFrame ([{&quot;name&quot;:&quot;Yong&quot;, &quot;id&quot;:&#39;wd1&#39;},{&quot;name&quot;:&quot;Gan&quot;,&quot;id&quot;:&#39;wd2&#39;}], index = (1,2)) id name 1 wd1 Yong 2 wd2 Gan Specify Column Header during Creation, can acts as column filter and manual arrangement Note missing info as NaN pd.DataFrame ([{&quot;name&quot;:&quot;Yong&quot;, &quot;id&quot;:1, &quot;zkey&quot;:101},{&quot;name&quot;:&quot;Gan&quot;,&quot;id&quot;:2}], columns=(&quot;name&quot;,&quot;id&quot;,&quot;zkey&quot;)) name id zkey 0 Yong 1 101.0 1 Gan 2 NaN 13.7.1.3 From Column Oriented Data Create from Dictrionary of List DataFrame( { &#39;column1&#39;: list1, &#39;column2&#39;: list2, &#39;column3&#39;: list3 } , index = row_label_list, columns = column_list) By default, DataFrame will arrange the columns alphabetically, unless columns is specified Default Row Label data = {&#39;empID&#39;: [100, 101, 102, 103, 104], &#39;year&#39;: [2017, 2017, 2017, 2018, 2018], &#39;salary&#39;: [40000, 24000, 31000, 20000, 30000], &#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Charles&#39;, &#39;David&#39;, &#39;Eric&#39;]} pd.DataFrame(data) empID year salary name 0 100 2017 40000 Alice 1 101 2017 24000 Bob 2 102 2017 31000 Charles 3 103 2018 20000 David 4 104 2018 30000 Eric Specify Row Label during Creation data = {&#39;empID&#39;: [100, 101, 102, 103, 104], &#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Charles&#39;, &#39;David&#39;, &#39;Eric&#39;], &#39;year&#39;: [2017, 2017, 2017, 2018, 2018], &#39;salary&#39;: [40000, 24000, 31000, 20000, 30000] } pd.DataFrame (data, index=[&#39;r1&#39;,&#39;r2&#39;,&#39;r3&#39;,&#39;r4&#39;,&#39;r5&#39;]) empID name year salary r1 100 Alice 2017 40000 r2 101 Bob 2017 24000 r3 102 Charles 2017 31000 r4 103 David 2018 20000 r5 104 Eric 2018 30000 Manualy Choose Columns and Arrangement data = {&#39;empID&#39;: [100, 101, 102, 103, 104], &#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Charles&#39;, &#39;David&#39;, &#39;Eric&#39;], &#39;year&#39;: [2017, 2017, 2017, 2018, 2018], &#39;salary&#39;: [40000, 24000, 31000, 20000, 30000] } pd.DataFrame (data, columns=(&#39;empID&#39;,&#39;name&#39;,&#39;salary&#39;), index=[&#39;r1&#39;,&#39;r2&#39;,&#39;r3&#39;,&#39;r4&#39;,&#39;r5&#39;]) empID name salary r1 100 Alice 40000 r2 101 Bob 24000 r3 102 Charles 31000 r4 103 David 20000 r5 104 Eric 30000 13.7.2 Attributes df = pd.DataFrame( { &#39;empID&#39;: [100, 101, 102, 103, 104], &#39;year1&#39;: [2017, 2017, 2017, 2018, 2018], &#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Charles&#39;,&#39;David&#39;, &#39;Eric&#39;], &#39;year2&#39;: [2001, 1907, 2003, 1998, 2011], &#39;salary&#39;: [40000, 24000, 31000, 20000, 30000]}, columns = [&#39;year1&#39;,&#39;salary&#39;,&#39;year2&#39;,&#39;empID&#39;,&#39;name&#39;]) 13.7.2.1 Dimensions df.shape (5, 5) 13.7.2.2 Index df.index RangeIndex(start=0, stop=5, step=1) Underlying Index values are numpy object df.index.values array([0, 1, 2, 3, 4], dtype=int64) 13.7.2.3 Columns df.columns Index([‘year1’, ‘salary’, ‘year2’, ‘empID’, ‘name’], dtype=‘object’) Underlying Index values are numpy object df.columns.values array([‘year1’, ‘salary’, ‘year2’, ‘empID’, ‘name’], dtype=object) 13.7.2.4 Values Underlying Column values are numpy object df.values array([[2017, 40000, 2001, 100, ‘Alice’], [2017, 24000, 1907, 101, ‘Bob’], [2017, 31000, 2003, 102, ‘Charles’], [2018, 20000, 1998, 103, ‘David’], [2018, 30000, 2011, 104, ‘Eric’]], dtype=object) 13.7.3 Index Manipulation index and row label are used interchangeably in this book 13.7.3.1 Sample Data Columns are intentionaly ordered in a messy way df = pd.DataFrame( { &#39;empID&#39;: [100, 101, 102, 103, 104], &#39;year1&#39;: [2017, 2017, 2017, 2018, 2018], &#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Charles&#39;,&#39;David&#39;, &#39;Eric&#39;], &#39;year2&#39;: [2001, 1907, 2003, 1998, 2011], &#39;salary&#39;: [40000, 24000, 31000, 20000, 30000]}, columns = [&#39;year1&#39;,&#39;salary&#39;,&#39;year2&#39;,&#39;empID&#39;,&#39;name&#39;]) print (df, &#39;\\n&#39;) year1 salary year2 empID name 0 2017 40000 2001 100 Alice 1 2017 24000 1907 101 Bob 2 2017 31000 2003 102 Charles 3 2018 20000 1998 103 David 4 2018 30000 2011 104 Eric print (df.index) RangeIndex(start=0, stop=5, step=1) 13.7.3.2 Convert Column To Index set_index(&#39;column_name&#39;, inplace=False) inplace=True means don’t create a new dataframe. Modify existing dataframe inplace=False means return a new dataframe print(df) year1 salary year2 empID name 0 2017 40000 2001 100 Alice 1 2017 24000 1907 101 Bob 2 2017 31000 2003 102 Charles 3 2018 20000 1998 103 David 4 2018 30000 2011 104 Eric print(df.index,&#39;\\n&#39;) RangeIndex(start=0, stop=5, step=1) df.set_index(&#39;empID&#39;,inplace=True) print(df) year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric print(df.index) # return new DataFrameObj Int64Index([100, 101, 102, 103, 104], dtype=‘int64’, name=‘empID’) 13.7.3.3 Convert Index Back To Column Reseting index will resequence the index as 0,1,2 etc Old index column will be converted back as normal column Operation support inplace** option df.reset_index(inplace=True) print(df) empID year1 salary year2 name 0 100 2017 40000 2001 Alice 1 101 2017 24000 1907 Bob 2 102 2017 31000 2003 Charles 3 103 2018 20000 1998 David 4 104 2018 30000 2011 Eric 13.7.3.4 Updating Index ( .index= ) Warning: - Updating index doesn’t reorder the data sequence - Number of elements before and after reorder must match, otherwise error - Same label are allowed to repeat - Not reversable df.index = [101, 101, 101, 102, 103] print( df ) empID year1 salary year2 name 101 100 2017 40000 2001 Alice 101 101 2017 24000 1907 Bob 101 102 2017 31000 2003 Charles 102 103 2018 20000 1998 David 103 104 2018 30000 2011 Eric 13.7.3.5 Reordering Index (. reindex ) Reindex will reorder the rows according to new index The operation is not reversable Start from this original dataframe Change the order of Index, always return a new dataframe df.index = [101,102,103,104,105] print( df ) ## original sequence empID year1 salary year2 name 101 100 2017 40000 2001 Alice 102 101 2017 24000 1907 Bob 103 102 2017 31000 2003 Charles 104 103 2018 20000 1998 David 105 104 2018 30000 2011 Eric print( df.reindex([103,102,101,104,105]) ) ## new sequence, new dataframe empID year1 salary year2 name 103 102 2017 31000 2003 Charles 102 101 2017 24000 1907 Bob 101 100 2017 40000 2001 Alice 104 103 2018 20000 1998 David 105 104 2018 30000 2011 Eric 13.7.4 Subsetting Columns Select Single Column Return Series dataframe.columnName # single column, name based, return Series object dataframe[ single_col_name ] # single column, name based, return Series object dataframe[ [single_col_name] ] # single column, name based, return DataFrame object Select Single/Multiple Columns Return DataFrame dataframe[ single/list_of_col_names ] # name based, return Dataframe object dataframe.loc[ : , single_col_name ] # single column, series dataframe.loc[ : , col_name_list ] # multiple columns, dataframe dataframe.loc[ : , col_name_ranage ] # multiple columns, dataframe dataframe.iloc[ : , col_number ] # single column, series dataframe.iloc[ : , col_number_list ] # multiple columns, dataframe dataframe.iloc[ : , number_range ] # multiple columns, dataframe 13.7.4.1 Select Single Column Selecting single column always return as panda::Series df.name 101 Alice 102 Bob 103 Charles 104 David 105 Eric Name: name, dtype: object df[&#39;name&#39;] 101 Alice 102 Bob 103 Charles 104 David 105 Eric Name: name, dtype: object df.loc[:, &#39;name&#39;] 101 Alice 102 Bob 103 Charles 104 David 105 Eric Name: name, dtype: object df.iloc[:, 3] 101 2001 102 1907 103 2003 104 1998 105 2011 Name: year2, dtype: int64 13.7.4.2 Select Multiple Columns Multiple columns return as panda::Dataframe object` df[[&#39;name&#39;]] # return one column dataframe name 101 Alice 102 Bob 103 Charles 104 David 105 Eric print(df.columns) Index([‘empID’, ‘year1’, ‘salary’, ‘year2’, ‘name’], dtype=‘object’) df[[&#39;name&#39;,&#39;year1&#39;]] name year1 101 Alice 2017 102 Bob 2017 103 Charles 2017 104 David 2018 105 Eric 2018 df.loc[:,[&#39;name&#39;,&#39;year1&#39;]] name year1 101 Alice 2017 102 Bob 2017 103 Charles 2017 104 David 2018 105 Eric 2018 df.loc[:,&#39;year1&#39;:&#39;year2&#39;] # range of columns year1 salary year2 101 2017 40000 2001 102 2017 24000 1907 103 2017 31000 2003 104 2018 20000 1998 105 2018 30000 2011 df.iloc[:,[0,3]] empID year2 101 100 2001 102 101 1907 103 102 2003 104 103 1998 105 104 2011 df.iloc[:,0:3] empID year1 salary 101 100 2017 40000 102 101 2017 24000 103 102 2017 31000 104 103 2018 20000 105 104 2018 30000 13.7.4.3 Selection by Data Type df.select_dtypes(include=None, exclude=None) Always return panda::DataFrame, even though only single column matches. Allowed types are: - number (integer and float) - integer / float - datetime - timedelta - category df.get_dtype_counts() int64 4 object 1 dtype: int64 df.select_dtypes(exclude=&#39;number&#39;) name 101 Alice 102 Bob 103 Charles 104 David 105 Eric df.select_dtypes(exclude=(&#39;number&#39;,&#39;object&#39;)) Empty DataFrame Columns: [] Index: [101, 102, 103, 104, 105] 13.7.4.4 Subset by filter() .filter(items=None, like=None, regex=None, axis=1) like = Substring Matches df.filter( like=&#39;year&#39;, axis=&#39;columns&#39;) ## or axis = 1 year1 year2 101 2017 2001 102 2017 1907 103 2017 2003 104 2018 1998 105 2018 2011 items = list of column names df.filter( items=(&#39;year1&#39;,&#39;year2&#39;), axis=1) ## or axis = 1 year1 year2 101 2017 2001 102 2017 1907 103 2017 2003 104 2018 1998 105 2018 2011 regex = Regular Expression Select column names that contain integer df.filter(regex=&#39;\\d&#39;) ## default axis=1 if DataFrame year1 year2 101 2017 2001 102 2017 1907 103 2017 2003 104 2018 1998 105 2018 2011 13.7.5 Column Manipulation 13.7.5.1 Sample Data df empID year1 salary year2 name 101 100 2017 40000 2001 Alice 102 101 2017 24000 1907 Bob 103 102 2017 31000 2003 Charles 104 103 2018 20000 1998 David 105 104 2018 30000 2011 Eric 13.7.5.2 Renaming Columns Method 1 : Rename All Columns (.columns =) - Construct the new column names, check if there is no missing column names - Missing columns will return error - Direct Assignment to column property result in change to dataframe new_columns = [&#39;year.1&#39;,&#39;salary&#39;,&#39;year.2&#39;,&#39;empID&#39;,&#39;name&#39;] df.columns = new_columns df.head(2) year.1 salary year.2 empID name 101 100 2017 40000 2001 Alice 102 101 2017 24000 1907 Bob Method 2 : Renaming Specific Column (.rename (columns=) ) - Change column name through rename function - Support inpalce option for original dataframe change - Missing column is OK df.rename( columns={&#39;year.1&#39;:&#39;year1&#39;, &#39;year.2&#39;:&#39;year2&#39;}, inplace=True) df.head(2) year1 salary year2 empID name 101 100 2017 40000 2001 Alice 102 101 2017 24000 1907 Bob 13.7.5.3 Reordering Columns Always return a new dataframe. There is no inplace option for reordering columns Method 1 - reindex(columns = ) - reindex may sounds like operation on row labels, but it works - Missmatch column names will result in NA for the unfound column new_colorder = [ &#39;empID&#39;, &#39;name&#39;, &#39;salary&#39;, &#39;year1&#39;, &#39;year2&#39;] df.reindex(columns = new_colorder).head(2) empID name salary year1 year2 101 2001 Alice 2017 100 40000 102 1907 Bob 2017 101 24000 Method 2 - [ ] notation - Missmatch column will result in ERROR new_colorder = [ &#39;empID&#39;, &#39;name&#39;, &#39;salary&#39;, &#39;year1&#39;, &#39;year2&#39;] df[new_colorder] empID name salary year1 year2 101 2001 Alice 2017 100 40000 102 1907 Bob 2017 101 24000 103 2003 Charles 2017 102 31000 104 1998 David 2018 103 20000 105 2011 Eric 2018 104 30000 13.7.5.4 Duplicating or Replacing Column New Column will be created instantly using [] notation DO NOT USE dot Notation because it is view only attribute df[&#39;year3&#39;] = df.year1 df year1 salary year2 empID name year3 101 100 2017 40000 2001 Alice 100 102 101 2017 24000 1907 Bob 101 103 102 2017 31000 2003 Charles 102 104 103 2018 20000 1998 David 103 105 104 2018 30000 2011 Eric 104 13.7.5.5 Dropping Columns (.drop) dataframe.drop( columns=&#39;column_name&#39;, inplace=True/False) # delete single column dataframe.drop( columns=list_of_colnames, inplace=True/False) # delete multiple column dataframe.drop( index=&#39;row_label&#39;, inplace=True/False) # delete single row dataframe.drop( index= list_of_row_labels, inplace=True/False) # delete multiple rows inplace=True means column will be deleted from original dataframe. Default is False, which return a copy of dataframe By Column Name(s) df.drop( columns=&#39;year1&#39;) # drop single column salary year2 empID name year3 101 2017 40000 2001 Alice 100 102 2017 24000 1907 Bob 101 103 2017 31000 2003 Charles 102 104 2018 20000 1998 David 103 105 2018 30000 2011 Eric 104 df.drop(columns=[&#39;year2&#39;,&#39;year3&#39;]) # drop multiple columns year1 salary empID name 101 100 2017 2001 Alice 102 101 2017 1907 Bob 103 102 2017 2003 Charles 104 103 2018 1998 David 105 104 2018 2011 Eric By Column Number(s) Use dataframe.columns to produce interim list of column names df.drop( columns=df.columns[[3,4,5]] ) # delete columns by list of column number year1 salary year2 101 100 2017 40000 102 101 2017 24000 103 102 2017 31000 104 103 2018 20000 105 104 2018 30000 df.drop( columns=df.columns[3:6] ) # delete columns by range of column number year1 salary year2 101 100 2017 40000 102 101 2017 24000 103 102 2017 31000 104 103 2018 20000 105 104 2018 30000 13.7.6 Subsetting Rows dataframe.loc[ row_label ] # return series, single row dataframe.loc[ row_label_list ] # multiple rows dataframe.loc[ boolean_list ] # multiple rows dataframe.iloc[ row_number ] # return series, single row dataframe.iloc[ row_number_list ] # multiple rows dataframe.iloc[ number_range ] # multiple rows dataframe.sample(frac=) # frac = 0.6 means sampling 60% of rows randomly 13.7.6.1 Sample Data df = pd.DataFrame( { &#39;empID&#39;: [100, 101, 102, 103, 104], &#39;year1&#39;: [2017, 2017, 2017, 2018, 2018], &#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Charles&#39;,&#39;David&#39;, &#39;Eric&#39;], &#39;year2&#39;: [2001, 1907, 2003, 1998, 2011], &#39;salary&#39;: [40000, 24000, 31000, 20000, 30000]}, columns = [&#39;year1&#39;,&#39;salary&#39;,&#39;year2&#39;,&#39;empID&#39;,&#39;name&#39;]).set_index([&#39;empID&#39;]) df year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric 13.7.6.2 By Index or Boolean Single Index return Series df.loc[101] # by single row label, return series year1 2017 salary 24000 year2 1907 name Bob Name: 101, dtype: object List or Range of Indexes returns DataFrame df.loc[ [100,103] ] # by multiple row labels year1 salary year2 name empID 100 2017 40000 2001 Alice 103 2018 20000 1998 David df.loc[ 100:103 ] # by range of row labels year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David List of Boolean returns DataFrame criteria = (df.salary &gt; 30000) &amp; (df.year1==2017) print (criteria) empID 100 True 101 False 102 True 103 False 104 False dtype: bool print (df.loc[criteria]) year1 salary year2 name empID 100 2017 40000 2001 Alice 102 2017 31000 2003 Charles 13.7.6.3 By Row Number Single Row return Series df.iloc[1] # by single row number year1 2017 salary 24000 year2 1907 name Bob Name: 101, dtype: object Multiple rows returned as dataframe object df.iloc[ [0,3] ] # by row numbers year1 salary year2 name empID 100 2017 40000 2001 Alice 103 2018 20000 1998 David df.iloc[ 0:3 ] # by row number range year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 13.7.6.4 query() .query(expr, inplace=False) df.query(&#39;salary&lt;=31000 and year1 == 2017&#39;) year1 salary year2 name empID 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 13.7.6.5 sample() np.random.seed(15) df.sample(frac=0.6) #randomly pick 60% of rows, without replacement year1 salary year2 name empID 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric 13.7.7 Row Manipulation 13.7.7.1 Sample Data 13.7.7.2 Dropping Rows (.drop) .drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise') By Row Label(s) df.drop(index=100) # single row year1 salary year2 name empID 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric df.drop(index=[100,103]) # multiple rows year1 salary year2 name empID 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 104 2018 30000 2011 Eric 13.7.8 Slicing 13.7.8.1 Sample Data df year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric 13.7.8.2 Getting One Cell By Row Label and Column Name (loc) dataframe.loc [ row_label , col_name ] # by row label and column names dataframe.loc [ bool_list , col_name ] # by row label and column names dataframe.iloc[ row_number, col_number ] # by row and column number print (df.loc[100,&#39;year1&#39;]) 2017 By Row Number and Column Number (iloc) print (df.iloc[1,2]) 1907 13.7.8.3 Getting Multiple Cells Specify rows and columns (by individual or range) dataframe.loc [ list/range_of_row_labels , list/range_col_names ] # by row label and column names dataframe.iloc[ list/range_row_numbers, list/range_col_numbers ] # by row number By Index and Column Name (loc) print (df.loc[ [101,103], [&#39;name&#39;,&#39;year1&#39;] ], &#39;\\n&#39;) # by list of row label and column names name year1 empID 101 Bob 2017 103 David 2018 print (df.loc[ 101:104 , &#39;year1&#39;:&#39;year2&#39; ], &#39;\\n&#39;) # by range of row label and column names year1 salary year2 empID 101 2017 24000 1907 102 2017 31000 2003 103 2018 20000 1998 104 2018 30000 2011 By Boolean Row and Column Names (loc) df.loc[df.year1==2017, &#39;year1&#39;:&#39;year2&#39;] year1 salary year2 empID 100 2017 40000 2001 101 2017 24000 1907 102 2017 31000 2003 By Row and Column Number (iloc) print (df.iloc[ [1,4], [0,3]],&#39;\\n&#39; ) # by individual rows/columns year1 name empID 101 2017 Bob 104 2018 Eric print (df.iloc[ 1:4 , 0:3], &#39;\\n&#39;) # by range year1 salary year2 empID 101 2017 24000 1907 102 2017 31000 2003 103 2018 20000 1998 13.7.9 Chained Indexing Chained Index Method creates a copy of dataframe, any modification of data on original dataframe does not affect the copy dataframe.loc [...] [...] dataframe.iloc [...] [...] Suggesting, never use chain indexing df = pd.DataFrame( { &#39;empID&#39;: [100, 101, 102, 103, 104], &#39;year1&#39;: [2017, 2017, 2017, 2018, 2018], &#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;, &#39;Charles&#39;,&#39;David&#39;, &#39;Eric&#39;], &#39;year2&#39;: [2001, 1907, 2003, 1998, 2011], &#39;salary&#39;: [40000, 24000, 31000, 20000, 30000]}, columns = [&#39;year1&#39;,&#39;salary&#39;,&#39;year2&#39;,&#39;empID&#39;,&#39;name&#39;]).set_index([&#39;empID&#39;]) df year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric df.loc[100][&#39;year&#39;] =2000 C:/ProgramData/Anaconda3/python.exe:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy C:3-packages.py:915: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy self.loc[key] = value df ## notice row label 100 had not been updated, because data was updated on a copy due to chain indexing year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric 13.7.10 Data Structure 13.7.10.1 Instance Methods - Structure Find out the column names, data type in a summary. Output is for display only, not a data object df.info() # return text output &lt;class ‘pandas.core.frame.DataFrame’&gt; Int64Index: 5 entries, 100 to 104 Data columns (total 4 columns): year1 5 non-null int64 salary 5 non-null int64 year2 5 non-null int64 name 5 non-null object dtypes: int64(3), object(1) memory usage: 360.0+ bytes df.get_dtype_counts() # return Series int64 3 object 1 dtype: int64 13.7.10.2 Conversion To Other Format df.to_json() ‘{“year1”:{“100”:2017,“101”:2017,“102”:2017,“103”:2018,“104”:2018},“salary”:{“100”:40000,“101”:24000,“102”:31000,“103”:20000,“104”:30000},“year2”:{“100”:2001,“101”:1907,“102”:2003,“103”:1998,“104”:2011},“name”:{“100”:“Alice”,“101”:“Bob”,“102”:“Charles”,“103”:“David”,“104”:“Eric”}}’ df.to_records() rec.array([(100, 2017, 40000, 2001, ‘Alice’), (101, 2017, 24000, 1907, ‘Bob’), (102, 2017, 31000, 2003, ‘Charles’), (103, 2018, 20000, 1998, ‘David’), (104, 2018, 30000, 2011, ‘Eric’)], dtype=[(‘empID’, ‘&lt;i8’), (‘year1’, ‘&lt;i8’), (‘salary’, ‘&lt;i8’), (‘year2’, ‘&lt;i8’), (‘name’, ‘O’)]) df.to_csv() ‘empID,year1,salary,year2,name100,2017,40000,2001,Alice101,2017,24000,1907,Bob102,2017,31000,2003,Charles103,2018,20000,1998,David104,2018,30000,2011,Eric’ 13.7.11 Exploratory Analysis 13.7.11.1 Sample Data df year1 salary year2 name empID 100 2017 40000 2001 Alice 101 2017 24000 1907 Bob 102 2017 31000 2003 Charles 103 2018 20000 1998 David 104 2018 30000 2011 Eric 13.7.11.2 All Stats in One - .describe() df.describe(include=&#39;number&#39;) # default df.describe(include=&#39;object&#39;) # display for non-numeric columns df.describe(include=&#39;all&#39;) # display both numeric and non-numeric When applied to DataFrame object, describe shows all basic statistic for all numeric columns: - Count (non-NA) - Unique (for string) - Top (for string) - Frequency (for string) - Percentile - Mean - Min / Max - Standard Deviation For Numeric Columns only You can customize the percentiles requred. Notice 0.5 percentile is always there although not specified df.describe() year1 salary year2 count 5.000000 5.000000 5.000000 mean 2017.400000 29000.000000 1984.000000 std 0.547723 7615.773106 43.312816 min 2017.000000 20000.000000 1907.000000 25% 2017.000000 24000.000000 1998.000000 50% 2017.000000 30000.000000 2001.000000 75% 2018.000000 31000.000000 2003.000000 max 2018.000000 40000.000000 2011.000000 df.describe(percentiles=[0.9,0.3,0.2,0.1]) year1 salary year2 count 5.000000 5.000000 5.000000 mean 2017.400000 29000.000000 1984.000000 std 0.547723 7615.773106 43.312816 min 2017.000000 20000.000000 1907.000000 10% 2017.000000 21600.000000 1943.400000 20% 2017.000000 23200.000000 1979.800000 30% 2017.000000 25200.000000 1998.600000 50% 2017.000000 30000.000000 2001.000000 90% 2018.000000 36400.000000 2007.800000 max 2018.000000 40000.000000 2011.000000 For both Numeric and Object df.describe(include=&#39;all&#39;) year1 salary year2 name count 5.0 5.0 5.0 5 unique NaN NaN NaN 5 top NaN NaN NaN David freq NaN NaN NaN 1 mean 2017.4 29000.0 1984.0 NaN … … … … … min 2017.0 20000.0 1907.0 NaN 25% 2017.0 24000.0 1998.0 NaN 50% 2017.0 30000.0 2001.0 NaN 75% 2018.0 31000.0 2003.0 NaN max 2018.0 40000.0 2011.0 NaN [11 rows x 4 columns] 13.7.11.3 min/max/mean/median df.min() # default axis=0, column-wise year1 2017 salary 20000 year2 1907 name Alice dtype: object df.min(axis=1) # axis=1, row-wise empID 100 2001 101 1907 102 2003 103 1998 104 2011 dtype: int64 Observe, sum on string will concatenate column-wise, whereas row-wise only sum up numeric fields df.sum(0) year1 10087 salary 145000 year2 9920 name AliceBobCharlesDavidEric dtype: object df.sum(1) empID 100 44018 101 27924 102 35020 103 24016 104 34029 dtype: int64 13.7.12 Plotting 13.8 Categories 13.8.1 Creating 13.8.1.1 From List Basic (Auto Category Mapping) Basic syntax return categorical index with sequence with code 0,1,2,3… mapping to first found category In this case, low(0), high(1), medium(2) temp = [&#39;low&#39;,&#39;high&#39;,&#39;medium&#39;,&#39;high&#39;,&#39;high&#39;,&#39;low&#39;,&#39;medium&#39;,&#39;medium&#39;,&#39;high&#39;] temp_cat = pd.Categorical(temp) temp_cat [low, high, medium, high, high, low, medium, medium, high] Categories (3, object): [high, low, medium] type( temp_cat ) &lt;class ‘pandas.core.arrays.categorical.Categorical’&gt; Manual Category Mapping During creation, we can specify mapping of codes to category: low(0), medium(1), high(2) temp_cat = pd.Categorical(temp, categories=[&#39;low&#39;,&#39;medium&#39;,&#39;high&#39;]) temp_cat [low, high, medium, high, high, low, medium, medium, high] Categories (3, object): [low, medium, high] 13.8.1.2 From Series We can ‘add’ categorical structure into a Series. With these methods, additional property (.cat) is added as a categorical accessor Through this accessor, you gain access to various properties of the category such as .codes, .categories. But not .get_values() as the information is in the Series itself Can we manual map category ????? temp = [&#39;low&#39;,&#39;high&#39;,&#39;medium&#39;,&#39;high&#39;,&#39;high&#39;,&#39;low&#39;,&#39;medium&#39;,&#39;medium&#39;,&#39;high&#39;] temp_cat = pd.Series(temp, dtype=&#39;category&#39;) print (type(temp_cat)) # Series object &lt;class ‘pandas.core.series.Series’&gt; print (type(temp_cat.cat)) # Categorical Accessor &lt;class ‘pandas.core.arrays.categorical.CategoricalAccessor’&gt; Method below has the same result as above by using .astype(‘category’) It is useful adding category structure into existing series. temp_ser = pd.Series(temp) temp_cat = pd.Series(temp).astype(&#39;category&#39;) print (type(temp_cat)) # Series object &lt;class ‘pandas.core.series.Series’&gt; print (type(temp_cat.cat)) # Categorical Accessor &lt;class ‘pandas.core.arrays.categorical.CategoricalAccessor’&gt; temp_cat.cat.categories Index([‘high’, ‘low’, ‘medium’], dtype=‘object’) 13.8.1.3 Ordering Category temp = [&#39;low&#39;,&#39;high&#39;,&#39;medium&#39;,&#39;high&#39;,&#39;high&#39;,&#39;low&#39;,&#39;medium&#39;,&#39;medium&#39;,&#39;high&#39;] temp_cat = pd.Categorical(temp, categories=[&#39;low&#39;,&#39;medium&#39;,&#39;high&#39;], ordered=True) temp_cat [low, high, medium, high, high, low, medium, medium, high] Categories (3, object): [low &lt; medium &lt; high] temp_cat.get_values() array([‘low’, ‘high’, ‘medium’, ‘high’, ‘high’, ‘low’, ‘medium’, ‘medium’, ‘high’], dtype=object) temp_cat.codes array([0, 2, 1, 2, 2, 0, 1, 1, 2], dtype=int8) temp_cat[0] &lt; temp_cat[3] False 13.8.2 Properties 13.8.2.1 .categories first element’s code = 0 second element’s code = 1 third element’s code = 2 temp_cat.categories Index([‘low’, ‘medium’, ‘high’], dtype=‘object’) 13.8.2.2 .codes Codes are actual integer value stored as array. 1 represent ‘high’, temp_cat.codes array([0, 2, 1, 2, 2, 0, 1, 1, 2], dtype=int8) 13.8.3 Rename Category 13.8.3.1 Renamce To New Category Object .rename_categories() method return a new category object with new changed categories temp = [&#39;low&#39;,&#39;high&#39;,&#39;medium&#39;,&#39;high&#39;,&#39;high&#39;,&#39;low&#39;,&#39;medium&#39;,&#39;medium&#39;,&#39;high&#39;] new_temp_cat = temp_cat.rename_categories([&#39;sejuk&#39;,&#39;sederhana&#39;,&#39;panas&#39;]) new_temp_cat [sejuk, panas, sederhana, panas, panas, sejuk, sederhana, sederhana, panas] Categories (3, object): [sejuk &lt; sederhana &lt; panas] temp_cat # original category object categories not changed [low, high, medium, high, high, low, medium, medium, high] Categories (3, object): [low &lt; medium &lt; high] 13.8.3.2 Rename Inplace Observe the original categories had been changed using .rename() temp_cat.categories = [&#39;sejuk&#39;,&#39;sederhana&#39;,&#39;panas&#39;] temp_cat # original category object categories is changed [sejuk, panas, sederhana, panas, panas, sejuk, sederhana, sederhana, panas] Categories (3, object): [sejuk &lt; sederhana &lt; panas] 13.8.4 Adding New Category This return a new category object with added categories temp_cat_more = temp_cat.add_categories([&#39;susah&#39;,&#39;senang&#39;]) temp_cat_more [sejuk, panas, sederhana, panas, panas, sejuk, sederhana, sederhana, panas] Categories (5, object): [sejuk &lt; sederhana &lt; panas &lt; susah &lt; senang] 13.8.5 Removing Category This is not in place, hence return a new categorical object 13.8.5.1 Remove Specific Categor(ies) Elements with its category removed will become NaN temp = [&#39;low&#39;,&#39;high&#39;,&#39;medium&#39;,&#39;high&#39;,&#39;high&#39;,&#39;low&#39;,&#39;medium&#39;,&#39;medium&#39;,&#39;high&#39;] temp_cat = pd.Categorical(temp) temp_cat_removed = temp_cat.remove_categories(&#39;low&#39;) temp_cat_removed [NaN, high, medium, high, high, NaN, medium, medium, high] Categories (2, object): [high, medium] 13.8.5.2 Remove Unused Category Since categories removed are not used, there is no impact to the element print (temp_cat_more) [sejuk, panas, sederhana, panas, panas, sejuk, sederhana, sederhana, panas] Categories (5, object): [sejuk &lt; sederhana &lt; panas &lt; susah &lt; senang] temp_cat_more.remove_unused_categories() [sejuk, panas, sederhana, panas, panas, sejuk, sederhana, sederhana, panas] Categories (3, object): [sejuk &lt; sederhana &lt; panas] 13.8.6 Add and Remove Categories In One Step - Set() temp = [&#39;low&#39;,&#39;high&#39;,&#39;medium&#39;,&#39;high&#39;,&#39;high&#39;,&#39;low&#39;,&#39;medium&#39;,&#39;medium&#39;,&#39;high&#39;] temp_cat = pd.Categorical(temp, ordered=True) temp_cat [low, high, medium, high, high, low, medium, medium, high] Categories (3, object): [high &lt; low &lt; medium] temp_cat.set_categories([&#39;low&#39;,&#39;medium&#39;,&#39;sederhana&#39;,&#39;susah&#39;,&#39;senang&#39;]) [low, NaN, medium, NaN, NaN, low, medium, medium, NaN] Categories (5, object): [low &lt; medium &lt; sederhana &lt; susah &lt; senang] 13.8.7 Categorical Descriptive Analysis 13.8.7.1 At One Glance temp_cat.describe() counts freqs categories high 4 0.444444 low 2 0.222222 medium 3 0.333333 13.8.7.2 Frequency Count temp_cat.value_counts() high 4 low 2 medium 3 dtype: int64 13.8.7.3 Least Frequent Category, Most Frequent Category, and Most Frequent Category ( temp_cat.min(), temp_cat.max(), temp_cat.mode() ) (‘high’, ‘medium’, [high] Categories (3, object): [high &lt; low &lt; medium]) 13.8.8 Other Methods 13.8.8.1 .get_values() Since actual value stored by categorical object are integer codes, get_values() function return values translated from *.codes** property temp_cat.get_values() #array array([‘low’, ‘high’, ‘medium’, ‘high’, ‘high’, ‘low’, ‘medium’, ‘medium’, ‘high’], dtype=object) 13.9 Dummies get_dummies creates columns for each categories The underlying data can be string or pd.Categorical It produces a new pd.DataFrame 13.9.1 Sample Data df = pd.DataFrame ( {&#39;A&#39;: [&#39;A1&#39;, &#39;A2&#39;, &#39;A3&#39;,&#39;A1&#39;,&#39;A3&#39;,&#39;A1&#39;], &#39;B&#39;: [&#39;B1&#39;,&#39;B2&#39;,&#39;B3&#39;,&#39;B1&#39;,&#39;B1&#39;,&#39;B3&#39;], &#39;C&#39;: [&#39;C1&#39;,&#39;C2&#39;,&#39;C3&#39;,&#39;C1&#39;,np.nan,np.nan]}) df A B C 0 A1 B1 C1 1 A2 B2 C2 2 A3 B3 C3 3 A1 B1 C1 4 A3 B1 NaN 5 A1 B3 NaN 13.9.2 Dummies on Array-Like Data pd.get_dummies(df.A) A1 A2 A3 0 1 0 0 1 0 1 0 2 0 0 1 3 1 0 0 4 0 0 1 5 1 0 0 13.9.3 Dummies on DataFrame (multiple columns) 13.9.3.1 All Columns pd.get_dummies(df) A_A1 A_A2 A_A3 B_B1 B_B2 B_B3 C_C1 C_C2 C_C3 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0 2 0 0 1 0 0 1 0 0 1 3 1 0 0 1 0 0 1 0 0 4 0 0 1 1 0 0 0 0 0 5 1 0 0 0 0 1 0 0 0 13.9.3.2 Selected Columns cols = [&#39;A&#39;,&#39;B&#39;] pd.get_dummies(df[cols]) A_A1 A_A2 A_A3 B_B1 B_B2 B_B3 0 1 0 0 1 0 0 1 0 1 0 0 1 0 2 0 0 1 0 0 1 3 1 0 0 1 0 0 4 0 0 1 1 0 0 5 1 0 0 0 0 1 13.9.4 Dummies with na By default, nan values are ignored pd.get_dummies(df.C) C1 C2 C3 0 1 0 0 1 0 1 0 2 0 0 1 3 1 0 0 4 0 0 0 5 0 0 0 Make NaN as a dummy variable pd.get_dummies(df.C,dummy_na=True) C1 C2 C3 NaN 0 1 0 0 0 1 0 1 0 0 2 0 0 1 0 3 1 0 0 0 4 0 0 0 1 5 0 0 0 1 13.9.5 Specify Prefixes pd.get_dummies(df.A, prefix=&#39;col&#39;) col_A1 col_A2 col_A3 0 1 0 0 1 0 1 0 2 0 0 1 3 1 0 0 4 0 0 1 5 1 0 0 pd.get_dummies(df[cols], prefix=[&#39;colA&#39;,&#39;colB&#39;]) colA_A1 colA_A2 colA_A3 colB_B1 colB_B2 colB_B3 0 1 0 0 1 0 0 1 0 1 0 0 1 0 2 0 0 1 0 0 1 3 1 0 0 1 0 0 4 0 0 1 1 0 0 5 1 0 0 0 0 1 13.9.6 Dropping First Column Dummies cause colinearity issue for regression as it has redundant column. Dropping a column does not loose any information technically pd.get_dummies(df[cols],drop_first=True) A_A2 A_A3 B_B2 B_B3 0 0 0 0 0 1 1 0 1 0 2 0 1 0 1 3 0 0 0 0 4 0 1 0 0 5 0 0 0 1 13.10 Getting External Data 13.10.1 html_table parser Read the web page, create a list: which contain one or more dataframes that maps to each html table found Auto detect column header Auto create index using number starting from 0 read_html(url) # return list of dataframe(s) that maps to web table(s) structure #df_list = pd.read_html(&#39;https://www.bloomberg.com/markets/currencies&#39;) #print (&#39;Total Table(s) Found : &#39;, len(df_list)) #df = df_list[0] #print (df) 13.10.2 CSV Import 13.10.2.1 Syntax pandas.read_csv( &#39;url or filePath&#39;, # path to file or url encoding = &#39;utf_8&#39;, # optional: default is &#39;utf_8&#39; index_col = [&#39;colName1&#39;, ...], # optional: specify one or more index column parse_dates = [&#39;dateCol1&#39;, ...], # optional: specify multiple string column to convert to date na_values = [&#39;.&#39;,&#39;na&#39;,&#39;NA&#39;,&#39;N/A&#39;], # optional: values that is considered NA names = [&#39;newColName1&#39;, ... ], # optional: overwrite column names thousands = &#39;.&#39;, # optional: thousand seperator symbol nrows = n, # optional: load only first n rows skiprows = 0 # optional: don&#39;t load first n rows ) Refer to full codec Python Codec. 13.10.2.2 Default Import By default: - index is sequence of integer 0,1,2… - only two data type: number and string (auto detection) - date is not parsed, hence stayed as string goo = pd.read_csv(&#39;data/goog.csv&#39;, encoding=&#39;utf_8&#39;) goo.head() Date Open High Low Close Volume 0 12/19/2016 790.219971 797.659973 786.270020 794.200012 1225900 1 12/20/2016 796.760010 798.650024 793.270020 796.419983 925100 2 12/21/2016 795.840027 796.676025 787.099976 794.559998 1208700 3 12/22/2016 792.359985 793.320007 788.580017 791.260010 969100 4 12/23/2016 790.900024 792.739990 787.280029 789.909973 623400 goo.info() &lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 61 entries, 0 to 60 Data columns (total 6 columns): Date 61 non-null object Open 61 non-null float64 High 61 non-null float64 Low 61 non-null float64 Close 61 non-null float64 Volume 61 non-null int64 dtypes: float64(4), int64(1), object(1) memory usage: 2.9+ KB 13.10.2.3 Specify Data Types By default read_csv only import data types of float64 and object(str). This is done through auto detection. To customize the data type, use dtype parameter with a dict of definition. d_types = {&#39;Volume&#39;: str} pd.read_csv(&#39;data/goog.csv&#39;, dtype=d_types).head() Date Open High Low Close Volume 0 12/19/2016 790.219971 797.659973 786.270020 794.200012 1225900 1 12/20/2016 796.760010 798.650024 793.270020 796.419983 925100 2 12/21/2016 795.840027 796.676025 787.099976 794.559998 1208700 3 12/22/2016 792.359985 793.320007 788.580017 791.260010 969100 4 12/23/2016 790.900024 792.739990 787.280029 789.909973 623400 pd.read_csv(&#39;data/goog.csv&#39;, dtype=d_types).info() &lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 61 entries, 0 to 60 Data columns (total 6 columns): Date 61 non-null object Open 61 non-null float64 High 61 non-null float64 Low 61 non-null float64 Close 61 non-null float64 Volume 61 non-null object dtypes: float64(4), object(2) memory usage: 2.9+ KB 13.10.2.4 On The Fly Date Parsing and Indexing You can specify multiple date-alike column for parsing pd.read_csv(&#39;data/goog.csv&#39;, parse_dates=[&#39;Date&#39;]).head() Date Open High Low Close Volume 0 2016-12-19 790.219971 797.659973 786.270020 794.200012 1225900 1 2016-12-20 796.760010 798.650024 793.270020 796.419983 925100 2 2016-12-21 795.840027 796.676025 787.099976 794.559998 1208700 3 2016-12-22 792.359985 793.320007 788.580017 791.260010 969100 4 2016-12-23 790.900024 792.739990 787.280029 789.909973 623400 pd.read_csv(&#39;data/goog.csv&#39;, parse_dates=[&#39;Date&#39;]).info() &lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 61 entries, 0 to 60 Data columns (total 6 columns): Date 61 non-null datetime64[ns] Open 61 non-null float64 High 61 non-null float64 Low 61 non-null float64 Close 61 non-null float64 Volume 61 non-null int64 dtypes: datetime64ns, float64(4), int64(1) memory usage: 2.9 KB 13.10.2.5 Parse Date, Then Set as Index When date is set as index, the type is DateTimeIndex goo3 = pd.read_csv(&#39;data/goog.csv&#39;,index_col=&#39;Date&#39;, parse_dates=[&#39;Date&#39;]) goo3.head() Open High Low Close Volume Date 2016-12-19 790.219971 797.659973 786.270020 794.200012 1225900 2016-12-20 796.760010 798.650024 793.270020 796.419983 925100 2016-12-21 795.840027 796.676025 787.099976 794.559998 1208700 2016-12-22 792.359985 793.320007 788.580017 791.260010 969100 2016-12-23 790.900024 792.739990 787.280029 789.909973 623400 Observe index is now DateTime data type type(goo3.index) &lt;class ‘pandas.core.indexes.datetimes.DatetimeIndex’&gt; tb.reset_index() grp dept G1 G2 All 0 D1 17 24 41 1 D2 21 30 51 2 D3 10 25 35 3 D4 15 17 32 4 D5 20 21 41 5 All 83 117 200 13.11 GroupBy Aggretation and summarization require creating DataFrameGroupBy object from existing DataFrame The GroupBy object is a very flexible abstraction. In many ways, you can simply treat it as if it’s a collection of DataFrames, and it does the difficult things under the hood company = pd.read_csv(&#39;data/company.csv&#39;) company.head() Company Department Name Age Salary Birthdate 0 C1 D1 Yong 45 15000 1/1/1970 1 C1 D1 Chew 35 12000 2/1/1980 2 C1 D2 Lim 34 8000 2/19/1977 3 C1 D3 Jessy 23 2500 3/15/1990 4 C1 D3 Hoi Ming 55 25000 4/15/1987 13.11.1 Creating Groups com_grp = company.groupby([&#39;Company&#39;,&#39;Department&#39;]) com_grp &lt;pandas.core.groupby.groupby.DataFrameGroupBy object at 0x000000002895FD30&gt; 13.11.2 Properties 13.11.2.1 Number of Groups Created com_grp.ngroups 9 13.11.2.2 Row Numbers Associated For Each Group com_grp.groups # return Dictionary {(‘C1’, ‘D1’): Int64Index([0, 1], dtype=‘int64’), (‘C1’, ‘D2’): Int64Index([2], dtype=‘int64’), (‘C1’, ‘D3’): Int64Index([3, 4, 5], dtype=‘int64’), (‘C2’, ‘D1’): Int64Index([6], dtype=‘int64’), (‘C2’, ‘D2’): Int64Index([7, 8, 9], dtype=‘int64’), (‘C2’, ‘D3’): Int64Index([10, 11, 12], dtype=‘int64’), (‘C3’, ‘D1’): Int64Index([14], dtype=‘int64’), (‘C3’, ‘D2’): Int64Index([15], dtype=‘int64’), (‘C3’, ‘D3’): Int64Index([13, 16, 17], dtype=‘int64’)} 13.11.3 Methods 13.11.3.1 Number of Rows In Each Group com_grp.size() # return panda Series object Company Department C1 D1 2 D2 1 D3 3 C2 D1 1 D2 3 D3 3 C3 D1 1 D2 1 D3 3 dtype: int64 13.11.3.2 Valid (not Null) Data Count For Each Fields In The Group com_grp.count() # return panda DataFrame object Name Age Salary Birthdate Company Department C1 D1 2 2 2 2 D2 1 1 1 1 D3 3 3 3 3 C2 D1 1 1 1 1 D2 3 3 3 3 D3 3 3 3 3 C3 D1 1 1 1 1 D2 1 1 1 1 D3 3 3 3 3 13.11.4 Retrieve Rows All row retrieval operations return a dataframe 13.11.4.1 Retrieve N Rows For Each Groups Example below retrieve 2 rows from each group com_grp.head(2) Company Department Name Age Salary Birthdate 0 C1 D1 Yong 45 15000 1/1/1970 1 C1 D1 Chew 35 12000 2/1/1980 2 C1 D2 Lim 34 8000 2/19/1977 3 C1 D3 Jessy 23 2500 3/15/1990 4 C1 D3 Hoi Ming 55 25000 4/15/1987 .. … … … … … … 11 C2 D3 Jeannie 30 12500 12/31/1980 13 C3 D3 Chang 32 7900 7/26/1973 14 C3 D1 Ong 44 17500 8/21/1980 15 C3 D2 Lily 41 15300 7/17/1990 16 C3 D3 Sally 54 21000 7/19/1968 [14 rows x 6 columns] 13.11.4.2 Retrieve Rows In One Specific Group com_grp.get_group((&#39;C1&#39;,&#39;D3&#39;)) Company Department Name Age Salary Birthdate 3 C1 D3 Jessy 23 2500 3/15/1990 4 C1 D3 Hoi Ming 55 25000 4/15/1987 5 C1 D3 Sui Wei 56 3000 6/15/1990 13.11.4.3 Retrieve n-th Row From Each Group Row number is 0-based com_grp.nth(-1) # retireve last row from each group Age Birthdate Name Salary Company Department C1 D1 35 2/1/1980 Chew 12000 D2 34 2/19/1977 Lim 8000 D3 56 6/15/1990 Sui Wei 3000 C2 D1 18 7/15/1997 Anne 400 D2 46 10/31/1988 Jimmy 14000 D3 29 12/1/1963 Bernard 9800 C3 D1 44 8/21/1980 Ong 17500 D2 41 7/17/1990 Lily 15300 D3 37 3/16/1969 Esther 13500 13.11.5 Iteration DataFrameGroupBy object can be thought as a collection of named groups def print_groups (g): for name,group in g: print (name) print (group[:2]) print_groups (com_grp) (‘C1’, ‘D1’) Company Department Name Age Salary Birthdate 0 C1 D1 Yong 45 15000 1/1/1970 1 C1 D1 Chew 35 12000 2/1/1980 (‘C1’, ‘D2’) Company Department Name Age Salary Birthdate 2 C1 D2 Lim 34 8000 2/19/1977 (‘C1’, ‘D3’) Company Department Name Age Salary Birthdate 3 C1 D3 Jessy 23 2500 3/15/1990 4 C1 D3 Hoi Ming 55 25000 4/15/1987 (‘C2’, ‘D1’) Company Department Name Age Salary Birthdate 6 C2 D1 Anne 18 400 7/15/1997 (‘C2’, ‘D2’) Company Department Name Age Salary Birthdate 7 C2 D2 Deborah 30 8600 8/15/1984 8 C2 D2 Nikalus 51 12000 9/18/2000 (‘C2’, ‘D3’) Company Department Name Age Salary Birthdate 10 C2 D3 Michael 38 17000 11/30/1997 11 C2 D3 Jeannie 30 12500 12/31/1980 (‘C3’, ‘D1’) Company Department Name Age Salary Birthdate 14 C3 D1 Ong 44 17500 8/21/1980 (‘C3’, ‘D2’) Company Department Name Age Salary Birthdate 15 C3 D2 Lily 41 15300 7/17/1990 (‘C3’, ‘D3’) Company Department Name Age Salary Birthdate 13 C3 D3 Chang 32 7900 7/26/1973 16 C3 D3 Sally 54 21000 7/19/1968 com_grp &lt;pandas.core.groupby.groupby.DataFrameGroupBy object at 0x000000002895FD30&gt; 13.11.6 Apply Aggregate Functions to Groups Aggregate apply functions to columns in every groups, and return a summary data for each group 13.11.6.1 Apply One Function to One or More Columns com_grp[&#39;Age&#39;].sum() Company Department C1 D1 80 D2 34 D3 134 C2 D1 18 D2 127 D3 97 C3 D1 44 D2 41 D3 123 Name: Age, dtype: int64 com_grp[[&#39;Age&#39;,&#39;Salary&#39;]].sum() Age Salary Company Department C1 D1 80 27000 D2 34 8000 D3 134 30500 C2 D1 18 400 D2 127 34600 D3 97 39300 C3 D1 44 17500 D2 41 15300 D3 123 42400 13.11.6.2 Apply One or More Functions To All Columns com_grp.agg(np.mean) Age Salary Company Department C1 D1 40.000000 13500.000000 D2 34.000000 8000.000000 D3 44.666667 10166.666667 C2 D1 18.000000 400.000000 D2 42.333333 11533.333333 D3 32.333333 13100.000000 C3 D1 44.000000 17500.000000 D2 41.000000 15300.000000 D3 41.000000 14133.333333 com_grp.agg([np.mean,np.sum]) Age Salary mean sum mean sum Company Department C1 D1 40.000000 80 13500.000000 27000 D2 34.000000 34 8000.000000 8000 D3 44.666667 134 10166.666667 30500 C2 D1 18.000000 18 400.000000 400 D2 42.333333 127 11533.333333 34600 D3 32.333333 97 13100.000000 39300 C3 D1 44.000000 44 17500.000000 17500 D2 41.000000 41 15300.000000 15300 D3 41.000000 123 14133.333333 42400 13.11.6.3 Apply Different Functions To Different Columns com_grp.agg({&#39;Age&#39;:np.mean, &#39;Salary&#39;: [np.min,np.max]}) Age Salary mean amin amax Company Department C1 D1 40.000000 12000 15000 D2 34.000000 8000 8000 D3 44.666667 2500 25000 C2 D1 18.000000 400 400 D2 42.333333 8600 14000 D3 32.333333 9800 17000 C3 D1 44.000000 17500 17500 D2 41.000000 15300 15300 D3 41.000000 7900 21000 13.11.7 Transform Transform is an operation used combined with DataFrameGroupBy object transform() return a new DataFrame object grp = company.groupby(&#39;Company&#39;) grp.size() Company C1 6 C2 7 C3 5 dtype: int64 transform() perform a function to a group, and expands and replicate it to multiple rows according to original DataFrame grp[[&#39;Age&#39;,&#39;Salary&#39;]].transform(&#39;sum&#39;) Age Salary 0 248 65500 1 248 65500 2 248 65500 3 248 65500 4 248 65500 .. … … 13 208 75200 14 208 75200 15 208 75200 16 208 75200 17 208 75200 [18 rows x 2 columns] grp.transform( lambda x:x+10 ) Age Salary 0 55 15010 1 45 12010 2 44 8010 3 33 2510 4 65 25010 .. … … 13 42 7910 14 54 17510 15 51 15310 16 64 21010 17 47 13510 [18 rows x 2 columns] 13.12 Concat 13.12.1 Sample Data s1 = pd.Series([&#39;A1&#39;,&#39;A2&#39;,&#39;A3&#39;,&#39;A4&#39;]) s2 = pd.Series([&#39;B1&#39;,&#39;B2&#39;,&#39;B3&#39;,&#39;B4&#39;]) s3 = pd.Series([&#39;C1&#39;,&#39;C2&#39;,&#39;C3&#39;,&#39;C4&#39;]) df = pd.DataFrame({ &#39;A&#39;: s1, &#39;B&#39;: s2}) df A B 0 A1 B1 1 A2 B2 2 A3 B3 3 A4 B4 13.12.2 Column-Wise 13.12.2.1 Multiple Arrays/Series Added series will have 0,1,2,… column names pd.concat([s1,s2,s3],axis=1) 0 1 2 0 A1 B1 C1 1 A2 B2 C2 2 A3 B3 C3 3 A4 B4 C4 13.12.2.2 DataFrame and Series No change to original data frame column name Added columns from series will have 0,1,2,3,.. column name pd.concat([df,s3,s1],axis=1) A B 0 1 0 A1 B1 C1 A1 1 A2 B2 C2 A2 2 A3 B3 C3 A3 3 A4 B4 C4 A4 13.12.3 Row-Wise 13.13 Fundamental Analysis 13.13.1 Structure of the Dataframe (.info()) info() is a function that print information to screen. It doesn’t return any object dataframe.info() # display columns and number of rows (that has no missing data) df.info() &lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 4 entries, 0 to 3 Data columns (total 2 columns): A 4 non-null object B 4 non-null object dtypes: object(2) memory usage: 144.0+ bytes 13.13.2 First Few Rows (.head()) dataframe.head (n) # return dataframe of first n rows, default n = 5 df.head() A B 0 A1 B1 1 A2 B2 2 A3 B3 3 A4 B4 13.14 Missing Data 13.14.1 What Is Considered Missing Data ? 13.14.2 Sample Data df = pd.DataFrame( np.random.randn(5, 3), index =[&#39;a&#39;, &#39;c&#39;, &#39;e&#39;, &#39;f&#39;, &#39;h&#39;], columns =[&#39;one&#39;, &#39;two&#39;, &#39;three&#39;]) df[&#39;four&#39;] = &#39;bar&#39; df[&#39;five&#39;] = df[&#39;one&#39;] &gt; 0 df one two three four five a -0.155909 -0.501790 0.235569 bar False c -1.763605 -1.095862 -1.087766 bar False e -0.305170 -0.473748 -0.200595 bar False f 0.355197 0.689518 0.410590 bar True h -0.564978 0.599391 -0.162936 bar False df.reindex([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;]) one two three four five a -0.155909 -0.501790 0.235569 bar False b NaN NaN NaN NaN NaN c -1.763605 -1.095862 -1.087766 bar False d NaN NaN NaN NaN NaN e -0.305170 -0.473748 -0.200595 bar False f 0.355197 0.689518 0.410590 bar True g NaN NaN NaN NaN NaN h -0.564978 0.599391 -0.162936 bar False How Missing Data For Each Column ? df.count() one 5 two 5 three 5 four 5 five 5 dtype: int64 len(df.index) - df.count() one 0 two 0 three 0 four 0 five 0 dtype: int64 df.isnull() one two three four five a False False False False False c False False False False False e False False False False False f False False False False False h False False False False False df.describe() one two three count 5.000000 5.000000 5.000000 mean -0.486893 -0.156498 -0.161028 std 0.788635 0.772882 0.579752 min -1.763605 -1.095862 -1.087766 25% -0.564978 -0.501790 -0.200595 50% -0.305170 -0.473748 -0.162936 75% -0.155909 0.599391 0.235569 max 0.355197 0.689518 0.410590 13.15 Pandas DateTime pandas contains extensive capabilities and features for working with time series data for all domains. Using the NumPy datetime64 and timedelta64 dtypes panda.Timestamp, a subclass of datetime.datetime, is pandas? scalar type for timezone-naive or timezone-aware datetime data. It mimics datetime.datime 13.16 DateTimeIndex 13.16.1 Creating Source can be string, date, datetime object 13.16.1.1 Convert From When the input is list-like, to_datetime convert to DateTimeIndex dti = pd.to_datetime([&#39;2011-01-03&#39;, # from string date(2018,4,13), # from date datetime(2018,3,1,7,30)]# from datetime ) dti DatetimeIndex([‘2011-01-03 00:00:00’, ‘2018-04-13 00:00:00’, ‘2018-03-01 07:30:00’], dtype=‘datetime64[ns]’, freq=None) dti[1] Timestamp(‘2018-04-13 00:00:00’) 13.16.2 Instance Method 13.16.2.1 Conversion to: datetime.datetime Use to_pydatetime to convert into python standard datetime object print(dti.to_pydatetime()) [datetime.datetime(2011, 1, 3, 0, 0) datetime.datetime(2018, 4, 13, 0, 0) datetime.datetime(2018, 3, 1, 7, 30)] print(type(dti.to_pydatetime())) &lt;class ‘numpy.ndarray’&gt; 13.16.2.2 Converion: to_series This creates index and data with the same value dti = pd.date_range(&#39;2018-02&#39;, periods=4, freq=&#39;M&#39;) dts = dti.to_series() print( dts) 2018-02-28 2018-02-28 2018-03-31 2018-03-31 2018-04-30 2018-04-30 2018-05-31 2018-05-31 Freq: M, dtype: datetime64[ns] print(type(dts)) &lt;class ‘pandas.core.series.Series’&gt; 13.16.2.3 Converion: to_frame() This convert to single column dataframe with index as the same value dtf = dti.to_frame() dtf 0 2018-02-28 2018-02-28 2018-03-31 2018-03-31 2018-04-30 2018-04-30 2018-05-31 2018-05-31 dtf.info() &lt;class ‘pandas.core.frame.DataFrame’&gt; DatetimeIndex: 4 entries, 2018-02-28 to 2018-05-31 Freq: M Data columns (total 1 columns): 0 4 non-null datetime64[ns] dtypes: datetime64ns memory usage: 64.0 bytes 13.16.3 Properties dti = pd.date_range(&#39;2018-02&#39;, periods=4, freq=&#39;D&#39;) print( dti.weekday ) Int64Index([3, 4, 5, 6], dtype=‘int64’) print( dti.month ) Int64Index([2, 2, 2, 2], dtype=‘int64’) "],
["matplotlib-2.html", "14 matplotlib 14.1 Library 14.2 Sample Data 14.3 MATLAB-like API 14.4 Object-Oriented API 14.5 Histogram 14.6 Scatter Plot 14.7 Bar Chart", " 14 matplotlib from IPython.core.display import display, HTML display(HTML(&quot;&lt;style&gt;.container { width:75% !important; margin-left:350px; }&lt;/style&gt;&quot;)) #%matplotlib inline &lt;IPython.core.display.HTML object&gt; import numpy as np import pandas as pd import matplotlib.pyplot as plt import math import seaborn as sns pd.set_option( &#39;display.notebook_repr_html&#39;, False) # render Series and DataFrame as text, not HTML pd.set_option( &#39;display.max_column&#39;, 10) # number of columns pd.set_option( &#39;display.max_rows&#39;, 10) # number of rows pd.set_option( &#39;display.width&#39;, 90) # number of characters per row 14.1 Library import matplotlib import matplotlib.pyplot as plt from plydata import define, query, select, group_by, summarize, arrange, head, rename import plotnine from plotnine import * import os os.environ[&#39;QT_QPA_PLATFORM_PLUGIN_PATH&#39;] = &quot;C:\\ProgramData\\Anaconda3\\Library\\plugins\\platforms&quot; 14.2 Sample Data This chapter uses the sample data generate with below code. The idea is to simulate two categorical-alike feature, and two numeric value feature: com is random character between ?C1?, ?C2? and ?C3? dept is random character between ?D1?, ?D2?, ?D3?, ?D4? and ?D5? grp is random character with randomly generated ?G1?, ?G2? value1 represents numeric value, normally distributed at mean 50 value2 is numeric value, normally distributed at mean 25 n = 200 comp = [&#39;C&#39; + i for i in np.random.randint( 1,4, size = n).astype(str)] # 3x Company dept = [&#39;D&#39; + i for i in np.random.randint( 1,6, size = n).astype(str)] # 5x Department grp = [&#39;G&#39; + i for i in np.random.randint( 1,3, size = n).astype(str)] # 2x Groups value1 = np.random.normal( loc=50 , scale=5 , size = n) value2 = np.random.normal( loc=20 , scale=3 , size = n) value3 = np.random.normal( loc=5 , scale=30 , size = n) mydf = pd.DataFrame({ &#39;comp&#39;:comp, &#39;dept&#39;:dept, &#39;grp&#39;: grp, &#39;value1&#39;:value1, &#39;value2&#39;:value2, &#39;value3&#39;:value3 }) mydf.head() comp dept grp value1 value2 value3 0 C3 D1 G2 58.001073 20.797796 4.565181 1 C2 D4 G2 47.122054 20.691133 36.084163 2 C3 D5 G1 49.497686 15.715835 7.232685 3 C1 D3 G2 50.129623 26.790262 -6.875583 4 C3 D3 G1 51.620032 23.704337 11.909618 mydf.info() &lt;class ‘pandas.core.frame.DataFrame’&gt; RangeIndex: 200 entries, 0 to 199 Data columns (total 6 columns): comp 200 non-null object dept 200 non-null object grp 200 non-null object value1 200 non-null float64 value2 200 non-null float64 value3 200 non-null float64 dtypes: float64(3), object(3) memory usage: 9.5+ KB 14.3 MATLAB-like API The good thing about the pylab MATLAB-style API is that it is easy to get started with if you are familiar with MATLAB, and it has a minumum of coding overhead for simple plots. However, I’d encourrage not using the MATLAB compatible API for anything but the simplest figures. Instead, I recommend learning and using matplotlib’s object-oriented plotting API. It is remarkably powerful. For advanced figures with subplots, insets and other components it is very nice to work with. 14.3.1 Sample Data # Sample Data x = np.linspace(0,5,10) y = x ** 2 14.3.2 Single Plot #plt.figure() #plt.xlabel(&#39;x&#39;) #plt.ylabel(&#39;y&#39;) #plt.plot(x,y,&#39;red&#39;) #plt.title(&#39;My Good Data&#39;) #plt.show() 14.3.3 Multiple Subplots Each call lto subplot() will create a new container for subsequent plot command plt.figure() &lt;Figure size 267.36x250 with 0 Axes&gt; plt.subplot(1,2,1) # 1 row, 2 cols, at first box &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000028897FD0&gt; plt.plot(x,y,&#39;r--&#39;) [&lt;matplotlib.lines.Line2D object at 0x000000002A93B128&gt;] plt.subplot(1,2,2) # 1 row, 2 cols, at second box &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002A92BEF0&gt; plt.plot(y,x,&#39;g*-&#39;) [&lt;matplotlib.lines.Line2D object at 0x000000002B940AC8&gt;] plt.show() 14.4 Object-Oriented API 14.4.1 Sample Data # Sample Data x = np.linspace(0,5,10) y = x ** 2 14.4.2 Single Plot One figure, one axes fig = plt.figure() axes = fig.add_axes([0,0,1,1]) # left, bottom, width, height (range 0 to 1) axes.plot(x, y, &#39;r&#39;) [&lt;matplotlib.lines.Line2D object at 0x000000002A92BF98&gt;] axes.set_xlabel(&#39;x&#39;) Text(0.5, 0, ‘x’) axes.set_ylabel(&#39;y&#39;) Text(0, 0.5, ‘y’) axes.set_title(&#39;title&#39;) Text(0.5, 1.0, ‘title’) plt.show() 14.4.3 Multiple Axes In One Plot This is still considered a single plot, but with multiple axes fig = plt.figure() ax1 = fig.add_axes([0, 0, 1, 1]) # main axes ax2 = fig.add_axes([0.2, 0.5, 0.4, 0.3]) # inset axes ax1.plot(x,y,&#39;r&#39;) [&lt;matplotlib.lines.Line2D object at 0x000000002BA23AC8&gt;] ax1.set_xlabel(&#39;x&#39;) Text(0.5, 0, ‘x’) ax1.set_ylabel(&#39;y&#39;) Text(0, 0.5, ‘y’) ax2.plot(y, x, &#39;g&#39;) [&lt;matplotlib.lines.Line2D object at 0x000000002A93B048&gt;] ax2.set_xlabel(&#39;y&#39;) Text(0.5, 0, ‘y’) ax2.set_ylabel(&#39;x&#39;) Text(0, 0.5, ‘x’) ax2.set_title(&#39;insert title&#39;) Text(0.5, 1.0, ‘insert title’) plt.show() 14.4.4 Multiple Subplots One figure can contain multiple subplots Each subplot has one axes 14.4.4.1 Simple Subplots - all same size subplots() function return axes object that is iterable. Single Row Grid Single row grid means axes is an 1-D array. Hence can use for to iterate through axes fig, axes = plt.subplots( nrows=1,ncols=3 ) print (axes.shape) (3,) for ax in axes: ax.plot(x, y, &#39;r&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_title(&#39;title&#39;) ax.text(0.2,0.5,&#39;One&#39;) [&lt;matplotlib.lines.Line2D object at 0x000000002BB0C1D0&gt;] Text(0.5, 0, ‘x’) Text(0, 0.5, ‘y’) Text(0.5, 1.0, ‘title’) Text(0.2, 0.5, ‘One’) [&lt;matplotlib.lines.Line2D object at 0x000000002BB0C7B8&gt;] Text(0.5, 0, ‘x’) Text(0, 0.5, ‘y’) Text(0.5, 1.0, ‘title’) Text(0.2, 0.5, ‘One’) [&lt;matplotlib.lines.Line2D object at 0x000000002BB0CD30&gt;] Text(0.5, 0, ‘x’) Text(0, 0.5, ‘y’) Text(0.5, 1.0, ‘title’) Text(0.2, 0.5, ‘One’) plt.show() Multiple Row Grid Multile row grid means axes is an 2-D array. Hence can use two levels of for loop to iterate through each row and column fig, axes = plt.subplots(2, 3, sharex=&#39;col&#39;, sharey=&#39;row&#39;) print (axes.shape) (2, 3) for i in range(axes.shape[0]): for j in range(axes.shape[1]): axes[i, j].text(0.5, 0.5, str((i, j)), fontsize=18, ha=&#39;center&#39;) Text(0.5, 0.5, ‘(0, 0)’) Text(0.5, 0.5, ‘(0, 1)’) Text(0.5, 0.5, ‘(0, 2)’) Text(0.5, 0.5, ‘(1, 0)’) Text(0.5, 0.5, ‘(1, 1)’) Text(0.5, 0.5, ‘(1, 2)’) plt.show() 14.4.4.2 Complicated Subplots - different size GridSpec specify grid size of the figure Manually specify each subplot and their relevant grid position and size plt.figure(figsize=(5,5)) &lt;Figure size 500x500 with 0 Axes&gt; grid = plt.GridSpec(2, 3, hspace=0.4, wspace=0.4) plt.subplot(grid[0, 0]) #row 0, col 0 &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BC9A358&gt; plt.subplot(grid[0, 1:]) #row 0, col 1 to : &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BCD9CC0&gt; plt.subplot(grid[1, :2]) #row 1, col 0:2 &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BD0EFD0&gt; plt.subplot(grid[1, 2]); #row 1, col 2 &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BD485F8&gt; plt.show() plt.figure(figsize=(5,5)) &lt;Figure size 500x500 with 0 Axes&gt; grid = plt.GridSpec(4, 4, hspace=0.8, wspace=0.4) plt.subplot(grid[:3, 0]) # row 0:3, col 0 &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BD5E320&gt; plt.subplot(grid[:3, 1: ]) # row 0:3, col 1: &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002C1500F0&gt; plt.subplot(grid[3, 1: ]); # row 3, col 1: &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BDC1C50&gt; plt.show() -1 means last row or column plt.figure(figsize=(6,6)) &lt;Figure size 600x600 with 0 Axes&gt; grid = plt.GridSpec(4, 4, hspace=0.4, wspace=1.2) plt.subplot(grid[:-1, 0 ]) # row 0 till last row (not including last row), col 0 &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000288CF0F0&gt; plt.subplot(grid[:-1, 1:]) # row 0 till last row (not including last row), col 1 till end &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BD92E80&gt; plt.subplot(grid[-1, 1: ]); # row last row, col 1 till end &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BD25BE0&gt; plt.show() 14.4.5 Figure Customization 14.4.5.1 Avoid Overlap - Use tight_layout() Sometimes when the figure size is too small, plots will overlap each other. - tight_layout() will introduce extra white space in between the subplots to avoid overlap. - The figure became wider. fig, axes = plt.subplots( nrows=1,ncols=2) for ax in axes: ax.plot(x, y, &#39;r&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_title(&#39;title&#39;) [&lt;matplotlib.lines.Line2D object at 0x000000002BA3FB70&gt;] Text(0.5, 0, ‘x’) Text(0, 0.5, ‘y’) Text(0.5, 1.0, ‘title’) [&lt;matplotlib.lines.Line2D object at 0x000000002BD98C18&gt;] Text(0.5, 0, ‘x’) Text(0, 0.5, ‘y’) Text(0.5, 1.0, ‘title’) fig.tight_layout() # adjust the positions of axes so that there is no overlap plt.show() 14.4.5.2 Avoid Overlap - Change Figure Size fig, axes = plt.subplots( nrows=1,ncols=2,figsize=(12,3)) for ax in axes: ax.plot(x, y, &#39;r&#39;) ax.set_xlabel(&#39;x&#39;) ax.set_ylabel(&#39;y&#39;) ax.set_title(&#39;title&#39;) [&lt;matplotlib.lines.Line2D object at 0x00000000288D6B00&gt;] Text(0.5, 0, ‘x’) Text(0, 0.5, ‘y’) Text(0.5, 1.0, ‘title’) [&lt;matplotlib.lines.Line2D object at 0x000000002B9A3B00&gt;] Text(0.5, 0, ‘x’) Text(0, 0.5, ‘y’) Text(0.5, 1.0, ‘title’) plt.show() 14.4.5.3 Text Within Figure fig = plt.figure() fig.text(0.5, 0.5, &#39;This Is A Sample&#39;,fontsize=18, ha=&#39;center&#39;); Text(0.5, 0.5, ‘This Is A Sample’) axes = fig.add_axes([0,0,1,1]) # left, bottom, width, height (range 0 to 1) plt.show() 14.4.6 Axes Customization 14.4.6.1 Y-Axis Limit fig = plt.figure() fig.add_axes([0,0,1,1], ylim=(-2,5)); &lt;matplotlib.axes._axes.Axes object at 0x000000002BDA1D30&gt; plt.show() 14.4.6.2 Text Within Axes fig, ax = plt.subplots(2, 3, sharex=&#39;col&#39;, sharey=&#39;row&#39;) for i in range(2): for j in range(3): ax[i, j].text(0.5, 0.5, str((i, j)), fontsize=18, ha=&#39;center&#39;) Text(0.5, 0.5, ‘(0, 0)’) Text(0.5, 0.5, ‘(0, 1)’) Text(0.5, 0.5, ‘(0, 2)’) Text(0.5, 0.5, ‘(1, 0)’) Text(0.5, 0.5, ‘(1, 1)’) Text(0.5, 0.5, ‘(1, 2)’) plt.show() plt.text(0.5, 0.5, &#39;one&#39;,fontsize=18, ha=&#39;center&#39;) Text(0.5, 0.5, ‘one’) plt.show() 14.4.6.3 Share Y Axis Label fig, ax = plt.subplots(2, 3, sharex=&#39;col&#39;, sharey=&#39;row&#39;) # removed inner label plt.show() 14.4.6.4 Create Subplot Individually Each call lto subplot() will create a new container for subsequent plot command plt.subplot(2,4,1) &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000068CEE10&gt; plt.text(0.5, 0.5, &#39;one&#39;,fontsize=18, ha=&#39;center&#39;) Text(0.5, 0.5, ‘one’) plt.subplot(2,4,8) &lt;matplotlib.axes._subplots.AxesSubplot object at 0x00000000066ED518&gt; plt.text(0.5, 0.5, &#39;eight&#39;,fontsize=18, ha=&#39;center&#39;) Text(0.5, 0.5, ‘eight’) plt.show() Iterate through subplots (ax) to populate them fig, ax = plt.subplots(2, 3, sharex=&#39;col&#39;, sharey=&#39;row&#39;) for i in range(2): for j in range(3): ax[i, j].text(0.5, 0.5, str((i, j)), fontsize=18, ha=&#39;center&#39;) Text(0.5, 0.5, ‘(0, 0)’) Text(0.5, 0.5, ‘(0, 1)’) Text(0.5, 0.5, ‘(0, 2)’) Text(0.5, 0.5, ‘(1, 0)’) Text(0.5, 0.5, ‘(1, 1)’) Text(0.5, 0.5, ‘(1, 2)’) plt.show() 14.5 Histogram plt.hist(mydf.value1, bins=12); (array([ 2., 4., 10., 16., 35., 38., 31., 27., 22., 6., 6., 3.]), array([37.09329803, 39.25349925, 41.41370047, 43.57390169, 45.73410291, 47.89430413, 50.05450535, 52.21470657, 54.37490779, 56.53510901, 58.69531023, 60.85551145, 63.01571267]), &lt;a list of 12 Patch objects&gt;) plt.show() 14.6 Scatter Plot plt.scatter(mydf.value1, mydf.value2) &lt;matplotlib.collections.PathCollection object at 0x00000000067B0B00&gt; plt.show() 14.7 Bar Chart com_grp = mydf.groupby(&#39;comp&#39;) grpdf = com_grp[&#39;value1&#39;].sum().reset_index() grpdf comp value1 0 C1 3988.891405 1 C2 3007.230028 2 C3 3017.883718 plt.bar(grpdf.comp, grpdf.value1); &lt;BarContainer object of 3 artists&gt; plt.xlabel(&#39;Company&#39;) Text(0.5, 0, ‘Company’) plt.ylabel(&#39;Sum of Value 1&#39;) Text(0, 0.5, ‘Sum of Value 1’) plt.show() "],
["seaborn.html", "15 seaborn 15.1 Seaborn and Matplotlib 15.2 Sample Data 15.3 Scatter Plot 15.4 Histogram 15.5 Bar Chart 15.6 Faceting 15.7 Pair Grid", " 15 seaborn 15.1 Seaborn and Matplotlib seaborn returns a matplotlib object that can be modified by the options in the pyplot module Often, these options are wrapped by seaborn and .plot() in pandas and available as arguments 15.2 Sample Data n = 100 comp = [&#39;C&#39; + i for i in np.random.randint( 1,4, size = n).astype(str)] # 3x Company dept = [&#39;D&#39; + i for i in np.random.randint( 1,4, size = n).astype(str)] # 5x Department grp = [&#39;G&#39; + i for i in np.random.randint( 1,4, size = n).astype(str)] # 2x Groups value1 = np.random.normal( loc=50 , scale=5 , size = n) value2 = np.random.normal( loc=20 , scale=3 , size = n) value3 = np.random.normal( loc=5 , scale=30 , size = n) mydf = pd.DataFrame({ &#39;comp&#39;:comp, &#39;dept&#39;:dept, &#39;grp&#39;: grp, &#39;value1&#39;:value1, &#39;value2&#39;:value2, &#39;value3&#39;:value3 }) mydf.head() comp dept grp value1 value2 value3 0 C2 D2 G1 58.413310 17.257990 8.308861 1 C2 D2 G1 40.941753 15.972926 -40.682326 2 C1 D1 G2 50.870315 19.156772 11.312435 3 C2 D1 G2 34.040375 20.682569 -2.149571 4 C3 D2 G1 43.585637 20.666183 59.560983 15.3 Scatter Plot 15.3.1 2x Numeric sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, data=mydf) &lt;seaborn.axisgrid.FacetGrid object at 0x00000000067067F0&gt; plt.show() sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, fit_reg=False, data=mydf); #hide regresion line &lt;seaborn.axisgrid.FacetGrid object at 0x000000002A92BBE0&gt; plt.show() 15.3.2 2xNumeric + 1x Categorical Use hue to represent additional categorical feature sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, data=mydf, hue=&#39;comp&#39;, fit_reg=False); &lt;seaborn.axisgrid.FacetGrid object at 0x00000000066D6EB8&gt; plt.show() 15.3.3 2xNumeric + 2x Categorical Use col and hue to represent two categorical features sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, col=&#39;comp&#39;,hue=&#39;grp&#39;, fit_reg=False, data=mydf); &lt;seaborn.axisgrid.FacetGrid object at 0x00000000289902B0&gt; plt.show() 15.3.4 2xNumeric + 3x Categorical Use row, col and hue to represent three categorical features sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, row=&#39;dept&#39;,col=&#39;comp&#39;, hue=&#39;grp&#39;, fit_reg=False, data=mydf); &lt;seaborn.axisgrid.FacetGrid object at 0x000000002BDE0978&gt; plt.show() 15.3.5 Customization 15.3.5.1 size size: height in inch for each facet sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, col=&#39;comp&#39;,hue=&#39;grp&#39;, size=3,fit_reg=False, data=mydf) &lt;seaborn.axisgrid.FacetGrid object at 0x000000002BC7D400&gt; C:3-packages.py:546: UserWarning: The size paramter has been renamed to height; please update your code. warnings.warn(msg, UserWarning) C:3-packages.py:311: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). fig, axes = plt.subplots(nrow, ncol, **kwargs) plt.show() Observe that even size is very large, lmplot will fit (shrink) everything into one row by deafult. See example below. sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, col=&#39;comp&#39;,hue=&#39;grp&#39;, size=5,fit_reg=False, data=mydf) &lt;seaborn.axisgrid.FacetGrid object at 0x000000002BD48CF8&gt; plt.show() 15.3.5.2 col_wrap To avoid lmplot from shrinking the chart, we use col_wrap=&lt;col_number to wrap the output. Compare the size (height of each facet) with the above without col_wrap. Below chart is larger. sns.lmplot(x=&#39;value1&#39;, y=&#39;value2&#39;, col=&#39;comp&#39;,hue=&#39;grp&#39;, size=5, col_wrap=2, fit_reg=False, data=mydf) &lt;seaborn.axisgrid.FacetGrid object at 0x0000000028990D30&gt; C:3-packages.py:320: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). fig = plt.figure(figsize=figsize) plt.show() 15.4 Histogram seaborn.distplot( a, # Series, 1D Array or List bins=None, hist=True, rug = False, vertical=False ) 15.4.1 1x Numeric sns.distplot(mydf.value1) &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000006A269B0&gt; plt.show() sns.distplot(mydf.value1,hist=True,rug=True,vertical=True, bins=30,color=&#39;g&#39;) &lt;matplotlib.axes._subplots.AxesSubplot object at 0x0000000006843A20&gt; plt.show() 15.5 Bar Chart com_grp = mydf.groupby(&#39;comp&#39;) grpdf = com_grp[&#39;value1&#39;].sum().reset_index() grpdf comp value1 0 C1 1343.247772 1 C2 1871.515883 2 C3 1783.986137 15.5.1 1x Categorical, 1x Numeric sns.barplot(x=&#39;comp&#39;,y=&#39;value1&#39;,data=grpdf) &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002C156470&gt; plt.show() 15.5.2 Customization 15.5.2.1 Ordering sns.barplot(x=&#39;comp&#39;,y=&#39;value2&#39;, hue=&#39;grp&#39;, order=[&#39;C3&#39;,&#39;C2&#39;,&#39;C1&#39;], hue_order=[&#39;G1&#39;,&#39;G2&#39;,&#39;G3&#39;], data=mydf ) &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BAB5E48&gt; plt.show() 15.5.2.2 Flipping X/Y Axis sns.barplot(x=&#39;value2&#39;,y=&#39;comp&#39;, hue=&#39;grp&#39;,data=mydf) &lt;matplotlib.axes._subplots.AxesSubplot object at 0x000000002BC251D0&gt; plt.show() 15.6 Faceting Faceting in Seaborn is a generic function that works with matplotlib various plot utility. It support matplotlib as well as seaborn plotting utility. 15.6.1 Faceting Histogram g = sns.FacetGrid(mydf, col=&quot;comp&quot;, row=&#39;dept&#39;) g.map(plt.hist, &quot;value1&quot;) &lt;seaborn.axisgrid.FacetGrid object at 0x000000002BDD77F0&gt; plt.show() g = sns.FacetGrid(mydf, col=&quot;comp&quot;, row=&#39;dept&#39;) g.map(plt.hist, &quot;value1&quot;) &lt;seaborn.axisgrid.FacetGrid object at 0x0000000007112E80&gt; plt.show() 15.6.2 Faceting Scatter Plot g = sns.FacetGrid(mydf, col=&quot;comp&quot;, row=&#39;dept&#39;,hue=&#39;grp&#39;) g.map(plt.scatter, &quot;value1&quot;,&quot;value2&quot;,alpha=0.7); &lt;seaborn.axisgrid.FacetGrid object at 0x00000000067ABE80&gt; g.add_legend() &lt;seaborn.axisgrid.FacetGrid object at 0x00000000067ABE80&gt; plt.show() 15.7 Pair Grid 15.7.1 Simple Pair Grid g = sns.PairGrid(mydf, hue=&#39;comp&#39;) C:3-packages.py:1270: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). squeeze=False) g.map(plt.scatter); &lt;seaborn.axisgrid.PairGrid object at 0x000000002BC91A58&gt; g.add_legend() &lt;seaborn.axisgrid.PairGrid object at 0x000000002BC91A58&gt; plt.show() 15.7.2 Different Diag and OffDiag g = sns.PairGrid(mydf, hue=&#39;comp&#39;) g.map_diag(plt.hist, bins=15) &lt;seaborn.axisgrid.PairGrid object at 0x000000002BC91EF0&gt; g.map_offdiag(plt.scatter) &lt;seaborn.axisgrid.PairGrid object at 0x000000002BC91EF0&gt; g.add_legend() &lt;seaborn.axisgrid.PairGrid object at 0x000000002BC91EF0&gt; plt.show() "],
["plotnine.html", "16 plotnine 16.1 Histogram 16.2 Scatter Plot 16.3 Line Chart 16.4 Bar Chart", " 16 plotnine 16.1 Histogram 16.1.1 1xNumeric plotnine.ggplot( dataframe, aex(x=&#39;colName&#39;)) + geom_histogram( bins=10 ) plotnine.ggplot( dataframe, aex(x=&#39;colName&#39;)) + geom_histogram( binwidth=? ) plotnine.options.figure_size = (3, 3) ggplot(mydf, aes(x=&#39;value1&#39;)) + geom_histogram() # default bins = 10 &lt;ggplot: (45928112)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages_bin.py:93: UserWarning: ‘stat_bin()’ using ‘bins = 10’. Pick better value with ‘binwidth’. warn(msg.format(params[‘bins’])) C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) ggplot(mydf, aes(x=&#39;value1&#39;)) + geom_histogram(bins = 15) &lt;ggplot: (45969058)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) ggplot(mydf, aes(x=&#39;value1&#39;)) + geom_histogram(binwidth = 3) &lt;ggplot: (-9223372036848008027)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.1.2 1xNumeric + 1xCategorical plotnine.ggplot( dataframe, aes(x=&#39;colName&#39;), fill=&#39;categorical-alike-colName&#39;) + geom_histogram() ggplot(mydf, aes(x=&#39;value1&#39;, fill=&#39;grp&#39;)) + geom_histogram(bins=15) &lt;ggplot: (6733993)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.2 Scatter Plot 16.2.1 2x Numeric ggplot(mydf, aes(x=&#39;value1&#39;,y=&#39;value2&#39;)) + geom_point() &lt;ggplot: (-9223372036847969073)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.2.2 2x Numeric + 1x Categorical ggplot( DataFrame, aes(x=&#39;colName1&#39;,y=&#39;colName2&#39;)) + geom_point( aes( color=&#39;categorical-alike-colName&#39;, size=&#39;numberColName&#39; )) ggplot(mydf, aes(x=&#39;value1&#39;,y=&#39;value2&#39;)) + geom_point(aes(color=&#39;grp&#39;)) &lt;ggplot: (45995875)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) ggplot(mydf, aes(x=&#39;value1&#39;,y=&#39;value2&#39;,color=&#39;grp&#39;)) + geom_point() &lt;ggplot: (-9223372036808546437)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) ggplot(mydf, aes(x=&#39;value1&#39;,y=&#39;value2&#39;)) + \\ geom_point(aes( color=&#39;grp&#39; )) &lt;ggplot: (6873180)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.2.3 2x Numeric + 1x Numeric + 1x Categorical ggplot(mydf, aes(x=&#39;value1&#39;,y=&#39;value2&#39;)) + \\ geom_point(aes( color=&#39;grp&#39;, size=&#39;value3&#39; )) &lt;ggplot: (6821149)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.2.4 Overlay Smooth Line ggplot(mydf, aes(x=&#39;value1&#39;, y=&#39;value2&#39;)) + \\ geom_point() + \\ geom_smooth() # default method=&#39;loess&#39; &lt;ggplot: (6742641)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:146: UserWarning: Confidence intervals are not yet implementedfor lowess smoothings. warnings.warn(“Confidence intervals are not yet implemented” C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) ggplot(mydf, aes(x=&#39;value1&#39;, y=&#39;value2&#39;,fill=&#39;grp&#39;)) + \\ geom_point() + \\ geom_smooth( se=True, color=&#39;red&#39;, method=&#39;lm&#39;, level=0.75) &lt;ggplot: (-9223372036846067305)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.3 Line Chart 16.3.1 2x Numeric Data ggplot (mydf.head(15), aes(x=&#39;value1&#39;, y=&#39;value2&#39;)) + geom_line() &lt;ggplot: (-9223372036808984460)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.3.2 1x Numeric, 1x Categorical ggplot (mydf.head(15), aes(x=&#39;dept&#39;, y=&#39;value1&#39;)) + geom_line() &lt;ggplot: (-9223372036847935800)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) ggplot (mydf.head(30), aes(x=&#39;dept&#39;, y=&#39;value1&#39;)) + geom_line( aes(group=1)) &lt;ggplot: (46028152)&gt; C:3-packages.py:517: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return not cbook.iterable(value) and (cbook.is_numlike(value) or C:3-packages.py:517: MatplotlibDeprecationWarning: The is_numlike function was deprecated in Matplotlib 3.0 and will be removed in 3.2. Use isinstance(…, numbers.Number) instead. return not cbook.iterable(value) and (cbook.is_numlike(value) or C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.3.3 2x Numeric, 1x Categorical ggplot (mydf.head(15), aes(x=&#39;value1&#39;, y=&#39;value2&#39;)) + geom_line( aes(color=&#39;grp&#39;),size=2) &lt;ggplot: (-9223372036809018431)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) 16.4 Bar Chart 16.4.0.1 1x Categorical Single categorical variable produces frequency chart. tmpdf = mydf.groupby([&#39;comp&#39;],as_index=False).count() tmpdf comp dept grp value1 value2 value3 0 C1 27 27 27 27 27 1 C2 37 37 37 37 37 2 C3 36 36 36 36 36 tmpdf.info() &lt;class ‘pandas.core.frame.DataFrame’&gt; Int64Index: 3 entries, 0 to 2 Data columns (total 6 columns): comp 3 non-null object dept 3 non-null int64 grp 3 non-null int64 value1 3 non-null int64 value2 3 non-null int64 value3 3 non-null int64 dtypes: int64(5), object(1) memory usage: 168.0+ bytes ggplot (tmpdf, aes(x=&#39;comp&#39;, y=&#39;grp&#39;)) +geom_col() &lt;ggplot: (-9223372036809035979)&gt; C:3-packages.py:93: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. if cbook.iterable(self.breaks) and cbook.iterable(self.labels): C:3-packages.py:367: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). figure = plt.figure() C:3-packages.py:553: MatplotlibDeprecationWarning: The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead. return cbook.iterable(var) and not is_string(var) "],
["sklearn.html", "17 sklearn 17.1 Setup (hidden) 17.2 The Library 17.3 Model Fitting 17.4 Model Tuning 17.5 High Level ML Process 17.6 Built-in Datasets 17.7 Train Test Data Splitting 17.8 Polynomial Transform 17.9 Imputation of Missing Data 17.10 Scaling 17.11 Pipeline 17.12 Cross Validation", " 17 sklearn This is a machine learning library. 17.1 Setup (hidden) from IPython.core.display import display, HTML display(HTML(&quot;&lt;style&gt;.container { width:75% !important; margin-left:350px; }&lt;/style&gt;&quot;)) #matplotlib inline &lt;IPython.core.display.HTML object&gt; import numpy as np import pandas as pd import matplotlib.pyplot as plt import math pd.set_option( &#39;display.notebook_repr_html&#39;, False) # render Series and DataFrame as text, not HTML pd.set_option( &#39;display.max_column&#39;, 10) # number of columns pd.set_option( &#39;display.max_rows&#39;, 10) # number of rows pd.set_option( &#39;display.width&#39;, 90) # number of characters per row import matplotlib.pyplot as plt 17.2 The Library sklearn does not automatically import its subpackages. Therefore all subpakcages must be specifically loaded before use. # Sample Data from sklearn import datasets # Model Selection from sklearn.model_selection import train_test_split from sklearn.model_selection import KFold from sklearn.model_selection import LeaveOneOut from sklearn.model_selection import cross_validate # Preprocessing from sklearn.preprocessing import Imputer from sklearn.preprocessing import MinMaxScaler from sklearn.preprocessing import StandardScaler from sklearn.preprocessing import Normalizer from sklearn.preprocessing import PolynomialFeatures # Model and Pipeline from sklearn.linear_model import LinearRegression,Lasso from sklearn.pipeline import make_pipeline # Measurement from sklearn.metrics import * import statsmodels.formula.api as smf 17.3 Model Fitting split 17.3.1 Underfitting The model does not fit the training data and therefore misses the trends in the data The model cannot be generalized to new data, this is usually the result of a very simple model (not enough predictors/independent variables) The model will have poor predictive ability For example, we fit a linear model (like linear regression) to data that is not linear 17.3.2 Overfitting The model has trained ?too well? and is now, well, fit too closely to the training dataset The model is too complex (i.e. too many features/variables compared to the number of observations) The model will be very accurate on the training data but will probably be very not accurate on untrained or new data The model is not generalized (or not AS generalized), meaning you can generalize the results The model learns or describes the ?noise? in the training data instead of the actual relationships between variables in the data 17.3.3 Just Right It is worth noting the underfitting is not as prevalent as overfitting Nevertheless, we want to avoid both of those problems in data analysis We want to find the middle ground between under and overfitting our model 17.4 Model Tuning A highly complex model tend to overfit A too flexible model tend to underfit Complexity can be reduced by: - Less features - Less degree of polynomial features - Apply generalization (tuning hyperparameters) split 17.5 High Level ML Process split 17.6 Built-in Datasets sklearn included some popular datasets to play with Each dataset is of type Bunch. It has useful data (array) in the form of properties: - keys (display all data availabe within the dataset) - data (common) - target (common) - DESCR (common) - feature_names (some dataset) - target_names (some dataset) - images (some dataset) 17.6.1 diabetes (regression) 17.6.1.1 Load Dataset diabetes = datasets.load_diabetes() print (type(diabetes)) &lt;class ‘sklearn.utils.Bunch’&gt; 17.6.1.2 keys diabetes.keys() dict_keys([‘data’, ‘target’, ‘DESCR’, ‘feature_names’, ‘data_filename’, ‘target_filename’]) 17.6.1.3 Features and Target .data = features - two dimension array .target = target - one dimension array print (type(diabetes.data)) &lt;class ‘numpy.ndarray’&gt; print (type(diabetes.target)) &lt;class ‘numpy.ndarray’&gt; print (diabetes.data.shape) (442, 10) print (diabetes.target.shape) (442,) 17.6.1.4 Load with X,y (Convenient Method) using return_X_y = True, data is loaded into X, target is loaded into y X,y = datasets.load_diabetes(return_X_y=True) print (X.shape) (442, 10) print (y.shape) (442,) 17.6.2 digits (Classification) This is a copy of the test set of the UCI ML hand-written digits datasets digits = datasets.load_digits() print (type(digits)) &lt;class ‘sklearn.utils.Bunch’&gt; print (type(digits.data)) &lt;class ‘numpy.ndarray’&gt; digits.keys() dict_keys([‘data’, ‘target’, ‘target_names’, ‘images’, ‘DESCR’]) digits.target_names array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 17.6.2.1 data digits.data.shape # features (1797, 64) digits.target.shape # target (1797,) 17.6.2.2 Images images is 3 dimensional array There are 1797 samples, each sample is 8x8 pixels digits.images.shape (1797, 8, 8) type(digits.images) &lt;class ‘numpy.ndarray’&gt; Each element represent the data that make its target print (digits.target[100]) 4 print (digits.images[100]) [[ 0. 0. 0. 2. 13. 0. 0. 0.] [ 0. 0. 0. 8. 15. 0. 0. 0.] [ 0. 0. 5. 16. 5. 2. 0. 0.] [ 0. 0. 15. 12. 1. 16. 4. 0.] [ 0. 4. 16. 2. 9. 16. 8. 0.] [ 0. 0. 10. 14. 16. 16. 4. 0.] [ 0. 0. 0. 0. 13. 8. 0. 0.] [ 0. 0. 0. 0. 13. 6. 0. 0.]] plt.matshow(digits.images[100]) &lt;matplotlib.image.AxesImage object at 0x000000002BD679E8&gt; C:/ProgramData/Anaconda3/python.exe:1: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (matplotlib.pyplot.figure) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam figure.max_open_warning). 17.6.2.3 Loading Into X,y (Convenient Method) X,y = datasets.load_digits(return_X_y=True) X.shape (1797, 64) y.shape (1797,) 17.6.3 iris (Classification) iris = datasets.load_iris() iris.keys() dict_keys([‘data’, ‘target’, ‘target_names’, ‘DESCR’, ‘feature_names’, ‘filename’]) 17.6.3.1 Feature Names iris.feature_names [‘sepal length (cm)’, ‘sepal width (cm)’, ‘petal length (cm)’, ‘petal width (cm)’] 17.6.3.2 target iris.target_names array([‘setosa’, ‘versicolor’, ‘virginica’], dtype=‘&lt;U10’) iris.target array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]) 17.7 Train Test Data Splitting 17.7.1 Sample Data Generate 100 rows of data, with 3x features (X1,X2,X3), and one dependant variable (Y) n = 21 # number of samples I = 5 # intercept value E = np.random.randint( 1,20, n) # Error x1 = np.random.randint( 1,n+1, n) x2 = np.random.randint( 1,n+1, n) x3 = np.random.randint( 1,n+1, n) y = 0.1*x1 + 0.2*x2 + 0.3*x3 + E + I mydf = pd.DataFrame({ &#39;y&#39;:y, &#39;x1&#39;:x1, &#39;x2&#39;:x2, &#39;x3&#39;:x3 }) mydf.shape (21, 4) 17.7.2 One Time Split sklearn::train_test_split() has two forms: - Take one DF, split into 2 DF (most of sklearn modeling use this method - Take two DFs, split into 4 DF mydf.head() y x1 x2 x3 0 14.4 14 7 12 1 14.3 18 5 5 2 26.4 14 11 6 3 14.8 3 21 1 4 11.5 4 13 5 17.7.2.1 Method 1: Split One Dataframe Into Two (Train &amp; Test) traindf, testdf = train_test_split( df, test_size=, random_state= ) # random_state : seed number (integer), optional # test_size : fraction of 1, 0.2 means 20% split traindf, testdf = train_test_split(mydf,test_size=0.2, random_state=25) print (len(traindf)) 16 print (len(testdf)) 5 17.7.2.2 Method 2: Split Two DataFrame (X,Y) into Four x_train/test, y_train/test x_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=, random_state= ) # random_state : seed number (integer), optional # test_size : fraction of 1, 0.2 means 20% split Split DataFrame into X and Y First feature_cols = [&#39;x1&#39;,&#39;x2&#39;,&#39;x3&#39;] X = mydf[feature_cols] Y = mydf.y Then Split X/Y into x_train/test, y_train/test x_train, x_test, y_train, y_test = train_test_split( X,Y, test_size=0.2, random_state=25) print (len(x_train)) 16 print (len(x_test)) 5 17.7.3 K-Fold KFold(n_splits=3, shuffle=False, random_state=None) split suffle=False (default), meaning index number is taken continously kf = KFold(n_splits=7) for train_index, test_index in kf.split(X): print (train_index, test_index) [ 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [0 1 2] [ 0 1 2 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [3 4 5] [ 0 1 2 3 4 5 9 10 11 12 13 14 15 16 17 18 19 20] [6 7 8] [ 0 1 2 3 4 5 6 7 8 12 13 14 15 16 17 18 19 20] [ 9 10 11] [ 0 1 2 3 4 5 6 7 8 9 10 11 15 16 17 18 19 20] [12 13 14] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 18 19 20] [15 16 17] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17] [18 19 20] shuffle=True kf = KFold(n_splits=7, shuffle=True) for train_index, test_index in kf.split(X): print (train_index, test_index) [ 0 1 2 3 4 6 7 8 9 10 11 12 13 14 15 16 17 19] [ 5 18 20] [ 0 1 3 4 5 6 7 8 10 11 12 13 15 16 17 18 19 20] [ 2 9 14] [ 0 1 2 3 4 5 6 7 8 9 11 12 14 15 16 17 18 20] [10 13 19] [ 1 2 3 5 6 7 8 9 10 11 12 13 14 15 17 18 19 20] [ 0 4 16] [ 0 2 4 5 6 7 8 9 10 12 13 14 15 16 17 18 19 20] [ 1 3 11] [ 0 1 2 3 4 5 6 9 10 11 12 13 14 15 16 18 19 20] [ 7 8 17] [ 0 1 2 3 4 5 7 8 9 10 11 13 14 16 17 18 19 20] [ 6 12 15] 17.7.4 Leave One Out For a dataset of N rows, Leave One Out will split N-1 times, each time leaving one row as test, remaning as training set. Due to the high number of test sets (which is the same as the number of samples-1) this cross-validation method can be very costly. For large datasets one should favor KFold. loo = LeaveOneOut() for train_index, test_index in loo.split(X): print (train_index, test_index) [ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [0] [ 0 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [1] [ 0 1 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [2] [ 0 1 2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [3] [ 0 1 2 3 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [4] [ 0 1 2 3 4 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [5] [ 0 1 2 3 4 5 7 8 9 10 11 12 13 14 15 16 17 18 19 20] [6] [ 0 1 2 3 4 5 6 8 9 10 11 12 13 14 15 16 17 18 19 20] [7] [ 0 1 2 3 4 5 6 7 9 10 11 12 13 14 15 16 17 18 19 20] [8] [ 0 1 2 3 4 5 6 7 8 10 11 12 13 14 15 16 17 18 19 20] [9] [ 0 1 2 3 4 5 6 7 8 9 11 12 13 14 15 16 17 18 19 20] [10] [ 0 1 2 3 4 5 6 7 8 9 10 12 13 14 15 16 17 18 19 20] [11] [ 0 1 2 3 4 5 6 7 8 9 10 11 13 14 15 16 17 18 19 20] [12] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 14 15 16 17 18 19 20] [13] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 15 16 17 18 19 20] [14] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 16 17 18 19 20] [15] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 17 18 19 20] [16] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 18 19 20] [17] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 19 20] [18] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 20] [19] [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19] [20] X x1 x2 x3 0 14 7 12 1 18 5 5 2 14 11 6 3 3 21 1 4 4 13 5 .. .. .. .. 16 1 3 13 17 8 2 19 18 15 14 9 19 2 17 4 20 5 9 7 [21 rows x 3 columns] 17.8 Polynomial Transform This can be used as part of feature engineering, to introduce new features for data that seems to fit with quadradic model. 17.8.1 Single Variable 17.8.1.1 Sample Data Data must be 2-D before polynomial features can be applied. Code below convert 1D array into 2D array. x = np.array([1, 2, 3, 4, 5]) X = x[:,np.newaxis] X array([[1], [2], [3], [4], [5]]) 17.8.1.2 Degree 1 One Degree means maintain original features. No new features is created. PolynomialFeatures(degree=1, include_bias=False).fit_transform(X) array([[1.], [2.], [3.], [4.], [5.]]) 17.8.1.3 Degree 2 Degree-1 original feature: x Degree-2 additional features: x^2 PolynomialFeatures(degree=2, include_bias=False).fit_transform(X) array([[ 1., 1.], [ 2., 4.], [ 3., 9.], [ 4., 16.], [ 5., 25.]]) 17.8.1.4 Degree 3 Degree-1 original feature: x Degree-2 additional features: x^2 Degree-3 additional features: x^3 PolynomialFeatures(degree=3, include_bias=False).fit_transform(X) array([[ 1., 1., 1.], [ 2., 4., 8.], [ 3., 9., 27.], [ 4., 16., 64.], [ 5., 25., 125.]]) 17.8.1.5 Degree 4 Degree-1 original feature: x Degree-2 additional features: x^2 Degree-3 additional features: x^3 Degree-3 additional features: x^4 PolynomialFeatures(degree=4, include_bias=False).fit_transform(X) array([[ 1., 1., 1., 1.], [ 2., 4., 8., 16.], [ 3., 9., 27., 81.], [ 4., 16., 64., 256.], [ 5., 25., 125., 625.]]) 17.8.2 Two Variables 17.8.2.1 Sample Data X = pd.DataFrame( {&#39;x1&#39;: [1, 2, 3, 4, 5 ], &#39;x2&#39;: [6, 7, 8, 9, 10]}) X x1 x2 0 1 6 1 2 7 2 3 8 3 4 9 4 5 10 17.8.2.2 Degree 2 Degree-1 original features: x1, x2 Degree-2 additional features: x1^2, x2^2, x1:x2 PolynomialFeatures(degree=2, include_bias=False).fit_transform(X) array([[ 1., 6., 1., 6., 36.], [ 2., 7., 4., 14., 49.], [ 3., 8., 9., 24., 64.], [ 4., 9., 16., 36., 81.], [ 5., 10., 25., 50., 100.]]) 17.8.2.3 Degree 3 Degree-1 original features: x1, x2 Degree-2 additional features: x1^2, x2^2, x1:x2 Degree-3 additional features: x1^3, x2^3 x1:x2^2 x2:x1^2 PolynomialFeatures(degree=3, include_bias=False).fit_transform(X) array([[ 1., 6., 1., 6., 36., 1., 6., 36., 216.], [ 2., 7., 4., 14., 49., 8., 28., 98., 343.], [ 3., 8., 9., 24., 64., 27., 72., 192., 512.], [ 4., 9., 16., 36., 81., 64., 144., 324., 729.], [ 5., 10., 25., 50., 100., 125., 250., 500., 1000.]]) 17.9 Imputation of Missing Data 17.9.1 Sample Data from numpy import nan X = np.array([[ nan, 0, 3 ], [ 3, 7, 9 ], [ 3, 5, 2 ], [ 4, nan, 6 ], [ 8, 8, 1 ]]) y = np.array([14, 16, -1, 8, -5]) 17.9.2 Imputer 17.9.2.1 mean strategy imp = Imputer(strategy=&#39;mean&#39;) C:3-packages.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead. warnings.warn(msg, category=DeprecationWarning) X2 = imp.fit_transform(X) X2 array([[4.5, 0. , 3. ], [3. , 7. , 9. ], [3. , 5. , 2. ], [4. , 5. , 6. ], [8. , 8. , 1. ]]) 17.10 Scaling It is possible that some insignificant variable with larger range will be dominating the objective function. We can remove this problem by scaling down all the features to a same range. 17.10.1 Sample Data X=mydf.filter(like=&#39;x&#39;)[:5] X x1 x2 x3 0 14 7 12 1 18 5 5 2 14 11 6 3 3 21 1 4 4 13 5 17.10.2 MinMax Scaler MinMaxScaler( feature_range(0,1), copy=True ) # default feature range (output result) from 0 to 1 # default return a copy of new array, copy=False will inplace original array Define Scaler Object scaler = MinMaxScaler() Transform Data scaler.fit_transform(X) array([[0.73333333, 0.125 , 1. ], [1. , 0. , 0.36363636], [0.73333333, 0.375 , 0.45454545], [0. , 1. , 0. ], [0.06666667, 0.5 , 0.36363636]]) Scaler Attributes data_min_: minimum value of the feature (before scaling) data_max_: maximum value of the feature (before scaling) pd.DataFrame(list(zip(scaler.data_min_, scaler.data_max_)), columns=[&#39;data_min&#39;,&#39;data_max&#39;], index=X.columns) data_min data_max x1 3.0 18.0 x2 5.0 21.0 x3 1.0 12.0 17.10.3 Standard Scaler It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data, such as linear regression, logistic regression and linear discriminate analysis. StandardScaler(copy=True, with_mean=True, with_std=True) # copy=True : return a copy of data, instead of inplace # with_mean=True : centre all features by substracting with its mean # with_std=True : centre all features by dividing with its std Define Scaler Object scaler = StandardScaler() Transform Data scaler.fit_transform(X) array([[ 0.56793014, -0.78975397, 1.74943121], [ 1.23608324, -1.14873305, -0.22573306], [ 0.56793014, -0.07179582, 0.05643326], [-1.2694909 , 1.72309958, -1.35439836], [-1.10245262, 0.28718326, -0.22573306]]) Scaler Attributes After the data transformation step above, scaler will have the mean and variance information for each feature. pd.DataFrame(list(zip(scaler.mean_, scaler.var_)), columns=[&#39;mean&#39;,&#39;variance&#39;], index=X.columns) mean variance x1 10.6 35.84 x2 11.4 31.04 x3 5.8 12.56 17.11 Pipeline With any of the preceding examples, it can quickly become tedious to do the transformations by hand, especially if you wish to string together multiple steps. For example, we might want a processing pipeline that looks something like this: Impute missing values using the mean Transform features to quadratic Fit a linear regression make_pipeline takes list of functions as parameters. When calling fit() on a pipeline object, these functions will be performed in sequential with data flow from one function to another. make_pipeline ( function_1 (), function_2 (), function_3 () ) 17.11.1 Sample Data X x1 x2 x3 0 14 7 12 1 18 5 5 2 14 11 6 3 3 21 1 4 4 13 5 y array([14, 16, -1, 8, -5]) 17.11.2 Create Pipeline my_pipe = make_pipeline ( Imputer (strategy=&#39;mean&#39;), PolynomialFeatures (degree=2), LinearRegression () ) C:3-packages.py:66: DeprecationWarning: Class Imputer is deprecated; Imputer was deprecated in version 0.20 and will be removed in 0.22. Import impute.SimpleImputer from sklearn instead. warnings.warn(msg, category=DeprecationWarning) type(my_pipe) &lt;class ‘sklearn.pipeline.Pipeline’&gt; my_pipe Pipeline(memory=None, steps=[(‘imputer’, Imputer(axis=0, copy=True, missing_values=‘NaN’, strategy=‘mean’, verbose=0)), (‘polynomialfeatures’, PolynomialFeatures(degree=2, include_bias=True, interaction_only=False, order=‘C’)), (‘linearregression’, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False))], verbose=False) 17.11.3 Executing Pipeline my_pipe.fit( X, y) # execute the pipeline Pipeline(memory=None, steps=[(‘imputer’, Imputer(axis=0, copy=True, missing_values=‘NaN’, strategy=‘mean’, verbose=0)), (‘polynomialfeatures’, PolynomialFeatures(degree=2, include_bias=True, interaction_only=False, order=‘C’)), (‘linearregression’, LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False))], verbose=False) print (y) [14 16 -1 8 -5] print (my_pipe.predict(X)) [14. 16. -1. 8. -5.] type(my_pipe) &lt;class ‘sklearn.pipeline.Pipeline’&gt; 17.12 Cross Validation 17.12.1 Load Data X,y = datasets.load_diabetes(return_X_y=True) 17.12.2 Choose An Cross Validator kf = KFold(n_splits=5) 17.12.3 Run Cross Validation Single Scorer Use default scorer of the estimator (if available) lasso = Lasso() cv_results1 = cross_validate(lasso, X,y,cv=kf, return_train_score=False) Multiple Scorer Specify the scorer http://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter cv_results2 = cross_validate(lasso, X,y,cv=kf, scoring=(&quot;neg_mean_absolute_error&quot;,&quot;neg_mean_squared_error&quot;,&quot;r2&quot;), return_train_score=False) 17.12.4 The Result Result is a dictionary cv_results1.keys() dict_keys([‘fit_time’, ‘score_time’, ‘test_score’]) cv_results2.keys() dict_keys([‘fit_time’, ‘score_time’, ‘test_neg_mean_absolute_error’, ‘test_neg_mean_squared_error’, ‘test_r2’]) cv_results1 {‘fit_time’: array([0. , 0. , 0. , 0. , 0.00099683]), ‘score_time’: array([0.0009985 , 0.00099587, 0. , 0. , 0. ]), ‘test_score’: array([0.28349047, 0.35157959, 0.3533813 , 0.33481474, 0.36453281])} cv_results2 {‘fit_time’: array([0.00100064, 0.00100064, 0.00099993, 0.00099921, 0.00099993]), ‘score_time’: array([0., 0., 0., 0., 0.]), ‘test_neg_mean_absolute_error’: array([-50.09003423, -52.54110842, -55.02813846, -50.81121806, -55.60471593]), ‘test_neg_mean_squared_error’: array([-3491.74009759, -4113.86002091, -4046.91780932, -3489.74018715, -4111.92401769]), ‘test_r2’: array([0.28349047, 0.35157959, 0.3533813 , 0.33481474, 0.36453281])} "],
["nlp.html", "18 NLP 18.1 Setup (hidden) 18.2 The Library 18.3 Tokenizer 18.4 N-Gram 18.5 Stopwords 18.6 Normalizing 18.7 Sentiment 18.8 Naive Bayes", " 18 NLP Natural Language Processing 18.1 Setup (hidden) import numpy as np import pandas as pd from IPython.core.display import display, HTML display(HTML(&quot;&lt;style&gt;.container { width:75% !important; margin-left:350px; }&lt;/style&gt;&quot;)) &lt;IPython.core.display.HTML object&gt; pd.set_option( &#39;display.notebook_repr_html&#39;, False) # render Series and DataFrame as text, not HTML pd.set_option( &#39;display.max_column&#39;, 10) # number of columns pd.set_option( &#39;display.max_rows&#39;, 10) # number of rows pd.set_option( &#39;display.width&#39;, 90) # number of characters per row 18.2 The Library from nltk.tokenize.casual import casual_tokenize from nltk.tokenize.treebank import TreebankWordTokenizer 18.3 Tokenizer 18.3.1 Casual Tokenizer Built to deal with short, informal, emotion-laced texts from social netwtorks where grammar and spelling conventions vary widely casual_tokenize(&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it.&quot;) ## [&#39;hi&#39;, &#39;@ali&#39;, &#39;-&#39;, &#39;baba&#39;, &#39;,&#39;, &#39;you&#39;, &#39;are&#39;, &#39;aweeeeeesome&#39;, &#39;!&#39;, &quot;isn&#39;t&quot;, &#39;it&#39;, &#39;.&#39;, &#39;Believe&#39;, &#39;it&#39;, &#39;.&#39;] Strip off usernames and reduce number of repeated chars casual_tokenize(&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it.&quot;, reduce_len=True, ## shorten repeated chars strip_handles=True) ## strip usernames [‘hi’, ‘-’, ‘baba’, ‘,’, ‘you’, ‘are’, ‘aweeesome’, ‘!’, “isn’t”, ‘it’, ‘.’, ‘Believe’, ‘it’, ‘.’] 18.3.2 Treebank Tokenizer¶ TreebankWordTokenizer().tokenize(&quot;hi @ali-baba, you are aweeeeeesome! isn&#39;t it. Believe it.&quot;) [‘hi’, ‘@’, ‘ali-baba’, ‘,’, ‘you’, ‘are’, ‘aweeeeeesome’, ‘!’, ‘is’, “n’t”, ‘it.’, ‘Believe’, ‘it’, ‘.’] 18.4 N-Gram from nltk.util import ngrams import re sentence = &quot;Thomas Jefferson began building the city, at the age of 25&quot; pattern = re.compile(r&quot;[-\\s.,;!?]+&quot;) tokens = pattern.split(sentence) print(tokens) [‘Thomas’, ‘Jefferson’, ‘began’, ‘building’, ‘the’, ‘city’, ‘at’, ‘the’, ‘age’, ‘of’, ‘25’] Convert To 2-Gram List in two steps ngrams(tokens,2) &lt;generator object ngrams at 0x000000000F2E0DE0&gt; grammy = list( ngrams(tokens,2) ) print(grammy) [(‘Thomas’, ‘Jefferson’), (‘Jefferson’, ‘began’), (‘began’, ‘building’), (‘building’, ‘the’), (‘the’, ‘city’), (‘city’, ‘at’), (‘at’, ‘the’), (‘the’, ‘age’), (‘age’, ‘of’), (‘of’, ‘25’)] [ &quot; &quot;.join(x) for x in grammy] [‘Thomas Jefferson’, ‘Jefferson began’, ‘began building’, ‘building the’, ‘the city’, ‘city at’, ‘at the’, ‘the age’, ‘age of’, ‘of 25’] 18.5 Stopwords 18.5.1 Custom Stop Words stop_words = [&#39;a&#39;,&#39;an&#39;,&#39;the&#39;,&#39;on&#39;,&#39;of&#39;,&#39;off&#39;,&#39;this&#39;,&#39;is&#39;,&#39;at&#39;] sentence = &quot;The house is on fire&quot; tokens = TreebankWordTokenizer().tokenize(sentence) print(tokens) [‘The’, ‘house’, ‘is’, ‘on’, ‘fire’] tokens_without_stopwords = [ x for x in tokens if x not in stop_words ] print(tokens_without_stopwords) [‘The’, ‘house’, ‘fire’] 18.5.2 NLTK Stop Words Contain 179 words, in a list form import nltk #nltk.download(&#39;stopwords&#39;) nltk_stop_words = nltk.corpus.stopwords.words(&#39;english&#39;) print(nltk_stop_words) [‘i’, ‘me’, ‘my’, ‘myself’, ‘we’, ‘our’, ‘ours’, ‘ourselves’, ‘you’, “you’re”, “you’ve”, “you’ll”, “you’d”, ‘your’, ‘yours’, ‘yourself’, ‘yourselves’, ‘he’, ‘him’, ‘his’, ‘himself’, ‘she’, “she’s”, ‘her’, ‘hers’, ‘herself’, ‘it’, “it’s”, ‘its’, ‘itself’, ‘they’, ‘them’, ‘their’, ‘theirs’, ‘themselves’, ‘what’, ‘which’, ‘who’, ‘whom’, ‘this’, ‘that’, “that’ll”, ‘these’, ‘those’, ‘am’, ‘is’, ‘are’, ‘was’, ‘were’, ‘be’, ‘been’, ‘being’, ‘have’, ‘has’, ‘had’, ‘having’, ‘do’, ‘does’, ‘did’, ‘doing’, ‘a’, ‘an’, ‘the’, ‘and’, ‘but’, ‘if’, ‘or’, ‘because’, ‘as’, ‘until’, ‘while’, ‘of’, ‘at’, ‘by’, ‘for’, ‘with’, ‘about’, ‘against’, ‘between’, ‘into’, ‘through’, ‘during’, ‘before’, ‘after’, ‘above’, ‘below’, ‘to’, ‘from’, ‘up’, ‘down’, ‘in’, ‘out’, ‘on’, ‘off’, ‘over’, ‘under’, ‘again’, ‘further’, ‘then’, ‘once’, ‘here’, ‘there’, ‘when’, ‘where’, ‘why’, ‘how’, ‘all’, ‘any’, ‘both’, ‘each’, ‘few’, ‘more’, ‘most’, ‘other’, ‘some’, ‘such’, ‘no’, ‘nor’, ‘not’, ‘only’, ‘own’, ‘same’, ‘so’, ‘than’, ‘too’, ‘very’, ‘s’, ‘t’, ‘can’, ‘will’, ‘just’, ‘don’, “don’t”, ‘should’, “should’ve”, ‘now’, ‘d’, ‘ll’, ‘m’, ‘o’, ‘re’, ‘ve’, ‘y’, ‘ain’, ‘aren’, “aren’t”, ‘couldn’, “couldn’t”, ‘didn’, “didn’t”, ‘doesn’, “doesn’t”, ‘hadn’, “hadn’t”, ‘hasn’, “hasn’t”, ‘haven’, “haven’t”, ‘isn’, “isn’t”, ‘ma’, ‘mightn’, “mightn’t”, ‘mustn’, “mustn’t”, ‘needn’, “needn’t”, ‘shan’, “shan’t”, ‘shouldn’, “shouldn’t”, ‘wasn’, “wasn’t”, ‘weren’, “weren’t”, ‘won’, “won’t”, ‘wouldn’, “wouldn’t”] print(len(nltk_stop_words)) 179 18.5.3 SKLearn Stop Words¶ Contain 318 stop words, in frozenset form from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as sklearn_stop_words print(len( sklearn_stop_words)) 318 print( sklearn_stop_words) frozenset({‘thick’, ‘so’, ‘seemed’, ‘twelve’, ‘otherwise’, ‘is’, ‘together’, ‘therefore’, ‘except’, ‘nowhere’, ‘on’, ‘five’, ‘become’, ‘made’, ‘whose’, ‘six’, ‘cannot’, ‘you’, ‘etc’, ‘further’, ‘somewhere’, ‘him’, ‘hence’, ‘less’, ‘seems’, ‘to’, ‘becoming’, ‘and’, ‘co’, ‘i’, ‘both’, ‘could’, ‘not’, ‘her’, ‘his’, ‘many’, ‘often’, ‘therein’, ‘empty’, ‘who’, ‘fill’, ‘next’, ‘became’, ‘interest’, ‘hers’, ‘this’, ‘but’, ‘fire’, ‘meanwhile’, ‘thru’, ‘sometime’, ‘almost’, ‘from’, ‘nevertheless’, ‘any’, ‘amoungst’, ‘me’, ‘well’, ‘yours’, ‘had’, ‘anything’, ‘whereby’, ‘seeming’, ‘were’, ‘un’, ‘fifteen’, ‘they’, ‘by’, ‘nobody’, ‘formerly’, ‘whether’, ‘a’, ‘every’, ‘also’, ‘whom’, ‘anyhow’, ‘during’, ‘very’, ‘however’, ‘per’, ‘either’, ‘everything’, ‘what’, ‘ten’, ‘mine’, ‘name’, ‘she’, ‘front’, ‘since’, ‘their’, ‘beyond’, ‘more’, ‘others’, ‘myself’, ‘mostly’, ‘third’, ‘wherein’, ‘of’, ‘hereupon’, ‘four’, ‘may’, ‘con’, ‘into’, ‘much’, ‘thereby’, ‘up’, ‘describe’, ‘thin’, ‘herein’, ‘eleven’, ‘itself’, ‘yourselves’, ‘sometimes’, ‘whoever’, ‘thus’, ‘via’, ‘out’, ‘are’, ‘should’, ‘hasnt’, ‘or’, ‘without’, ‘where’, ‘would’, ‘becomes’, ‘my’, ‘due’, ‘all’, ‘another’, ‘re’, ‘at’, ‘about’, ‘which’, ‘been’, ‘below’, ‘call’, ‘thence’, ‘hereby’, ‘beside’, ‘something’, ‘bill’, ‘through’, ‘against’, ‘throughout’, ‘bottom’, ‘with’, ‘neither’, ‘might’, ‘take’, ‘whence’, ‘himself’, ‘same’, ‘twenty’, ‘couldnt’, ‘moreover’, ‘else’, ‘cant’, ‘besides’, ‘can’, ‘though’, ‘please’, ‘herself’, ‘it’, ‘show’, ‘rather’, ‘there’, ‘while’, ‘noone’, ‘everyone’, ‘for’, ‘its’, ‘perhaps’, ‘three’, ‘eg’, ‘detail’, ‘own’, ‘yourself’, ‘although’, ‘namely’, ‘part’, ‘have’, ‘first’, ‘alone’, ‘everywhere’, ‘before’, ‘hundred’, ‘latter’, ‘latterly’, ‘than’, ‘done’, ‘somehow’, ‘because’, ‘move’, ‘whatever’, ‘two’, ‘between’, ‘thereupon’, ‘ltd’, ‘amongst’, ‘that’, ‘after’, ‘how’, ‘anywhere’, ‘here’, ‘too’, ‘within’, ‘eight’, ‘around’, ‘us’, ‘several’, ‘above’, ‘am’, ‘when’, ‘last’, ‘them’, ‘be’, ‘already’, ‘put’, ‘whereas’, ‘onto’, ‘nothing’, ‘will’, ‘anyway’, ‘mill’, ‘indeed’, ‘once’, ‘your’, ‘cry’, ‘why’, ‘former’, ‘our’, ‘forty’, ‘back’, ‘down’, ‘hereafter’, ‘one’, ‘ie’, ‘he’, ‘if’, ‘thereafter’, ‘de’, ‘ours’, ‘an’, ‘no’, ‘these’, ‘now’, ‘never’, ‘ourselves’, ‘being’, ‘find’, ‘upon’, ‘afterwards’, ‘top’, ‘other’, ‘still’, ‘we’, ‘has’, ‘someone’, ‘across’, ‘see’, ‘under’, ‘do’, ‘none’, ‘system’, ‘amount’, ‘whereupon’, ‘then’, ‘seem’, ‘ever’, ‘nor’, ‘such’, ‘was’, ‘until’, ‘get’, ‘sixty’, ‘sincere’, ‘found’, ‘some’, ‘each’, ‘only’, ‘whenever’, ‘inc’, ‘the’, ‘whereafter’, ‘beforehand’, ‘anyone’, ‘towards’, ‘among’, ‘give’, ‘go’, ‘along’, ‘again’, ‘keep’, ‘few’, ‘most’, ‘behind’, ‘must’, ‘side’, ‘even’, ‘always’, ‘least’, ‘as’, ‘toward’, ‘whole’, ‘over’, ‘nine’, ‘those’, ‘elsewhere’, ‘full’, ‘themselves’, ‘whither’, ‘enough’, ‘wherever’, ‘serious’, ‘fifty’, ‘yet’, ‘in’, ‘off’}) combined_stop_words = list( set(nltk_stop_words) | set(sklearn_stop_words) ) 18.5.4 Combined NLTK and SKLearn Stop Words¶ combined_stop_words = list( set(nltk_stop_words) | set(sklearn_stop_words) ) len( combined_stop_words ) 378 Intersection, agreeing only 119 out of 378 words len( list( set(nltk_stop_words) &amp; set(sklearn_stop_words)) ) 119 18.6 Normalizing Similar things are combined into single normalized form. This will reduced the vocabulary. 18.6.1 Case Folding If tokens aren’t cap normalized, you will end up with large word list. However, some information is often communicated by capitalization of word, such as name of places. If names are important, consider using proper noun. tokens = [&#39;House&#39;,&#39;Visitor&#39;,&#39;Center&#39;] [ x.lower() for x in tokens] [‘house’, ‘visitor’, ‘center’] 18.6.2 Stemming Output of a stemmer is not necessary a proper word. Porter stemmer is a lifetime refinement with 300 lines of python code, it automatically convert words to lower cap. Stemming is faster then Lemmatization from nltk.stem.porter import PorterStemmer stemmer = PorterStemmer() tokens = (&#39;house&#39;,&#39;Housing&#39;,&#39;hOuses&#39;, &#39;Malicious&#39;,&#39;goodness&#39;) [stemmer.stem(x) for x in tokens ] [‘hous’, ‘hous’, ‘hous’, ‘malici’, ‘good’] 18.6.3 Lemmatization NLTK uses connections within princeton WordNet graph for word meanings. #nltk.download(&#39;wordnet&#39;) from nltk.stem import WordNetLemmatizer lemmatizer = WordNetLemmatizer() print( lemmatizer.lemmatize(&quot;better&quot;, pos =&#39;a&#39;) ) good print( lemmatizer.lemmatize(&quot;better&quot;, pos =&#39;n&#39;) ) better print( lemmatizer.lemmatize(&quot;good&quot;, pos =&#39;a&#39;) ) good print( lemmatizer.lemmatize(&quot;good&quot;, pos =&#39;n&#39;) ) good 18.6.4 Comparing Stemming and Lemmatization Lemmatization is slower than stemming = Lemmatization is better at retaining meanings Lemmatization produce valid english word Stemming not necessary produce valid english word Both reduce vocabulary size, but increase ambiguity For search engine application, stemming and lemmatization will improve recall as it associate more documents with the same query words, however with the cost of reducing precision and accuracy. For search-based chatbot where accuracy is more important, it should first search with unnormalzied words. 18.7 Sentiment 18.7.1 Vader It is a rule based sentiment analyzer, contain 7503 lexicons. It is good for social media because lexicon contain emoji text. Contain only 3 n-gram 18.7.1.1 Vader Lexicon from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer vadersa = SentimentIntensityAnalyzer() print( len(vadersa.lexicon)) 7503 vadersa.lexicon ## this is a dictionary {‘\\(:&#39;: -1.5, &#39;%)&#39;: -0.4, &#39;%-)&#39;: -1.5, &#39;&amp;-:&#39;: -0.4, &#39;&amp;:&#39;: -0.7, &quot;( &#39;}{&#39; )&quot;: 1.6, &#39;(%&#39;: -0.9, &quot;(&#39;-:&quot;: 2.2, &quot;(&#39;:&quot;: 2.3, &#39;((-:&#39;: 2.1, &#39;(*&#39;: 1.1, &#39;(-%&#39;: -0.7, &#39;(-*&#39;: 1.3, &#39;(-:&#39;: 1.6, &#39;(-:0&#39;: 2.8, &#39;(-:&lt;&#39;: -0.4, &#39;(-:o&#39;: 1.5, &#39;(-:O&#39;: 1.5, &#39;(-:{&#39;: -0.1, &#39;(-:|&gt;*&#39;: 1.9, &#39;(-;&#39;: 1.3, &#39;(-;|&#39;: 2.1, &#39;(8&#39;: 2.6, &#39;(:&#39;: 2.2, &#39;(:0&#39;: 2.4, &#39;(:&lt;&#39;: -0.2, &#39;(:o&#39;: 2.5, &#39;(:O&#39;: 2.5, &#39;(;&#39;: 1.1, &#39;(;&lt;&#39;: 0.3, &#39;(=&#39;: 2.2, &#39;(?:&#39;: 2.1, &#39;(^:&#39;: 1.5, &#39;(^;&#39;: 1.5, &#39;(^;0&#39;: 2.0, &#39;(^;o&#39;: 1.9, &#39;(o:&#39;: 1.6, &quot;)&#39;:&quot;: -2.0, &quot;)-&#39;:&quot;: -2.1, &#39;)-:&#39;: -2.1, &#39;)-:&lt;&#39;: -2.2, &#39;)-:{&#39;: -2.1, &#39;):&#39;: -1.8, &#39;):&lt;&#39;: -1.9, &#39;):{&#39;: -2.3, &#39;);&lt;&#39;: -2.6, &#39;*)&#39;: 0.6, &#39;*-)&#39;: 0.3, &#39;*-:&#39;: 2.1, &#39;*-;&#39;: 2.4, &#39;*:&#39;: 1.9, &#39;*&lt;|:-)&#39;: 1.6, &#39;*\\\\0/*&#39;: 2.3, &#39;*^:&#39;: 1.6, &#39;,-:&#39;: 1.2, &quot;---&#39;-;-{@&quot;: 2.3, &#39;--&lt;--&lt;@&#39;: 2.2, &#39;.-:&#39;: -1.2, &#39;..###-:&#39;: -1.7, &#39;..###:&#39;: -1.9, &#39;/-:&#39;: -1.3, &#39;/:&#39;: -1.3, &#39;/:&lt;&#39;: -1.4, &#39;/=&#39;: -0.9, &#39;/^:&#39;: -1.0, &#39;/o:&#39;: -1.4, &#39;0-8&#39;: 0.1, &#39;0-|&#39;: -1.2, &#39;0:)&#39;: 1.9, &#39;0:-)&#39;: 1.4, &#39;0:-3&#39;: 1.5, &#39;0:03&#39;: 1.9, &#39;0;^)&#39;: 1.6, &#39;0_o&#39;: -0.3, &#39;10q&#39;: 2.1, &#39;1337&#39;: 2.1, &#39;143&#39;: 3.2, &#39;1432&#39;: 2.6, &#39;14aa41&#39;: 2.4, &#39;182&#39;: -2.9, &#39;187&#39;: -3.1, &#39;2g2b4g&#39;: 2.8, &#39;2g2bt&#39;: -0.1, &#39;2qt&#39;: 2.1, &#39;3:(&#39;: -2.2, &#39;3:)&#39;: 0.5, &#39;3:-(&#39;: -2.3, &#39;3:-)&#39;: -1.4, &#39;4col&#39;: -2.2, &#39;4q&#39;: -3.1, &#39;5fs&#39;: 1.5, &#39;8)&#39;: 1.9, &#39;8-d&#39;: 1.7, &#39;8-o&#39;: -0.3, &#39;86&#39;: -1.6, &#39;8d&#39;: 2.9, &#39;:###..&#39;: -2.4, &#39;:\\)’: -0.2, ‘:&amp;’: -0.6, “:‘(“: -2.2,”:’)”: 2.3, “:‘-(“: -2.4,”:’-)”: 2.7, ‘:(’: -1.9, ‘:)’: 2.0, ‘:’: 2.5, ’:-###..’: -2.5, ’:-&amp;’: -0.5, ’:-(’: -1.5, ’:-)’: 1.3, ’:-))’: 2.8, ’:-’: 1.7, ‘:-,’: 1.1, ‘:-.’: -0.9, ‘:-/’: -1.2, ‘:-&lt;’: -1.5, ‘:-d’: 2.3, ‘:-D’: 2.3, ‘:-o’: 0.1, ‘:-p’: 1.5, ‘:-[’: -1.6, ’:-\\’: -0.9, ’:-c’: -1.3, ’:-|’: -0.7, ’:-||’: -2.5, ’:-Þ’: 0.9, ’:/’: -1.4, ’:3’: 2.3, ’:&lt;’: -2.1, ’:&gt;’: 2.1, ’:?)’: 1.3, ’:?c’: -1.6, ’:@’: -2.5, ’:d’: 2.3, ’:D’: 2.3, ’:l’: -1.7, ’:o’: -0.4, ’:p’: 1.0, ’:s’: -1.2, ’:[’: -2.0, ’:\\’: -1.3, ’:]’: 2.2, ’:^)’: 2.1, ’:^’: 2.6, ’:^/’: -1.2, ’:^\\’: -1.0, ’:^|’: -1.0, ’:c’: -2.1, ’:c)’: 2.0, ’:o)’: 2.1, ’:o/’: -1.4, ’:o\\’: -1.1, ’:o|’: -0.6, ’:P’: 1.4, ’:{’: -1.9, ’:|’: -0.4, ’:}’: 2.1, ’:Þ’: 1.1, ’;)’: 0.9, ’;-)’: 1.0, ’;-’: 2.2, ’;-]’: 0.7, ‘;d’: 0.8, ‘;D’: 0.8, ‘;]’: 0.6, ‘;^)’: 1.4, ‘&lt;/3’: -3.0, ‘&lt;3’: 1.9, ‘&lt;:’: 2.1, ‘&lt;:-|’: -1.4, ‘=)’: 2.2, ‘=-3’: 2.0, ‘=-d’: 2.4, ‘=-D’: 2.4, ‘=/’: -1.4, ‘=3’: 2.1, ‘=d’: 2.3, ‘=D’: 2.3, ‘=l’: -1.2, ‘=\\’: -1.2, ‘=]’: 1.6, ‘=p’: 1.3, ‘=|’: -0.8, ‘&gt;-:’: -2.0, ‘&gt;.&lt;’: -1.3, ‘&gt;:’: -2.1, ‘&gt;:(’: -2.7, ‘&gt;:)’: 0.4, ‘&gt;:-(’: -2.7, ‘&gt;:-)’: -0.4, ‘&gt;:/’: -1.6, ‘&gt;:o’: -1.2, ‘&gt;:p’: 1.0, ‘&gt;:[’: -2.1, ‘&gt;:\\’: -1.7, ‘&gt;;(’: -2.9, ‘&gt;;)’: 0.1, ‘&gt;&gt;^’: 2.1, ’@:’: -2.1, ’@&gt;–&gt;–’: 2.1, “@}-;-‘—“: 2.2, ‘aas’: 2.5, ‘aayf’: 2.7, ‘afu’: -2.9, ‘alol’: 2.8, ‘ambw’: 2.9, ‘aml’: 3.4, ‘atab’: -1.9, ‘awol’: -1.3, ‘ayc’: 0.2, ‘ayor’: -1.2, ‘aug-00’: 0.3, ‘bfd’: -2.7, ‘bfe’: -2.6, ‘bff’: 2.9, ‘bffn’: 1.0, ‘bl’: 2.3, ‘bsod’: -2.2, ‘btd’: -2.1, ‘btdt’: -0.1, ‘bz’: 0.4, ‘b^d’: 2.6, ‘cwot’: -2.3,”d-’:”: -2.5, ’d8’: -3.2, ’d:’: 1.2, ’d:&lt;’: -3.2, ’d;’: -2.9, ’d=’: 1.5, ’doa’: -2.3, ’dx’: -3.0, ’ez’: 1.5, ’fav’: 2.0, ’fcol’: -1.8, ’ff’: 1.8, ’ffs’: -2.8, ’fkm’: -2.4, ’foaf’: 1.8, ’ftw’: 2.0, ’fu’: -3.7, ’fubar’: -3.0, ’fwb’: 2.5, ’fyi’: 0.8, ’fysa’: 0.4, ’g1’: 1.4, ’gg’: 1.2, ’gga’: 1.7, ’gigo’: -0.6, ’gj’: 2.0, ’gl’: 1.3, ’gla’: 2.5, ’gn’: 1.2, ’gr8’: 2.7, ’grrr’: -0.4, ’gt’: 1.1, ’h&amp;k’: 2.3, ’hagd’: 2.2, ’hagn’: 2.2, ’hago’: 1.2, ’hak’: 1.9, ’hand’: 2.2, ’hho1/2k’: 1.4, ’hhoj’: 2.0, ’hhok’: 0.9, ’hugz’: 2.0, ’hi5’: 1.9, ’idk’: -0.4, ’ijs’: 0.7, ’ilu’: 3.4, ’iluaaf’: 2.7, ’ily’: 3.4, ’ily2’: 2.6, ’iou’: 0.7, ’iyq’: 2.3, ’j/j’: 2.0, ’j/k’: 1.6, ’j/p’: 1.4, ’j/t’: -0.2, ’j/w’: 1.0, ’j4f’: 1.4, ’j4g’: 1.7, ’jho’: 0.8, ’jhomf’: 1.0, ’jj’: 1.0, ’jk’: 0.9, ’jp’: 0.8, ’jt’: 0.9, ’jw’: 1.6, ’jealz’: -1.2, ’k4y’: 2.3, ’kfy’: 2.3, ’kia’: -3.2, ’kk’: 1.5, ’kmuf’: 2.2, ’l’: 2.0, ’l&amp;r’: 2.2, ’laoj’: 1.3, ’lmao’: 2.9, ’lmbao’: 1.8, ’lmfao’: 2.5, ’lmso’: 2.7, ’lol’: 1.8, ’lolz’: 2.7, ’lts’: 1.6, ’ly’: 2.6, ’ly4e’: 2.7, ’lya’: 3.3, ’lyb’: 3.0, ’lyl’: 3.1, ’lylab’: 2.7, ’lylas’: 2.6, ’lylb’: 1.6, ’m8’: 1.4, ’mia’: -1.2, ’mml’: 2.0, ’mofo’: -2.4, ’muah’: 2.3, ’mubar’: -1.0, ’musm’: 0.9, ’mwah’: 2.5, ’n1’: 1.9, ’nbd’: 1.3, ’nbif’: -0.5, ’nfc’: -2.7, ’nfw’: -2.4, ’nh’: 2.2, ’nimby’: -0.8, ’nimjd’: -0.7, ’nimq’: -0.2, ’nimy’: -1.4, ’nitl’: -1.5, ’nme’: -2.1, ’noyb’: -0.7, ’np’: 1.4, ’ntmu’: 1.4, ’o-8’: -0.5, ’o-:’: -0.3, ’o-|’: -1.1, ’o.o’: -0.8, ’O.o’: -0.6, ’o.O’: -0.6, ’o:’: -0.2, ’o:)’: 1.5, ’o:-)’: 2.0, ’o:-3’: 2.2, ’o:3’: 2.3, ’o:&lt;’: -0.3, ’o;^)’: 1.6, ’ok’: 1.2, ’o_o’: -0.5, ’O_o’: -0.5, ’o_O’: -0.5, ’pita’: -2.4, ’pls’: 0.3, ’plz’: 0.3, ’pmbi’: 0.8, ’pmfji’: 0.3, ’pmji’: 0.7, ’po’: -2.6, ’ptl’: 2.6, ’pu’: -1.1, ’qq’: -2.2, ’qt’: 1.8, ’r&amp;r’: 2.4, ’rofl’: 2.7, ’roflmao’: 2.5, ’rotfl’: 2.6, ’rotflmao’: 2.8, ’rotflmfao’: 2.5, ’rotflol’: 3.0, ’rotgl’: 2.9, ’rotglmao’: 1.8, ’s:’: -1.1, ’sapfu’: -1.1, ’sete’: 2.8, ’sfete’: 2.7, ’sgtm’: 2.4, ’slap’: 0.6, ’slaw’: 2.1, ’smh’: -1.3, ’snafu’: -2.5, ’sob’: -1.0, ’swak’: 2.3, ’tgif’: 2.3, ’thks’: 1.4, ’thx’: 1.5, ’tia’: 2.3, ’tmi’: -0.3, ’tnx’: 1.1, ’true’: 1.8, ’tx’: 1.5, ’txs’: 1.1, ’ty’: 1.6, ’tyvm’: 2.5, ’urw’: 1.9, ’vbg’: 2.1, ’vbs’: 3.1, ’vip’: 2.3, ’vwd’: 2.6, ’vwp’: 2.1, ’wag’: -0.2, ’wd’: 2.7, ’wilco’: 0.9, ’wp’: 1.0, ’wtf’: -2.8, ’wtg’: 2.1, ’wth’: -2.4, ’x-d’: 2.6, ’x-p’: 1.7, ’xd’: 2.8, ’xlnt’: 3.0, ’xoxo’: 3.0, ’xoxozzz’: 2.3, ’xp’: 1.6, ’xqzt’: 1.6, ’xtc’: 0.8, ’yolo’: 1.1, ’yoyo’: 0.4, ’yvw’: 1.6, ’yw’: 1.8, ’ywia’: 2.5, ’zzz’: -1.2, ’[-;’: 0.5, ’[:’: 1.3, ’[;’: 1.0, ’[=’: 1.7, ’\\-:’: -1.0, ’\\:’: -1.0, ’\\:&lt;’: -1.7, ’\\=’: -1.1, ’\\^:’: -1.3, ’\\o/’: 2.2, ’\\o:’: -1.2, ’]-:’: -2.1, ’]:’: -1.6, ’]:&lt;’: -2.5, ’^&lt;&lt;’: 1.4, ‘^urs’: -2.8, ‘abandon’: -1.9, ‘abandoned’: -2.0, ‘abandoner’: -1.9, ‘abandoners’: -1.9, ‘abandoning’: -1.6, ‘abandonment’: -2.4, ‘abandonments’: -1.7, ‘abandons’: -1.3, ‘abducted’: -2.3, ‘abduction’: -2.8, ‘abductions’: -2.0, ‘abhor’: -2.0, ‘abhorred’: -2.4, ‘abhorrent’: -3.1, ‘abhors’: -2.9, ‘abilities’: 1.0, ‘ability’: 1.3, ‘aboard’: 0.1, ‘absentee’: -1.1, ‘absentees’: -0.8, ‘absolve’: 1.2, ‘absolved’: 1.5, ‘absolves’: 1.3, ‘absolving’: 1.6, ‘abuse’: -3.2, ‘abused’: -2.3, ‘abuser’: -2.6, ‘abusers’: -2.6, ‘abuses’: -2.6, ‘abusing’: -2.0, ‘abusive’: -3.2, ‘abusively’: -2.8, ‘abusiveness’: -2.5, ‘abusivenesses’: -3.0, ‘accept’: 1.6, ‘acceptabilities’: 1.6, ‘acceptability’: 1.1, ‘acceptable’: 1.3, ‘acceptableness’: 1.3, ‘acceptably’: 1.5, ‘acceptance’: 2.0, ‘acceptances’: 1.7, ‘acceptant’: 1.6, ‘acceptation’: 1.3, ‘acceptations’: 0.9, ‘accepted’: 1.1, ‘accepting’: 1.6, ‘accepts’: 1.3, ‘accident’: -2.1, ‘accidental’: -0.3, ‘accidentally’: -1.4, ‘accidents’: -1.3, ‘accomplish’: 1.8, ‘accomplished’: 1.9, ‘accomplishes’: 1.7, ‘accusation’: -1.0, ‘accusations’: -1.3, ‘accuse’: -0.8, ‘accused’: -1.2, ‘accuses’: -1.4, ‘accusing’: -0.7, ‘ache’: -1.6, ‘ached’: -1.6, ‘aches’: -1.0, ‘achievable’: 1.3, ‘aching’: -2.2, ‘acquit’: 0.8, ‘acquits’: 0.1, ‘acquitted’: 1.0, ‘acquitting’: 1.3, ‘acrimonious’: -1.7, ‘active’: 1.7, ‘actively’: 1.3, ‘activeness’: 0.6, ‘activenesses’: 0.8, ‘actives’: 1.1, ‘adequate’: 0.9, ‘admirability’: 2.4, ‘admirable’: 2.6, ‘admirableness’: 2.2, ‘admirably’: 2.5, ‘admiral’: 1.3, ‘admirals’: 1.5, ‘admiralties’: 1.6, ‘admiralty’: 1.2, ‘admiration’: 2.5, ‘admirations’: 1.6, ‘admire’: 2.1, ‘admired’: 2.3, ‘admirer’: 1.8, ‘admirers’: 1.7, ‘admires’: 1.5, ‘admiring’: 1.6, ‘admiringly’: 2.3, ‘admit’: 0.8, ‘admits’: 1.2, ‘admitted’: 0.4, ‘admonished’: -1.9, ‘adopt’: 0.7, ‘adopts’: 0.7, ‘adorability’: 2.2, ‘adorable’: 2.2, ‘adorableness’: 2.5, ‘adorably’: 2.1, ‘adoration’: 2.9, ‘adorations’: 2.2, ‘adore’: 2.6, ‘adored’: 1.8, ‘adorer’: 1.7, ‘adorers’: 2.1, ‘adores’: 1.6, ‘adoring’: 2.6, ‘adoringly’: 2.4, ‘adorn’: 0.9, ‘adorned’: 0.8, ‘adorner’: 1.3, ‘adorners’: 0.9, ‘adorning’: 1.0, ‘adornment’: 1.3, ‘adornments’: 0.8, ‘adorns’: 0.5, ‘advanced’: 1.0, ‘advantage’: 1.0, ‘advantaged’: 1.4, ‘advantageous’: 1.5, ‘advantageously’: 1.9, ‘advantageousness’: 1.6, ‘advantages’: 1.5, ‘advantaging’: 1.6, ‘adventure’: 1.3, ‘adventured’: 1.3, ‘adventurer’: 1.2, ‘adventurers’: 0.9, ‘adventures’: 1.4, ‘adventuresome’: 1.7, ‘adventuresomeness’: 1.3, ‘adventuress’: 0.8, ‘adventuresses’: 1.4, ‘adventuring’: 2.3, ‘adventurism’: 1.5, ‘adventurist’: 1.4, ‘adventuristic’: 1.7, ‘adventurists’: 1.2, ‘adventurous’: 1.4, ‘adventurously’: 1.3, ‘adventurousness’: 1.8, ‘adversarial’: -1.5, ‘adversaries’: -1.0, ‘adversary’: -0.8, ‘adversative’: -1.2, ‘adversatively’: -0.1, ‘adversatives’: -1.0, ‘adverse’: -1.5, ‘adversely’: -0.8, ‘adverseness’: -0.6, ‘adversities’: -1.5, ‘adversity’: -1.8, ‘affected’: -0.6, ‘affection’: 2.4, ‘affectional’: 1.9, ‘affectionally’: 1.5, ‘affectionate’: 1.9, ‘affectionately’: 2.2, ‘affectioned’: 1.8, ‘affectionless’: -2.0, ‘affections’: 1.5, ‘afflicted’: -1.5, ‘affronted’: 0.2, ‘aggravate’: -2.5, ‘aggravated’: -1.9, ‘aggravates’: -1.9, ‘aggravating’: -1.2, ‘aggress’: -1.3, ‘aggressed’: -1.4, ‘aggresses’: -0.5, ‘aggressing’: -0.6, ‘aggression’: -1.2, ‘aggressions’: -1.3, ‘aggressive’: -0.6, ‘aggressively’: -1.3, ‘aggressiveness’: -1.8, ‘aggressivities’: -1.4, ‘aggressivity’: -0.6, ‘aggressor’: -0.8, ‘aggressors’: -0.9, ‘aghast’: -1.9, ‘agitate’: -1.7, ‘agitated’: -2.0, ‘agitatedly’: -1.6, ‘agitates’: -1.4, ‘agitating’: -1.8, ‘agitation’: -1.0, ‘agitational’: -1.2, ‘agitations’: -1.3, ‘agitative’: -1.3, ‘agitato’: -0.1, ‘agitator’: -1.4, ‘agitators’: -2.1, ‘agog’: 1.9, ‘agonise’: -2.1, ‘agonised’: -2.3, ‘agonises’: -2.4, ‘agonising’: -1.5, ‘agonize’: -2.3, ‘agonized’: -2.2, ‘agonizes’: -2.3, ‘agonizing’: -2.7, ‘agonizingly’: -2.3, ‘agony’: -1.8, ‘agree’: 1.5, ‘agreeability’: 1.9, ‘agreeable’: 1.8, ‘agreeableness’: 1.8, ‘agreeablenesses’: 1.3, ‘agreeably’: 1.6, ‘agreed’: 1.1, ‘agreeing’: 1.4, ‘agreement’: 2.2, ‘agreements’: 1.1, ‘agrees’: 0.8, ‘alarm’: -1.4, ‘alarmed’: -1.4, ‘alarming’: -0.5, ‘alarmingly’: -2.6, ‘alarmism’: -0.3, ‘alarmists’: -1.1, ‘alarms’: -1.1, ‘alas’: -1.1, ‘alert’: 1.2, ‘alienation’: -1.1, ‘alive’: 1.6, ‘allergic’: -1.2, ‘allow’: 0.9, ‘alone’: -1.0, ‘alright’: 1.0, ‘amaze’: 2.5, ‘amazed’: 2.2, ‘amazedly’: 2.1, ‘amazement’: 2.5, ‘amazements’: 2.2, ‘amazes’: 2.2, ‘amazing’: 2.8, ‘amazon’: 0.7, ‘amazonite’: 0.2, ‘amazons’: -0.1, ‘amazonstone’: 1.0, ‘amazonstones’: 0.2, ‘ambitious’: 2.1, ‘ambivalent’: 0.5, ‘amor’: 3.0, ‘amoral’: -1.6, ‘amoralism’: -0.7, ‘amoralisms’: -0.7, ‘amoralities’: -1.2, ‘amorality’: -1.5, ‘amorally’: -1.0, ‘amoretti’: 0.2, ‘amoretto’: 0.6, ‘amorettos’: 0.3, ‘amorino’: 1.2, ‘amorist’: 1.6, ‘amoristic’: 1.0, ‘amorists’: 0.1, ‘amoroso’: 2.3, ‘amorous’: 1.8, ‘amorously’: 2.3, ‘amorousness’: 2.0, ‘amorphous’: -0.2, ‘amorphously’: 0.1, ‘amorphousness’: 0.3, ‘amort’: -2.1, ‘amortise’: 0.5, ‘amortised’: -0.2, ‘amortises’: 0.1, ‘amortizable’: 0.5, ‘amortization’: 0.6, ‘amortizations’: 0.2, ‘amortize’: -0.1, ‘amortized’: 0.8, ‘amortizes’: 0.6, ‘amortizing’: 0.8, ‘amusable’: 0.7, ‘amuse’: 1.7, ‘amused’: 1.8, ‘amusedly’: 2.2, ‘amusement’: 1.5, ‘amusements’: 1.5, ‘amuser’: 1.1, ‘amusers’: 1.3, ‘amuses’: 1.7, ‘amusia’: 0.3, ‘amusias’: -0.4, ‘amusing’: 1.6, ‘amusingly’: 0.8, ‘amusingness’: 1.8, ‘amusive’: 1.7, ‘anger’: -2.7, ‘angered’: -2.3, ‘angering’: -2.2, ‘angerly’: -1.9, ‘angers’: -2.3, ‘angrier’: -2.3, ‘angriest’: -3.1, ‘angrily’: -1.8, ‘angriness’: -1.7, ‘angry’: -2.3, ‘anguish’: -2.9, ‘anguished’: -1.8, ‘anguishes’: -2.1, ‘anguishing’: -2.7, ‘animosity’: -1.9, ‘annoy’: -1.9, ‘annoyance’: -1.3, ‘annoyances’: -1.8, ‘annoyed’: -1.6, ‘annoyer’: -2.2, ‘annoyers’: -1.5, ‘annoying’: -1.7, ‘annoys’: -1.8, ‘antagonism’: -1.9, ‘antagonisms’: -1.2, ‘antagonist’: -1.9, ‘antagonistic’: -1.7, ‘antagonistically’: -2.2, ‘antagonists’: -1.7, ‘antagonize’: -2.0, ‘antagonized’: -1.4, ‘antagonizes’: -0.5, ‘antagonizing’: -2.7, ‘anti’: -1.3, ‘anticipation’: 0.4, ‘anxieties’: -0.6, ‘anxiety’: -0.7, ‘anxious’: -1.0, ‘anxiously’: -0.9, ‘anxiousness’: -1.0, ‘aok’: 2.0, ‘apathetic’: -1.2, ‘apathetically’: -0.4, ‘apathies’: -0.6, ‘apathy’: -1.2, ‘apeshit’: -0.9, ‘apocalyptic’: -3.4, ‘apologise’: 1.6, ‘apologised’: 0.4, ‘apologises’: 0.8, ‘apologising’: 0.2, ‘apologize’: 0.4, ‘apologized’: 1.3, ‘apologizes’: 1.5, ‘apologizing’: -0.3, ‘apology’: 0.2, ‘appall’: -2.4, ‘appalled’: -2.0, ‘appalling’: -1.5, ‘appallingly’: -2.0, ‘appalls’: -1.9, ‘appease’: 1.1, ‘appeased’: 0.9, ‘appeases’: 0.9, ‘appeasing’: 1.0, ‘applaud’: 2.0, ‘applauded’: 1.5, ‘applauding’: 2.1, ‘applauds’: 1.4, ‘applause’: 1.8, ‘appreciate’: 1.7, ‘appreciated’: 2.3, ‘appreciates’: 2.3, ‘appreciating’: 1.9, ‘appreciation’: 2.3, ‘appreciations’: 1.7, ‘appreciative’: 2.6, ‘appreciatively’: 1.8, ‘appreciativeness’: 1.6, ‘appreciator’: 2.6, ‘appreciators’: 1.5, ‘appreciatory’: 1.7, ‘apprehensible’: 1.1, ‘apprehensibly’: -0.2, ‘apprehension’: -2.1, ‘apprehensions’: -0.9, ‘apprehensively’: -0.3, ‘apprehensiveness’: -0.7, ‘approval’: 2.1, ‘approved’: 1.8, ‘approves’: 1.7, ‘ardent’: 2.1, ‘arguable’: -1.0, ‘arguably’: -1.0, ‘argue’: -1.4, ‘argued’: -1.5, ‘arguer’: -1.6, ‘arguers’: -1.4, ‘argues’: -1.6, ‘arguing’: -2.0, ‘argument’: -1.5, ‘argumentative’: -1.5, ‘argumentatively’: -1.8, ‘argumentive’: -1.5, ‘arguments’: -1.7, ‘arrest’: -1.4, ‘arrested’: -2.1, ‘arrests’: -1.9, ‘arrogance’: -2.4, ‘arrogances’: -1.9, ‘arrogant’: -2.2, ‘arrogantly’: -1.8, ‘ashamed’: -2.1, ‘ashamedly’: -1.7, ‘ass’: -2.5, ‘assassination’: -2.9, ‘assassinations’: -2.7, ‘assault’: -2.8, ‘assaulted’: -2.4, ‘assaulting’: -2.3, ‘assaultive’: -2.8, ‘assaults’: -2.5, ‘asset’: 1.5, ‘assets’: 0.7, ‘assfucking’: -2.5, ‘assholes’: -2.8, ‘assurance’: 1.4, ‘assurances’: 1.4, ‘assure’: 1.4, ‘assured’: 1.5, ‘assuredly’: 1.6, ‘assuredness’: 1.4, ‘assurer’: 0.9, ‘assurers’: 1.1, ‘assures’: 1.3, ‘assurgent’: 1.3, ‘assuring’: 1.6, ‘assuror’: 0.5, ‘assurors’: 0.7, ‘astonished’: 1.6, ‘astound’: 1.7, ‘astounded’: 1.8, ‘astounding’: 1.8, ‘astoundingly’: 2.1, ‘astounds’: 2.1, ‘attachment’: 1.2, ‘attachments’: 1.1, ‘attack’: -2.1, ‘attacked’: -2.0, ‘attacker’: -2.7, ‘attackers’: -2.7, ‘attacking’: -2.0, ‘attacks’: -1.9, ‘attract’: 1.5, ‘attractancy’: 0.9, ‘attractant’: 1.3, ‘attractants’: 1.4, ‘attracted’: 1.8, ‘attracting’: 2.1, ‘attraction’: 2.0, ‘attractions’: 1.8, ‘attractive’: 1.9, ‘attractively’: 2.2, ‘attractiveness’: 1.8, ‘attractivenesses’: 2.1, ‘attractor’: 1.2, ‘attractors’: 1.2, ‘attracts’: 1.7, ‘audacious’: 0.9, ‘authority’: 0.3, ‘aversion’: -1.9, ‘aversions’: -1.1, ‘aversive’: -1.6, ‘aversively’: -0.8, ‘avert’: -0.7, ‘averted’: -0.3, ‘averts’: -0.4, ‘avid’: 1.2, ‘avoid’: -1.2, ‘avoidance’: -1.7, ‘avoidances’: -1.1, ‘avoided’: -1.4, ‘avoider’: -1.8, ‘avoiders’: -1.4, ‘avoiding’: -1.4, ‘avoids’: -0.7, ‘await’: 0.4, ‘awaited’: -0.1, ‘awaits’: 0.3, ‘award’: 2.5, ‘awardable’: 2.4, ‘awarded’: 1.7, ‘awardee’: 1.8, ‘awardees’: 1.2, ‘awarder’: 0.9, ‘awarders’: 1.3, ‘awarding’: 1.9, ‘awards’: 2.0, ‘awesome’: 3.1, ‘awful’: -2.0, ‘awkward’: -0.6, ‘awkwardly’: -1.3, ‘awkwardness’: -0.7, ‘axe’: -0.4, ‘axed’: -1.3, ‘backed’: 0.1, ‘backing’: 0.1, ‘backs’: -0.2, ‘bad’: -2.5, ‘badass’: 1.4, ‘badly’: -2.1, ‘bailout’: -0.4, ‘bamboozle’: -1.5, ‘bamboozled’: -1.5, ‘bamboozles’: -1.5, ‘ban’: -2.6, ‘banish’: -1.9, ‘bankrupt’: -2.6, ‘bankster’: -2.1, ‘banned’: -2.0, ‘bargain’: 0.8, ‘barrier’: -0.5, ‘bashful’: -0.1, ‘bashfully’: 0.2, ‘bashfulness’: -0.8, ‘bastard’: -2.5, ‘bastardies’: -1.8, ‘bastardise’: -2.1, ‘bastardised’: -2.3, ‘bastardises’: -2.3, ‘bastardising’: -2.6, ‘bastardization’: -2.4, ‘bastardizations’: -2.1, ‘bastardize’: -2.4, ‘bastardized’: -2.0, ‘bastardizes’: -1.8, ‘bastardizing’: -2.3, ‘bastardly’: -2.7, ‘bastards’: -3.0, ‘bastardy’: -2.7, ‘battle’: -1.6, ‘battled’: -1.2, ‘battlefield’: -1.6, ‘battlefields’: -0.9, ‘battlefront’: -1.2, ‘battlefronts’: -0.8, ‘battleground’: -1.7, ‘battlegrounds’: -0.6, ‘battlement’: -0.4, ‘battlements’: -0.4, ‘battler’: -0.8, ‘battlers’: -0.2, ‘battles’: -1.6, ‘battleship’: -0.1, ‘battleships’: -0.5, ‘battlewagon’: -0.3, ‘battlewagons’: -0.5, ‘battling’: -1.1, ‘beaten’: -1.8, ‘beatific’: 1.8, ‘beating’: -2.0, ‘beaut’: 1.6, ‘beauteous’: 2.5, ‘beauteously’: 2.6, ‘beauteousness’: 2.7, ‘beautician’: 1.2, ‘beauticians’: 0.4, ‘beauties’: 2.4, ‘beautification’: 1.9, ‘beautifications’: 2.4, ‘beautified’: 2.1, ‘beautifier’: 1.7, ‘beautifiers’: 1.7, ‘beautifies’: 1.8, ‘beautiful’: 2.9, ‘beautifuler’: 2.1, ‘beautifulest’: 2.6, ‘beautifully’: 2.7, ‘beautifulness’: 2.6, ‘beautify’: 2.3, ‘beautifying’: 2.3, ‘beauts’: 1.7, ‘beauty’: 2.8, ‘belittle’: -1.9, ‘belittled’: -2.0, ‘beloved’: 2.3, ‘benefic’: 1.4, ‘benefice’: 0.4, ‘beneficed’: 1.1, ‘beneficence’: 2.8, ‘beneficences’: 1.5, ‘beneficent’: 2.3, ‘beneficently’: 2.2, ‘benefices’: 1.1, ‘beneficial’: 1.9, ‘beneficially’: 2.4, ‘beneficialness’: 1.7, ‘beneficiaries’: 1.8, ‘beneficiary’: 2.1, ‘beneficiate’: 1.0, ‘beneficiation’: 0.4, ‘benefit’: 2.0, ‘benefits’: 1.6, ‘benefitted’: 1.7, ‘benefitting’: 1.9, ‘benevolence’: 1.7, ‘benevolences’: 1.9, ‘benevolent’: 2.7, ‘benevolently’: 1.4, ‘benevolentness’: 1.2, ‘benign’: 1.3, ‘benignancy’: 0.6, ‘benignant’: 2.2, ‘benignantly’: 1.1, ‘benignities’: 0.9, ‘benignity’: 1.3, ‘benignly’: 0.2, ‘bereave’: -2.1, ‘bereaved’: -2.1, ‘bereaves’: -1.9, ‘bereaving’: -1.3, ‘best’: 3.2, ‘betray’: -3.2, ‘betrayal’: -2.8, ‘betrayed’: -3.0, ‘betraying’: -2.5, ‘betrays’: -2.5, ‘better’: 1.9, ‘bias’: -0.4, ‘biased’: -1.1, ‘bitch’: -2.8, ‘bitched’: -2.6, ‘bitcheries’: -2.3, ‘bitchery’: -2.7, ‘bitches’: -2.9, ‘bitchier’: -2.0, ‘bitchiest’: -3.0, ‘bitchily’: -2.6, ‘bitchiness’: -2.6, ‘bitching’: -1.1, ‘bitchy’: -2.3, ‘bitter’: -1.8, ‘bitterbrush’: -0.2, ‘bitterbrushes’: -0.6, ‘bittered’: -1.8, ‘bitterer’: -1.9, ‘bitterest’: -2.3, ‘bittering’: -1.2, ‘bitterish’: -1.6, ‘bitterly’: -2.0, ‘bittern’: -0.2, ‘bitterness’: -1.7, ‘bitterns’: -0.4, ‘bitterroots’: -0.2, ‘bitters’: -0.4, ‘bittersweet’: -0.3, ‘bittersweetness’: -0.6, ‘bittersweets’: -0.2, ‘bitterweeds’: -0.5, ‘bizarre’: -1.3, ‘blah’: -0.4, ‘blam’: -0.2, ‘blamable’: -1.8, ‘blamably’: -1.8, ‘blame’: -1.4, ‘blamed’: -2.1, ‘blameful’: -1.7, ‘blamefully’: -1.6, ‘blameless’: 0.7, ‘blamelessly’: 0.9, ‘blamelessness’: 0.6, ‘blamer’: -2.1, ‘blamers’: -2.0, ‘blames’: -1.7, ‘blameworthiness’: -1.6, ‘blameworthy’: -2.3, ‘blaming’: -2.2, ‘bless’: 1.8, ‘blessed’: 2.9, ‘blesseder’: 2.0, ‘blessedest’: 2.8, ‘blessedly’: 1.7, ‘blessedness’: 1.6, ‘blesser’: 2.6, ‘blessers’: 1.9, ‘blesses’: 2.6, ‘blessing’: 2.2, ‘blessings’: 2.5, ‘blind’: -1.7, ‘bliss’: 2.7, ‘blissful’: 2.9, ‘blithe’: 1.2, ‘block’: -1.9, ‘blockbuster’: 2.9, ‘blocked’: -1.1, ‘blocking’: -1.6, ‘blocks’: -0.9, ‘bloody’: -1.9, ‘blurry’: -0.4, ‘bold’: 1.6, ‘bolder’: 1.2, ‘boldest’: 1.6, ‘boldface’: 0.3, ‘boldfaced’: -0.1, ‘boldfaces’: 0.1, ‘boldfacing’: 0.1, ‘boldly’: 1.5, ‘boldness’: 1.5, ‘boldnesses’: 0.9, ‘bolds’: 1.3, ‘bomb’: -2.2, ‘bonus’: 2.5, ‘bonuses’: 2.6, ‘boost’: 1.7, ‘boosted’: 1.5, ‘boosting’: 1.4, ‘boosts’: 1.3, ‘bore’: -1.0, ‘boreal’: -0.3, ‘borecole’: -0.2, ‘borecoles’: -0.3, ‘bored’: -1.1, ‘boredom’: -1.3, ‘boredoms’: -1.1, ‘boreen’: 0.1, ‘boreens’: 0.2, ‘boreholes’: -0.2, ‘borer’: -0.4, ‘borers’: -1.2, ‘bores’: -1.3, ‘borescopes’: -0.1, ‘boresome’: -1.3, ‘boring’: -1.3, ‘bother’: -1.4, ‘botheration’: -1.7, ‘botherations’: -1.3, ‘bothered’: -1.3, ‘bothering’: -1.6, ‘bothers’: -0.8, ‘bothersome’: -1.3, ‘boycott’: -1.3, ‘boycotted’: -1.7, ‘boycotting’: -1.7, ‘boycotts’: -1.4, ‘brainwashing’: -1.5, ‘brave’: 2.4, ‘braved’: 1.9, ‘bravely’: 2.3, ‘braver’: 2.4, ‘braveries’: 2.0, ‘bravery’: 2.2, ‘braves’: 1.9, ‘bravest’: 2.3, ‘breathtaking’: 2.0, ‘bribe’: -0.8, ‘bright’: 1.9, ‘brighten’: 1.9, ‘brightened’: 2.1, ‘brightener’: 1.0, ‘brighteners’: 1.0, ‘brightening’: 2.5, ‘brightens’: 1.5, ‘brighter’: 1.6, ‘brightest’: 3.0, ‘brightly’: 1.5, ‘brightness’: 1.6, ‘brightnesses’: 1.4, ‘brights’: 0.4, ‘brightwork’: 1.1, ‘brilliance’: 2.9, ‘brilliances’: 2.9, ‘brilliancies’: 2.3, ‘brilliancy’: 2.6, ‘brilliant’: 2.8, ‘brilliantine’: 0.8, ‘brilliantines’: 2.0, ‘brilliantly’: 3.0, ‘brilliants’: 1.9, ‘brisk’: 0.6, ‘broke’: -1.8, ‘broken’: -2.1, ‘brooding’: 0.1, ‘brutal’: -3.1, ‘brutalise’: -2.7, ‘brutalised’: -2.9, ‘brutalises’: -3.2, ‘brutalising’: -2.8, ‘brutalities’: -2.6, ‘brutality’: -3.0, ‘brutalization’: -2.1, ‘brutalizations’: -2.3, ‘brutalize’: -2.9, ‘brutalized’: -2.4, ‘brutalizes’: -3.2, ‘brutalizing’: -3.4, ‘brutally’: -3.0, ‘bullied’: -3.1, ‘bullshit’: -2.8, ‘bully’: -2.2, ‘bullying’: -2.9, ‘bummer’: -1.6, ‘buoyant’: 0.9, ‘burden’: -1.9, ‘burdened’: -1.7, ‘burdener’: -1.3, ‘burdeners’: -1.7, ‘burdening’: -1.4, ‘burdens’: -1.5, ‘burdensome’: -1.8, ‘bwahaha’: 0.4, ‘bwahahah’: 2.5, ‘calm’: 1.3, ‘calmative’: 1.1, ‘calmatives’: 0.5, ‘calmed’: 1.6, ‘calmer’: 1.5, ‘calmest’: 1.6, ‘calming’: 1.7, ‘calmly’: 1.3, ‘calmness’: 1.7, ‘calmnesses’: 1.6, ‘calmodulin’: 0.2, ‘calms’: 1.3, “can’t stand”: -2.0, ‘cancel’: -1.0, ‘cancelled’: -1.0, ‘cancelling’: -0.8, ‘cancels’: -0.9, ‘cancer’: -3.4, ‘capable’: 1.6, ‘captivated’: 1.6, ‘care’: 2.2, ‘cared’: 1.8, ‘carefree’: 1.7, ‘careful’: 0.6, ‘carefully’: 0.5, ‘carefulness’: 2.0, ‘careless’: -1.5, ‘carelessly’: -1.0, ‘carelessness’: -1.4, ‘carelessnesses’: -1.6, ‘cares’: 2.0, ‘caring’: 2.2, ‘casual’: 0.8, ‘casually’: 0.7, ‘casualty’: -2.4, ‘catastrophe’: -3.4, ‘catastrophic’: -2.2, ‘cautious’: -0.4, ‘celebrate’: 2.7, ‘celebrated’: 2.7, ‘celebrates’: 2.7, ‘celebrating’: 2.7, ‘censor’: -2.0, ‘censored’: -0.6, ‘censors’: -1.2, ‘certain’: 1.1, ‘certainly’: 1.4, ‘certainties’: 0.9, ‘certainty’: 1.0, ‘chagrin’: -1.9, ‘chagrined’: -1.4, ‘challenge’: 0.3, ‘challenged’: -0.4, ‘challenger’: 0.5, ‘challengers’: 0.4, ‘challenges’: 0.3, ‘challenging’: 0.6, ‘challengingly’: -0.6, ‘champ’: 2.1, ‘champac’: -0.2, ‘champagne’: 1.2, ‘champagnes’: 0.5, ‘champaign’: 0.2, ‘champaigns’: 0.5, ‘champaks’: -0.2, ‘champed’: 1.0, ‘champer’: -0.1, ‘champers’: 0.5, ‘champerties’: -0.1, ‘champertous’: 0.3, ‘champerty’: -0.2, ‘champignon’: 0.4, ‘champignons’: 0.2, ‘champing’: 0.7, ‘champion’: 2.9, ‘championed’: 1.2, ‘championing’: 1.8, ‘champions’: 2.4, ‘championship’: 1.9, ‘championships’: 2.2, ‘champs’: 1.8, ‘champy’: 1.0, ‘chance’: 1.0, ‘chances’: 0.8, ‘chaos’: -2.7, ‘chaotic’: -2.2, ‘charged’: -0.8, ‘charges’: -1.1, ‘charitable’: 1.7, ‘charitableness’: 1.9, ‘charitablenesses’: 1.6, ‘charitably’: 1.4, ‘charities’: 2.2, ‘charity’: 1.8, ‘charm’: 1.7, ‘charmed’: 2.0, ‘charmer’: 1.9, ‘charmers’: 2.1, ‘charmeuse’: 0.3, ‘charmeuses’: 0.4, ‘charming’: 2.8, ‘charminger’: 1.5, ‘charmingest’: 2.4, ‘charmingly’: 2.2, ‘charmless’: -1.8, ‘charms’: 1.9, ‘chastise’: -2.5, ‘chastised’: -2.2, ‘chastises’: -1.7, ‘chastising’: -1.7, ‘cheat’: -2.0, ‘cheated’: -2.3, ‘cheater’: -2.5, ‘cheaters’: -1.9, ‘cheating’: -2.6, ‘cheats’: -1.8, ‘cheer’: 2.3, ‘cheered’: 2.3, ‘cheerer’: 1.7, ‘cheerers’: 1.8, ‘cheerful’: 2.5, ‘cheerfuller’: 1.9, ‘cheerfullest’: 3.2, ‘cheerfully’: 2.1, ‘cheerfulness’: 2.1, ‘cheerier’: 2.6, ‘cheeriest’: 2.2, ‘cheerily’: 2.5, ‘cheeriness’: 2.5, ‘cheering’: 2.3, ‘cheerio’: 1.2, ‘cheerlead’: 1.7, ‘cheerleader’: 0.9, ‘cheerleaders’: 1.2, ‘cheerleading’: 1.2, ‘cheerleads’: 1.2, ‘cheerled’: 1.5, ‘cheerless’: -1.7, ‘cheerlessly’: -0.8, ‘cheerlessness’: -1.7, ‘cheerly’: 2.4, ‘cheers’: 2.1, ‘cheery’: 2.6, ‘cherish’: 1.6, ‘cherishable’: 2.0, ‘cherished’: 2.3, ‘cherisher’: 2.2, ‘cherishers’: 1.9, ‘cherishes’: 2.2, ‘cherishing’: 2.0, ‘chic’: 1.1, ‘childish’: -1.2, ‘chilling’: -0.1, ‘choke’: -2.5, ‘choked’: -2.1, ‘chokes’: -2.0, ‘choking’: -2.0, ‘chuckle’: 1.7, ‘chuckled’: 1.2, ‘chucklehead’: -1.9, ‘chuckleheaded’: -1.3, ‘chuckleheads’: -1.1, ‘chuckler’: 0.8, ‘chucklers’: 1.2, ‘chuckles’: 1.1, ‘chucklesome’: 1.1, ‘chuckling’: 1.4, ‘chucklingly’: 1.2, ‘clarifies’: 0.9, ‘clarity’: 1.7, ‘classy’: 1.9, ‘clean’: 1.7, ‘cleaner’: 0.7, ‘clear’: 1.6, ‘cleared’: 0.4, ‘clearly’: 1.7, ‘clears’: 0.3, ‘clever’: 2.0, ‘cleverer’: 2.0, ‘cleverest’: 2.6, ‘cleverish’: 1.0, ‘cleverly’: 2.3, ‘cleverness’: 2.3, ‘clevernesses’: 1.4, ‘clouded’: -0.2, ‘clueless’: -1.5, ‘cock’: -0.6, ‘cocksucker’: -3.1, ‘cocksuckers’: -2.6, ‘cocky’: -0.5, ‘coerced’: -1.5, ‘collapse’: -2.2, ‘collapsed’: -1.1, ‘collapses’: -1.2, ‘collapsing’: -1.2, ‘collide’: -0.3, ‘collides’: -1.1, ‘colliding’: -0.5, ‘collision’: -1.5, ‘collisions’: -1.1, ‘colluding’: -1.2, ‘combat’: -1.4, ‘combats’: -0.8, ‘comedian’: 1.6, ‘comedians’: 1.2, ‘comedic’: 1.7, ‘comedically’: 2.1, ‘comedienne’: 0.6, ‘comediennes’: 1.6, ‘comedies’: 1.7, ‘comedo’: 0.3, ‘comedones’: -0.8, ‘comedown’: -0.8, ‘comedowns’: -0.9, ‘comedy’: 1.5, ‘comfort’: 1.5, ‘comfortable’: 2.3, ‘comfortableness’: 1.3, ‘comfortably’: 1.8, ‘comforted’: 1.8, ‘comforter’: 1.9, ‘comforters’: 1.2, ‘comforting’: 1.7, ‘comfortingly’: 1.7, ‘comfortless’: -1.8, ‘comforts’: 2.1, ‘commend’: 1.9, ‘commended’: 1.9, ‘commit’: 1.2, ‘commitment’: 1.6, ‘commitments’: 0.5, ‘commits’: 0.1, ‘committed’: 1.1, ‘committing’: 0.3, ‘compassion’: 2.0, ‘compassionate’: 2.2, ‘compassionated’: 1.6, ‘compassionately’: 1.7, ‘compassionateness’: 0.9, ‘compassionates’: 1.6, ‘compassionating’: 1.6, ‘compassionless’: -2.6, ‘compelled’: 0.2, ‘compelling’: 0.9, ‘competent’: 1.3, ‘competitive’: 0.7, ‘complacent’: -0.3, ‘complain’: -1.5, ‘complainant’: -0.7, ‘complainants’: -1.1, ‘complained’: -1.7, ‘complainer’: -1.8, ‘complainers’: -1.3, ‘complaining’: -0.8, ‘complainingly’: -1.7, ‘complains’: -1.6, ‘complaint’: -1.2, ‘complaints’: -1.7, ‘compliment’: 2.1, ‘complimentarily’: 1.7, ‘complimentary’: 1.9, ‘complimented’: 1.8, ‘complimenting’: 2.3, ‘compliments’: 1.7, ‘comprehensive’: 1.0, ‘conciliate’: 1.0, ‘conciliated’: 1.1, ‘conciliates’: 1.1, ‘conciliating’: 1.3, ‘condemn’: -1.6, ‘condemnation’: -2.8, ‘condemned’: -1.9, ‘condemns’: -2.3, ‘confidence’: 2.3, ‘confident’: 2.2, ‘confidently’: 2.1, ‘conflict’: -1.3, ‘conflicting’: -1.7, ‘conflictive’: -1.8, ‘conflicts’: -1.6, ‘confront’: -0.7, ‘confrontation’: -1.3, ‘confrontational’: -1.6, ‘confrontationist’: -1.0, ‘confrontationists’: -1.2, ‘confrontations’: -1.5, ‘confronted’: -0.8, ‘confronter’: -0.3, ‘confronters’: -1.3, ‘confronting’: -0.6, ‘confronts’: -0.9, ‘confuse’: -0.9, ‘confused’: -1.3, ‘confusedly’: -0.6, ‘confusedness’: -1.5, ‘confuses’: -1.3, ‘confusing’: -0.9, ‘confusingly’: -1.4, ‘confusion’: -1.2, ‘confusional’: -1.2, ‘confusions’: -0.9, ‘congrats’: 2.4, ‘congratulate’: 2.2, ‘congratulation’: 2.9, ‘congratulations’: 2.9, ‘consent’: 0.9, ‘consents’: 1.0, ‘considerate’: 1.9, ‘consolable’: 1.1, ‘conspiracy’: -2.4, ‘constrained’: -0.4, ‘contagion’: -2.0, ‘contagions’: -1.5, ‘contagious’: -1.4, ‘contempt’: -2.8, ‘contemptibilities’: -2.0, ‘contemptibility’: -0.9, ‘contemptible’: -1.6, ‘contemptibleness’: -1.9, ‘contemptibly’: -1.4, ‘contempts’: -1.0, ‘contemptuous’: -2.2, ‘contemptuously’: -2.4, ‘contemptuousness’: -1.1, ‘contend’: 0.2, ‘contender’: 0.5, ‘contented’: 1.4, ‘contentedly’: 1.9, ‘contentedness’: 1.4, ‘contentious’: -1.2, ‘contentment’: 1.5, ‘contestable’: 0.6, ‘contradict’: -1.3, ‘contradictable’: -1.0, ‘contradicted’: -1.3, ‘contradicting’: -1.3, ‘contradiction’: -1.0, ‘contradictions’: -1.3, ‘contradictious’: -1.9, ‘contradictor’: -1.0, ‘contradictories’: -0.5, ‘contradictorily’: -0.9, ‘contradictoriness’: -1.4, ‘contradictors’: -1.6, ‘contradictory’: -1.4, ‘contradicts’: -1.4, ‘controversial’: -0.8, ‘controversially’: -1.1, ‘convince’: 1.0, ‘convinced’: 1.7, ‘convincer’: 0.6, ‘convincers’: 0.3, ‘convinces’: 0.7, ‘convincing’: 1.7, ‘convincingly’: 1.6, ‘convincingness’: 0.7, ‘convivial’: 1.2, ‘cool’: 1.3, ‘cornered’: -1.1, ‘corpse’: -2.7, ‘costly’: -0.4, ‘courage’: 2.2, ‘courageous’: 2.4, ‘courageously’: 2.3, ‘courageousness’: 2.1, ‘courteous’: 2.3, ‘courtesy’: 1.5, ‘cover-up’: -1.2, ‘coward’: -2.0, ‘cowardly’: -1.6, ‘coziness’: 1.5, ‘cramp’: -0.8, ‘crap’: -1.6, ‘crappy’: -2.6, ‘crash’: -1.7, ‘craze’: -0.6, ‘crazed’: -0.5, ‘crazes’: 0.2, ‘crazier’: -0.1, ‘craziest’: -0.2, ‘crazily’: -1.5, ‘craziness’: -1.6, ‘crazinesses’: -1.0, ‘crazing’: -0.5, ‘crazy’: -1.4, ‘crazyweed’: 0.8, ‘create’: 1.1, ‘created’: 1.0, ‘creates’: 1.1, ‘creatin’: 0.1, ‘creatine’: 0.2, ‘creating’: 1.2, ‘creatinine’: 0.4, ‘creation’: 1.1, ‘creationism’: 0.7, ‘creationisms’: 1.1, ‘creationist’: 0.8, ‘creationists’: 0.5, ‘creations’: 1.6, ‘creative’: 1.9, ‘creatively’: 1.5, ‘creativeness’: 1.8, ‘creativities’: 1.7, ‘creativity’: 1.6, ‘credit’: 1.6, ‘creditabilities’: 1.4, ‘creditability’: 1.9, ‘creditable’: 1.8, ‘creditableness’: 1.2, ‘creditably’: 1.7, ‘credited’: 1.5, ‘crediting’: 0.6, ‘creditor’: -0.1, ‘credits’: 1.5, ‘creditworthiness’: 1.9, ‘creditworthy’: 2.4, ‘crestfallen’: -2.5, ‘cried’: -1.6, ‘cries’: -1.7, ‘crime’: -2.5, ‘criminal’: -2.4, ‘criminals’: -2.7, ‘crisis’: -3.1, ‘critic’: -1.1, ‘critical’: -1.3, ‘criticise’: -1.9, ‘criticised’: -1.8, ‘criticises’: -1.3, ‘criticising’: -1.7, ‘criticism’: -1.9, ‘criticisms’: -0.9, ‘criticizable’: -1.0, ‘criticize’: -1.6, ‘criticized’: -1.5, ‘criticizer’: -1.5, ‘criticizers’: -1.6, ‘criticizes’: -1.4, ‘criticizing’: -1.5, ‘critics’: -1.2, ‘crude’: -2.7, ‘crudely’: -1.2, ‘crudeness’: -2.0, ‘crudenesses’: -2.0, ‘cruder’: -2.0, ‘crudes’: -1.1, ‘crudest’: -2.4, ‘cruel’: -2.8, ‘crueler’: -2.3, ‘cruelest’: -2.6, ‘crueller’: -2.4, ‘cruellest’: -2.9, ‘cruelly’: -2.8, ‘cruelness’: -2.9, ‘cruelties’: -2.3, ‘cruelty’: -2.9, ‘crush’: -0.6, ‘crushed’: -1.8, ‘crushes’: -1.9, ‘crushing’: -1.5, ‘cry’: -2.1, ‘crying’: -2.1, ‘cunt’: -2.2, ‘cunts’: -2.9, ‘curious’: 1.3, ‘curse’: -2.5, ‘cut’: -1.1, ‘cute’: 2.0, ‘cutely’: 1.3, ‘cuteness’: 2.3, ‘cutenesses’: 1.9, ‘cuter’: 2.3, ‘cutes’: 1.8, ‘cutesie’: 1.0, ‘cutesier’: 1.5, ‘cutesiest’: 2.2, ‘cutest’: 2.8, ‘cutesy’: 2.1, ‘cutey’: 2.1, ‘cuteys’: 1.5, ‘cutie’: 1.5, ‘cutiepie’: 2.0, ‘cuties’: 2.2, ‘cuts’: -1.2, ‘cutting’: -0.5, ‘cynic’: -1.4, ‘cynical’: -1.6, ‘cynically’: -1.3, ‘cynicism’: -1.7, ‘cynicisms’: -1.7, ‘cynics’: -0.3, ‘d-:’: 1.6, ‘damage’: -2.2, ‘damaged’: -1.9, ‘damager’: -1.9, ‘damagers’: -2.0, ‘damages’: -1.9, ‘damaging’: -2.3, ‘damagingly’: -2.0, ‘damn’: -1.7, ‘damnable’: -1.7, ‘damnableness’: -1.8, ‘damnably’: -1.7, ‘damnation’: -2.6, ‘damnations’: -1.4, ‘damnatory’: -2.6, ‘damned’: -1.6, ‘damnedest’: -0.5, ‘damnified’: -2.8, ‘damnifies’: -1.8, ‘damnify’: -2.2, ‘damnifying’: -2.4, ‘damning’: -1.4, ‘damningly’: -2.0, ‘damnit’: -2.4, ‘damns’: -2.2, ‘danger’: -2.4, ‘dangered’: -2.4, ‘dangering’: -2.5, ‘dangerous’: -2.1, ‘dangerously’: -2.0, ‘dangerousness’: -2.0, ‘dangers’: -2.2, ‘daredevil’: 0.5, ‘daring’: 1.5, ‘daringly’: 2.1, ‘daringness’: 1.4, ‘darings’: 0.4, ‘darkest’: -2.2, ‘darkness’: -1.0, ‘darling’: 2.8, ‘darlingly’: 1.6, ‘darlingness’: 2.3, ‘darlings’: 2.2, ‘dauntless’: 2.3, ‘daze’: -0.7, ‘dazed’: -0.7, ‘dazedly’: -0.4, ‘dazedness’: -0.5, ‘dazes’: -0.3, ‘dead’: -3.3, ‘deadlock’: -1.4, ‘deafening’: -1.2, ‘dear’: 1.6, ‘dearer’: 1.9, ‘dearest’: 2.6, ‘dearie’: 2.2, ‘dearies’: 1.0, ‘dearly’: 1.8, ‘dearness’: 2.0, ‘dears’: 1.9, ‘dearth’: -2.3, ‘dearths’: -0.9, ‘deary’: 1.9, ‘death’: -2.9, ‘debonair’: 0.8, ‘debt’: -1.5, ‘decay’: -1.7, ‘decayed’: -1.6, ‘decayer’: -1.6, ‘decayers’: -1.6, ‘decaying’: -1.7, ‘decays’: -1.7, ‘deceit’: -2.0, ‘deceitful’: -1.9, ‘deceive’: -1.7, ‘deceived’: -1.9, ‘deceives’: -1.6, ‘deceiving’: -1.4, ‘deception’: -1.9, ‘decisive’: 0.9, ‘dedicated’: 2.0, ‘defeat’: -2.0, ‘defeated’: -2.1, ‘defeater’: -1.4, ‘defeaters’: -0.9, ‘defeating’: -1.6, ‘defeatism’: -1.3, ‘defeatist’: -1.7, ‘defeatists’: -2.1, ‘defeats’: -1.3, ‘defeature’: -1.9, ‘defeatures’: -1.5, ‘defect’: -1.4, ‘defected’: -1.7, ‘defecting’: -1.8, ‘defection’: -1.4, ‘defections’: -1.5, ‘defective’: -1.9, ‘defectively’: -2.1, ‘defectiveness’: -1.8, ‘defectives’: -1.8, ‘defector’: -1.9, ‘defectors’: -1.3, ‘defects’: -1.7, ‘defence’: 0.4, ‘defenceman’: 0.4, ‘defencemen’: 0.6, ‘defences’: -0.2, ‘defender’: 0.4, ‘defenders’: 0.3, ‘defense’: 0.5, ‘defenseless’: -1.4, ‘defenselessly’: -1.1, ‘defenselessness’: -1.3, ‘defenseman’: 0.1, ‘defensemen’: -0.4, ‘defenses’: 0.7, ‘defensibility’: 0.4, ‘defensible’: 0.8, ‘defensibly’: 0.1, ‘defensive’: 0.1, ‘defensively’: -0.6, ‘defensiveness’: -0.4, ‘defensives’: -0.3, ‘defer’: -1.2, ‘deferring’: -0.7, ‘defiant’: -0.9, ‘deficit’: -1.7, ‘definite’: 1.1, ‘definitely’: 1.7, ‘degradable’: -1.0, ‘degradation’: -2.4, ‘degradations’: -1.5, ‘degradative’: -2.0, ‘degrade’: -1.9, ‘degraded’: -1.8, ‘degrader’: -2.0, ‘degraders’: -2.0, ‘degrades’: -2.1, ‘degrading’: -2.8, ‘degradingly’: -2.7, ‘dehumanize’: -1.8, ‘dehumanized’: -1.9, ‘dehumanizes’: -1.5, ‘dehumanizing’: -2.4, ‘deject’: -2.2, ‘dejected’: -2.2, ‘dejecting’: -2.3, ‘dejects’: -2.0, ‘delay’: -1.3, ‘delayed’: -0.9, ‘delectable’: 2.9, ‘delectables’: 1.4, ‘delectably’: 2.8, ‘delicate’: 0.2, ‘delicately’: 1.0, ‘delicates’: 0.6, ‘delicatessen’: 0.4, ‘delicatessens’: 0.4, ‘delicious’: 2.7, ‘deliciously’: 1.9, ‘deliciousness’: 1.8, ‘delight’: 2.9, ‘delighted’: 2.3, ‘delightedly’: 2.4, ‘delightedness’: 2.1, ‘delighter’: 2.0, ‘delighters’: 2.6, ‘delightful’: 2.8, ‘delightfully’: 2.7, ‘delightfulness’: 2.1, ‘delighting’: 1.6, ‘delights’: 2.0, ‘delightsome’: 2.3, ‘demand’: -0.5, ‘demanded’: -0.9, ‘demanding’: -0.9, ‘demonstration’: 0.4, ‘demoralized’: -1.6, ‘denied’: -1.9, ‘denier’: -1.5, ‘deniers’: -1.1, ‘denies’: -1.8, ‘denounce’: -1.4, ‘denounces’: -1.9, ‘deny’: -1.4, ‘denying’: -1.4, ‘depress’: -2.2, ‘depressant’: -1.6, ‘depressants’: -1.6, ‘depressed’: -2.3, ‘depresses’: -2.2, ‘depressible’: -1.7, ‘depressing’: -1.6, ‘depressingly’: -2.3, ‘depression’: -2.7, ‘depressions’: -2.2, ‘depressive’: -1.6, ‘depressively’: -2.1, ‘depressives’: -1.5, ‘depressor’: -1.8, ‘depressors’: -1.7, ‘depressurization’: -0.3, ‘depressurizations’: -0.4, ‘depressurize’: -0.5, ‘depressurized’: -0.3, ‘depressurizes’: -0.3, ‘depressurizing’: -0.7, ‘deprival’: -2.1, ‘deprivals’: -1.2, ‘deprivation’: -1.8, ‘deprivations’: -1.8, ‘deprive’: -2.1, ‘deprived’: -2.1, ‘depriver’: -1.6, ‘deprivers’: -1.4, ‘deprives’: -1.7, ‘depriving’: -2.0, ‘derail’: -1.2, ‘derailed’: -1.4, ‘derails’: -1.3, ‘deride’: -1.1, ‘derided’: -0.8, ‘derides’: -1.0, ‘deriding’: -1.5, ‘derision’: -1.2, ‘desirable’: 1.3, ‘desire’: 1.7, ‘desired’: 1.1, ‘desirous’: 1.3, ‘despair’: -1.3, ‘despaired’: -2.7, ‘despairer’: -1.3, ‘despairers’: -1.3, ‘despairing’: -2.3, ‘despairingly’: -2.2, ‘despairs’: -2.7, ‘desperate’: -1.3, ‘desperately’: -1.6, ‘desperateness’: -1.5, ‘desperation’: -2.0, ‘desperations’: -2.2, ‘despise’: -1.4, ‘despised’: -1.7, ‘despisement’: -2.4, ‘despisements’: -2.5, ‘despiser’: -1.8, ‘despisers’: -1.6, ‘despises’: -2.0, ‘despising’: -2.7, ‘despondent’: -2.1, ‘destroy’: -2.5, ‘destroyed’: -2.2, ‘destroyer’: -2.0, ‘destroyers’: -2.3, ‘destroying’: -2.6, ‘destroys’: -2.6, ‘destruct’: -2.4, ‘destructed’: -1.9, ‘destructibility’: -1.8, ‘destructible’: -1.5, ‘destructing’: -2.5, ‘destruction’: -2.7, ‘destructionist’: -2.6, ‘destructionists’: -2.1, ‘destructions’: -2.3, ‘destructive’: -3.0, ‘destructively’: -2.4, ‘destructiveness’: -2.4, ‘destructivity’: -2.2, ‘destructs’: -2.4, ‘detached’: -0.5, ‘detain’: -1.8, ‘detained’: -1.7, ‘detention’: -1.5, ‘determinable’: 0.9, ‘determinableness’: 0.2, ‘determinably’: 0.9, ‘determinacy’: 1.0, ‘determinant’: 0.2, ‘determinantal’: -0.3, ‘determinate’: 0.8, ‘determinately’: 1.2, ‘determinateness’: 1.1, ‘determination’: 1.7, ‘determinations’: 0.8, ‘determinative’: 1.1, ‘determinatives’: 0.9, ‘determinator’: 1.1, ‘determined’: 1.4, ‘devastate’: -3.1, ‘devastated’: -3.0, ‘devastates’: -2.8, ‘devastating’: -3.3, ‘devastatingly’: -2.4, ‘devastation’: -1.8, ‘devastations’: -1.9, ‘devastative’: -3.2, ‘devastator’: -2.8, ‘devastators’: -2.9, ‘devil’: -3.4, ‘deviled’: -1.6, ‘devilfish’: -0.8, ‘devilfishes’: -0.6, ‘deviling’: -2.2, ‘devilish’: -2.1, ‘devilishly’: -1.6, ‘devilishness’: -2.3, ‘devilkin’: -2.4, ‘devilled’: -2.3, ‘devilling’: -1.8, ‘devilment’: -1.9, ‘devilments’: -1.1, ‘devilries’: -1.6, ‘devilry’: -2.8, ‘devils’: -2.7, ‘deviltries’: -1.5, ‘deviltry’: -2.8, ‘devilwood’: -0.8, ‘devilwoods’: -1.0, ‘devote’: 1.4, ‘devoted’: 1.7, ‘devotedly’: 1.6, ‘devotedness’: 2.0, ‘devotee’: 1.6, ‘devotees’: 0.5, ‘devotement’: 1.5, ‘devotements’: 1.1, ‘devotes’: 1.6, ‘devoting’: 2.1, ‘devotion’: 2.0, ‘devotional’: 1.2, ‘devotionally’: 2.2, ‘devotionals’: 1.2, ‘devotions’: 1.8, ‘diamond’: 1.4, ‘dick’: -2.3, ‘dickhead’: -3.1, ‘die’: -2.9, ‘died’: -2.6, ‘difficult’: -1.5, ‘difficulties’: -1.2, ‘difficultly’: -1.7, ‘difficulty’: -1.4, ‘diffident’: -1.0, ‘dignified’: 2.2, ‘dignifies’: 2.0, ‘dignify’: 1.8, ‘dignifying’: 2.1, ‘dignitaries’: 0.6, ‘dignitary’: 1.9, ‘dignities’: 1.4, ‘dignity’: 1.7, ‘dilemma’: -0.7, ‘dipshit’: -2.1, ‘dire’: -2.0, ‘direful’: -3.1, ‘dirt’: -1.4, ‘dirtier’: -1.4, ‘dirtiest’: -2.4, ‘dirty’: -1.9, ‘disabling’: -2.1, ‘disadvantage’: -1.8, ‘disadvantaged’: -1.7, ‘disadvantageous’: -1.8, ‘disadvantageously’: -2.1, ‘disadvantageousness’: -1.6, ‘disadvantages’: -1.7, ‘disagree’: -1.6, ‘disagreeable’: -1.7, ‘disagreeableness’: -1.7, ‘disagreeablenesses’: -1.9, ‘disagreeably’: -1.5, ‘disagreed’: -1.3, ‘disagreeing’: -1.4, ‘disagreement’: -1.5, ‘disagreements’: -1.8, ‘disagrees’: -1.3, ‘disappear’: -0.9, ‘disappeared’: -0.9, ‘disappears’: -1.4, ‘disappoint’: -1.7, ‘disappointed’: -2.1, ‘disappointedly’: -1.7, ‘disappointing’: -2.2, ‘disappointingly’: -1.9, ‘disappointment’: -2.3, ‘disappointments’: -2.0, ‘disappoints’: -1.6, ‘disaster’: -3.1, ‘disasters’: -2.6, ‘disastrous’: -2.9, ‘disbelieve’: -1.2, ‘discard’: -1.0, ‘discarded’: -1.4, ‘discarding’: -0.7, ‘discards’: -1.0, ‘discomfort’: -1.8, ‘discomfortable’: -1.6, ‘discomforted’: -1.6, ‘discomforting’: -1.6, ‘discomforts’: -1.3, ‘disconsolate’: -2.3, ‘disconsolation’: -1.7, ‘discontented’: -1.8, ‘discord’: -1.7, ‘discounted’: 0.2, ‘discourage’: -1.8, ‘discourageable’: -1.2, ‘discouraged’: -1.7, ‘discouragement’: -2.0, ‘discouragements’: -1.8, ‘discourager’: -1.7, ‘discouragers’: -1.9, ‘discourages’: -1.9, ‘discouraging’: -1.9, ‘discouragingly’: -1.8, ‘discredited’: -1.9, ‘disdain’: -2.1, ‘disgrace’: -2.2, ‘disgraced’: -2.0, ‘disguise’: -1.0, ‘disguised’: -1.1, ‘disguises’: -1.0, ‘disguising’: -1.3, ‘disgust’: -2.9, ‘disgusted’: -2.4, ‘disgustedly’: -3.0, ‘disgustful’: -2.6, ‘disgusting’: -2.4, ‘disgustingly’: -2.9, ‘disgusts’: -2.1, ‘dishearten’: -2.0, ‘disheartened’: -2.2, ‘disheartening’: -1.8, ‘dishearteningly’: -2.0, ‘disheartenment’: -2.3, ‘disheartenments’: -2.2, ‘disheartens’: -2.2, ‘dishonest’: -2.7, ‘disillusion’: -1.0, ‘disillusioned’: -1.9, ‘disillusioning’: -1.3, ‘disillusionment’: -1.7, ‘disillusionments’: -1.5, ‘disillusions’: -1.6, ‘disinclined’: -1.1, ‘disjointed’: -1.3, ‘dislike’: -1.6, ‘disliked’: -1.7, ‘dislikes’: -1.7, ‘disliking’: -1.3, ‘dismal’: -3.0, ‘dismay’: -1.8, ‘dismayed’: -1.9, ‘dismaying’: -2.2, ‘dismayingly’: -1.9, ‘dismays’: -1.8, ‘disorder’: -1.7, ‘disorganized’: -1.2, ‘disoriented’: -1.5, ‘disparage’: -2.0, ‘disparaged’: -1.4, ‘disparages’: -1.6, ‘disparaging’: -2.2, ‘displeased’: -1.9, ‘dispute’: -1.7, ‘disputed’: -1.4, ‘disputes’: -1.1, ‘disputing’: -1.7, ‘disqualified’: -1.8, ‘disquiet’: -1.3, ‘disregard’: -1.1, ‘disregarded’: -1.6, ‘disregarding’: -0.9, ‘disregards’: -1.4, ‘disrespect’: -1.8, ‘disrespected’: -2.0, ‘disruption’: -1.5, ‘disruptions’: -1.4, ‘disruptive’: -1.3, ‘dissatisfaction’: -2.2, ‘dissatisfactions’: -1.9, ‘dissatisfactory’: -2.0, ‘dissatisfied’: -1.6, ‘dissatisfies’: -1.8, ‘dissatisfy’: -2.2, ‘dissatisfying’: -2.4, ‘distort’: -1.3, ‘distorted’: -1.7, ‘distorting’: -1.1, ‘distorts’: -1.4, ‘distract’: -1.2, ‘distractable’: -1.3, ‘distracted’: -1.4, ‘distractedly’: -0.9, ‘distractibility’: -1.3, ‘distractible’: -1.5, ‘distracting’: -1.2, ‘distractingly’: -1.4, ‘distraction’: -1.6, ‘distractions’: -1.0, ‘distractive’: -1.6, ‘distracts’: -1.3, ‘distraught’: -2.6, ‘distress’: -2.4, ‘distressed’: -1.8, ‘distresses’: -1.6, ‘distressful’: -2.2, ‘distressfully’: -1.7, ‘distressfulness’: -2.4, ‘distressing’: -1.7, ‘distressingly’: -2.2, ‘distrust’: -1.8, ‘distrusted’: -2.4, ‘distrustful’: -2.1, ‘distrustfully’: -1.8, ‘distrustfulness’: -1.6, ‘distrusting’: -2.1, ‘distrusts’: -1.3, ‘disturb’: -1.7, ‘disturbance’: -1.6, ‘disturbances’: -1.4, ‘disturbed’: -1.6, ‘disturber’: -1.4, ‘disturbers’: -2.1, ‘disturbing’: -2.3, ‘disturbingly’: -2.3, ‘disturbs’: -1.9, ‘dithering’: -0.5, ‘divination’: 1.7, ‘divinations’: 1.1, ‘divinatory’: 1.6, ‘divine’: 2.6, ‘divined’: 0.8, ‘divinely’: 2.9, ‘diviner’: 0.3, ‘diviners’: 1.2, ‘divines’: 0.8, ‘divinest’: 2.7, ‘diving’: 0.3, ‘divining’: 0.9, ‘divinise’: 0.5, ‘divinities’: 1.8, ‘divinity’: 2.7, ‘divinize’: 2.3, ‘dizzy’: -0.9, ‘dodging’: -0.4, ‘dodgy’: -0.9, ‘dolorous’: -2.2, ‘dominance’: 0.8, ‘dominances’: -0.1, ‘dominantly’: 0.2, ‘dominants’: 0.2, ‘dominate’: -0.5, ‘dominates’: 0.2, ‘dominating’: -1.2, ‘domination’: -0.2, ‘dominations’: -0.3, ‘dominative’: -0.7, ‘dominators’: -0.4, ‘dominatrices’: -0.2, ‘dominatrix’: -0.5, ‘dominatrixes’: 0.6, ‘doom’: -1.7, ‘doomed’: -3.2, ‘doomful’: -2.1, ‘dooming’: -2.8, ‘dooms’: -1.1, ‘doomsayer’: -0.7, ‘doomsayers’: -1.7, ‘doomsaying’: -1.5, ‘doomsayings’: -1.5, ‘doomsday’: -2.8, ‘doomsdayer’: -2.2, ‘doomsdays’: -2.4, ‘doomster’: -2.2, ‘doomsters’: -1.6, ‘doomy’: -1.1, ‘dork’: -1.4, ‘dorkier’: -1.1, ‘dorkiest’: -1.2, ‘dorks’: -0.5, ‘dorky’: -1.1, ‘doubt’: -1.5, ‘doubtable’: -1.5, ‘doubted’: -1.1, ‘doubter’: -1.6, ‘doubters’: -1.3, ‘doubtful’: -1.4, ‘doubtfully’: -1.2, ‘doubtfulness’: -1.2, ‘doubting’: -1.4, ‘doubtingly’: -1.4, ‘doubtless’: 0.9, ‘doubtlessly’: 1.2, ‘doubtlessness’: 0.8, ‘doubts’: -1.2, ‘douche’: -1.5, ‘douchebag’: -3.0, ‘downcast’: -1.8, ‘downhearted’: -2.3, ‘downside’: -1.0, ‘drag’: -0.9, ‘dragged’: -0.2, ‘drags’: -0.7, ‘drained’: -1.5, ‘dread’: -2.0, ‘dreaded’: -2.7, ‘dreadful’: -1.9, ‘dreadfully’: -2.7, ‘dreadfulness’: -3.2, ‘dreadfuls’: -2.4, ‘dreading’: -2.4, ‘dreadlock’: -0.4, ‘dreadlocks’: -0.2, ‘dreadnought’: -0.6, ‘dreadnoughts’: -0.4, ‘dreads’: -1.4, ‘dream’: 1.0, ‘dreams’: 1.7, ‘dreary’: -1.4, ‘droopy’: -0.8, ‘drop’: -1.1, ‘drown’: -2.7, ‘drowned’: -2.9, ‘drowns’: -2.2, ‘drunk’: -1.4, ‘dubious’: -1.5, ‘dud’: -1.0, ‘dull’: -1.7, ‘dullard’: -1.6, ‘dullards’: -1.8, ‘dulled’: -1.5, ‘duller’: -1.7, ‘dullest’: -1.7, ‘dulling’: -1.1, ‘dullish’: -1.1, ‘dullness’: -1.4, ‘dullnesses’: -1.9, ‘dulls’: -1.0, ‘dullsville’: -2.4, ‘dully’: -1.1, ‘dumb’: -2.3, ‘dumbass’: -2.6, ‘dumbbell’: -0.8, ‘dumbbells’: -0.2, ‘dumbcane’: -0.3, ‘dumbcanes’: -0.6, ‘dumbed’: -1.4, ‘dumber’: -1.5, ‘dumbest’: -2.3, ‘dumbfound’: -0.1, ‘dumbfounded’: -1.6, ‘dumbfounder’: -1.0, ‘dumbfounders’: -1.0, ‘dumbfounding’: -0.8, ‘dumbfounds’: -0.3, ‘dumbhead’: -2.6, ‘dumbheads’: -1.9, ‘dumbing’: -0.5, ‘dumbly’: -1.3, ‘dumbness’: -1.9, ‘dumbs’: -1.5, ‘dumbstruck’: -1.0, ‘dumbwaiter’: 0.2, ‘dumbwaiters’: -0.1, ‘dump’: -1.6, ‘dumpcart’: -0.6, ‘dumped’: -1.7, ‘dumper’: -1.2, ‘dumpers’: -0.8, ‘dumpier’: -1.4, ‘dumpiest’: -1.6, ‘dumpiness’: -1.2, ‘dumping’: -1.3, ‘dumpings’: -1.1, ‘dumpish’: -1.8, ‘dumpling’: 0.4, ‘dumplings’: -0.3, ‘dumps’: -1.7, ‘dumpster’: -0.6, ‘dumpsters’: -1.0, ‘dumpy’: -1.7, ‘dupe’: -1.5, ‘duped’: -1.8, ‘dwell’: 0.5, ‘dwelled’: 0.4, ‘dweller’: 0.3, ‘dwellers’: -0.3, ‘dwelling’: 0.1, ‘dwells’: -0.1, ‘dynamic’: 1.6, ‘dynamical’: 1.2, ‘dynamically’: 1.5, ‘dynamics’: 1.1, ‘dynamism’: 1.6, ‘dynamisms’: 1.2, ‘dynamist’: 1.4, ‘dynamistic’: 1.5, ‘dynamists’: 0.9, ‘dynamite’: 0.7, ‘dynamited’: -0.9, ‘dynamiter’: -1.2, ‘dynamiters’: 0.4, ‘dynamites’: -0.3, ‘dynamitic’: 0.9, ‘dynamiting’: 0.2, ‘dynamometer’: 0.3, ‘dynamometers’: 0.3, ‘dynamometric’: 0.3, ‘dynamometry’: 0.6, ‘dynamos’: 0.3, ‘dynamotor’: 0.6, ‘dysfunction’: -1.8, ‘eager’: 1.5, ‘eagerly’: 1.6, ‘eagerness’: 1.7, ‘eagers’: 1.6, ‘earnest’: 2.3, ‘ease’: 1.5, ‘eased’: 1.2, ‘easeful’: 1.5, ‘easefully’: 1.4, ‘easel’: 0.3, ‘easement’: 1.6, ‘easements’: 0.4, ‘eases’: 1.3, ‘easier’: 1.8, ‘easiest’: 1.8, ‘easily’: 1.4, ‘easiness’: 1.6, ‘easing’: 1.0, ‘easy’: 1.9, ‘easygoing’: 1.3, ‘easygoingness’: 1.5, ‘ecstacy’: 3.3, ‘ecstasies’: 2.3, ‘ecstasy’: 2.9, ‘ecstatic’: 2.3, ‘ecstatically’: 2.8, ‘ecstatics’: 2.9, ‘eerie’: -1.5, ‘eery’: -0.9, ‘effective’: 2.1, ‘effectively’: 1.9, ‘efficiencies’: 1.6, ‘efficiency’: 1.5, ‘efficient’: 1.8, ‘efficiently’: 1.7, ‘effin’: -2.3, ‘egotism’: -1.4, ‘egotisms’: -1.0, ‘egotist’: -2.3, ‘egotistic’: -1.4, ‘egotistical’: -0.9, ‘egotistically’: -1.8, ‘egotists’: -1.7, ‘elated’: 3.2, ‘elation’: 1.5, ‘elegance’: 2.1, ‘elegances’: 1.8, ‘elegancies’: 1.6, ‘elegancy’: 2.1, ‘elegant’: 2.1, ‘elegantly’: 1.9, ‘embarrass’: -1.2, ‘embarrassable’: -1.6, ‘embarrassed’: -1.5, ‘embarrassedly’: -1.1, ‘embarrasses’: -1.7, ‘embarrassing’: -1.6, ‘embarrassingly’: -1.7, ‘embarrassment’: -1.9, ‘embarrassments’: -1.7, ‘embittered’: -0.4, ‘embrace’: 1.3, ‘emergency’: -1.6, ‘emotional’: 0.6, ‘empathetic’: 1.7, ‘emptied’: -0.7, ‘emptier’: -0.7, ‘emptiers’: -0.7, ‘empties’: -0.7, ‘emptiest’: -1.8, ‘emptily’: -1.0, ‘emptiness’: -1.9, ‘emptinesses’: -1.5, ‘emptins’: -0.3, ‘empty’: -0.8, ‘emptying’: -0.6, ‘enchanted’: 1.6, ‘encourage’: 2.3, ‘encouraged’: 1.5, ‘encouragement’: 1.8, ‘encouragements’: 2.1, ‘encourager’: 1.5, ‘encouragers’: 1.5, ‘encourages’: 1.9, ‘encouraging’: 2.4, ‘encouragingly’: 2.0, ‘endorse’: 1.3, ‘endorsed’: 1.0, ‘endorsement’: 1.3, ‘endorses’: 1.4, ‘enemies’: -2.2, ‘enemy’: -2.5, ‘energetic’: 1.9, ‘energetically’: 1.8, ‘energetics’: 0.3, ‘energies’: 0.9, ‘energise’: 2.2, ‘energised’: 2.1, ‘energises’: 2.2, ‘energising’: 1.9, ‘energization’: 1.6, ‘energizations’: 1.5, ‘energize’: 2.1, ‘energized’: 2.3, ‘energizer’: 2.1, ‘energizers’: 1.7, ‘energizes’: 2.1, ‘energizing’: 2.0, ‘energy’: 1.1, ‘engage’: 1.4, ‘engaged’: 1.7, ‘engagement’: 2.0, ‘engagements’: 0.6, ‘engager’: 1.1, ‘engagers’: 1.0, ‘engages’: 1.0, ‘engaging’: 1.4, ‘engagingly’: 1.5, ‘engrossed’: 0.6, ‘enjoy’: 2.2, ‘enjoyable’: 1.9, ‘enjoyableness’: 1.9, ‘enjoyably’: 1.8, ‘enjoyed’: 2.3, ‘enjoyer’: 2.2, ‘enjoyers’: 2.2, ‘enjoying’: 2.4, ‘enjoyment’: 2.6, ‘enjoyments’: 2.0, ‘enjoys’: 2.3, ‘enlighten’: 2.3, ‘enlightened’: 2.2, ‘enlightening’: 2.3, ‘enlightens’: 1.7, ‘ennui’: -1.2, ‘enrage’: -2.6, ‘enraged’: -1.7, ‘enrages’: -1.8, ‘enraging’: -2.8, ‘enrapture’: 3.0, ‘enslave’: -3.1, ‘enslaved’: -1.7, ‘enslaves’: -1.6, ‘ensure’: 1.6, ‘ensuring’: 1.1, ‘enterprising’: 2.3, ‘entertain’: 1.3, ‘entertained’: 1.7, ‘entertainer’: 1.6, ‘entertainers’: 1.0, ‘entertaining’: 1.9, ‘entertainingly’: 1.9, ‘entertainment’: 1.8, ‘entertainments’: 2.3, ‘entertains’: 2.4, ‘enthral’: 0.4, ‘enthuse’: 1.6, ‘enthused’: 2.0, ‘enthuses’: 1.7, ‘enthusiasm’: 1.9, ‘enthusiasms’: 2.0, ‘enthusiast’: 1.5, ‘enthusiastic’: 2.2, ‘enthusiastically’: 2.6, ‘enthusiasts’: 1.4, ‘enthusing’: 1.9, ‘entitled’: 1.1, ‘entrusted’: 0.8, ‘envied’: -1.1, ‘envier’: -1.0, ‘enviers’: -1.1, ‘envies’: -0.8, ‘envious’: -1.1, ‘envy’: -1.1, ‘envying’: -0.8, ‘envyingly’: -1.3, ‘erroneous’: -1.8, ‘error’: -1.7, ‘errors’: -1.4, ‘escape’: 0.7, ‘escapes’: 0.5, ‘escaping’: 0.2, ‘esteemed’: 1.9, ‘ethical’: 2.3, ‘euphoria’: 3.3, ‘euphoric’: 3.2, ‘eviction’: -2.0, ‘evil’: -3.4, ‘evildoer’: -3.1, ‘evildoers’: -2.4, ‘evildoing’: -3.1, ‘evildoings’: -2.5, ‘eviler’: -2.1, ‘evilest’: -2.5, ‘eviller’: -2.9, ‘evillest’: -3.3, ‘evilly’: -3.4, ‘evilness’: -3.1, ‘evils’: -2.7, ‘exaggerate’: -0.6, ‘exaggerated’: -0.4, ‘exaggerates’: -0.6, ‘exaggerating’: -0.7, ‘exasperated’: -1.8, ‘excel’: 2.0, ‘excelled’: 2.2, ‘excellence’: 3.1, ‘excellences’: 2.5, ‘excellencies’: 2.4, ‘excellency’: 2.5, ‘excellent’: 2.7, ‘excellently’: 3.1, ‘excelling’: 2.5, ‘excels’: 2.5, ‘excelsior’: 0.7, ‘excitabilities’: 1.5, ‘excitability’: 1.2, ‘excitable’: 1.5, ‘excitableness’: 1.0, ‘excitant’: 1.8, ‘excitants’: 1.2, ‘excitation’: 1.8, ‘excitations’: 1.8, ‘excitative’: 0.3, ‘excitatory’: 1.1, ‘excite’: 2.1, ‘excited’: 1.4, ‘excitedly’: 2.3, ‘excitement’: 2.2, ‘excitements’: 1.9, ‘exciter’: 1.9, ‘exciters’: 1.4, ‘excites’: 2.1, ‘exciting’: 2.2, ‘excitingly’: 1.9, ‘exciton’: 0.3, ‘excitonic’: 0.2, ‘excitons’: 0.8, ‘excitor’: 0.5, ‘exclude’: -0.9, ‘excluded’: -1.4, ‘exclusion’: -1.2, ‘exclusive’: 0.5, ‘excruciate’: -2.7, ‘excruciated’: -1.3, ‘excruciates’: -1.0, ‘excruciating’: -3.3, ‘excruciatingly’: -2.9, ‘excruciation’: -3.4, ‘excruciations’: -1.9, ‘excuse’: 0.3, ‘exempt’: 0.4, ‘exhaust’: -1.2, ‘exhausted’: -1.5, ‘exhauster’: -1.3, ‘exhausters’: -1.3, ‘exhaustibility’: -0.8, ‘exhaustible’: -1.0, ‘exhausting’: -1.5, ‘exhaustion’: -1.5, ‘exhaustions’: -1.1, ‘exhaustive’: -0.5, ‘exhaustively’: -0.7, ‘exhaustiveness’: -1.1, ‘exhaustless’: 0.2, ‘exhaustlessness’: 0.9, ‘exhausts’: -1.1, ‘exhilarated’: 3.0, ‘exhilarates’: 2.8, ‘exhilarating’: 1.7, ‘exonerate’: 1.8, ‘exonerated’: 1.8, ‘exonerates’: 1.6, ‘exonerating’: 1.0, ‘expand’: 1.3, ‘expands’: 0.4, ‘expel’: -1.9, ‘expelled’: -1.0, ‘expelling’: -1.6, ‘expels’: -1.6, ‘exploit’: -0.4, ‘exploited’: -2.0, ‘exploiting’: -1.9, ‘exploits’: -1.4, ‘exploration’: 0.9, ‘explorations’: 0.3, ‘expose’: -0.6, ‘exposed’: -0.3, ‘exposes’: -0.5, ‘exposing’: -1.1, ‘extend’: 0.7, ‘extends’: 0.5, ‘exuberant’: 2.8, ‘exultant’: 3.0, ‘exultantly’: 1.4, ‘fab’: 2.0, ‘fabulous’: 2.4, ‘fabulousness’: 2.8, ‘fad’: 0.9, ‘fag’: -2.1, ‘faggot’: -3.4, ‘faggots’: -3.2, ‘fail’: -2.5, ‘failed’: -2.3, ‘failing’: -2.3, ‘failingly’: -1.4, ‘failings’: -2.2, ‘faille’: 0.1, ‘fails’: -1.8, ‘failure’: -2.3, ‘failures’: -2.0, ‘fainthearted’: -0.3, ‘fair’: 1.3, ‘faith’: 1.8, ‘faithed’: 1.3, ‘faithful’: 1.9, ‘faithfully’: 1.8, ‘faithfulness’: 1.9, ‘faithless’: -1.0, ‘faithlessly’: -0.9, ‘faithlessness’: -1.8, ‘faiths’: 1.8, ‘fake’: -2.1, ‘fakes’: -1.8, ‘faking’: -1.8, ‘fallen’: -1.5, ‘falling’: -0.6, ‘falsified’: -1.6, ‘falsify’: -2.0, ‘fame’: 1.9, ‘fan’: 1.3, ‘fantastic’: 2.6, ‘fantastical’: 2.0, ‘fantasticalities’: 2.1, ‘fantasticality’: 1.7, ‘fantasticalness’: 1.3, ‘fantasticate’: 1.5, ‘fantastico’: 0.4, ‘farce’: -1.7, ‘fascinate’: 2.4, ‘fascinated’: 2.1, ‘fascinates’: 2.0, ‘fascination’: 2.2, ‘fascinating’: 2.5, ‘fascist’: -2.6, ‘fascists’: -0.8, ‘fatal’: -2.5, ‘fatalism’: -0.6, ‘fatalisms’: -1.7, ‘fatalist’: -0.5, ‘fatalistic’: -1.0, ‘fatalists’: -1.2, ‘fatalities’: -2.9, ‘fatality’: -3.5, ‘fatally’: -3.2, ‘fatigue’: -1.0, ‘fatigued’: -1.4, ‘fatigues’: -1.3, ‘fatiguing’: -1.2, ‘fatiguingly’: -1.5, ‘fault’: -1.7, ‘faulted’: -1.4, ‘faultfinder’: -0.8, ‘faultfinders’: -1.5, ‘faultfinding’: -2.1, ‘faultier’: -2.1, ‘faultiest’: -2.1, ‘faultily’: -2.0, ‘faultiness’: -1.5, ‘faulting’: -1.4, ‘faultless’: 2.0, ‘faultlessly’: 2.0, ‘faultlessness’: 1.1, ‘faults’: -2.1, ‘faulty’: -1.3, ‘fave’: 1.9, ‘favor’: 1.7, ‘favorable’: 2.1, ‘favorableness’: 2.2, ‘favorably’: 1.6, ‘favored’: 1.8, ‘favorer’: 1.3, ‘favorers’: 1.4, ‘favoring’: 1.8, ‘favorite’: 2.0, ‘favorited’: 1.7, ‘favorites’: 1.8, ‘favoritism’: 0.7, ‘favoritisms’: 0.7, ‘favors’: 1.0, ‘favour’: 1.9, ‘favoured’: 1.8, ‘favourer’: 1.6, ‘favourers’: 1.6, ‘favouring’: 1.3, ‘favours’: 1.8, ‘fear’: -2.2, ‘feared’: -2.2, ‘fearful’: -2.2, ‘fearfuller’: -2.2, ‘fearfullest’: -2.5, ‘fearfully’: -2.2, ‘fearfulness’: -1.8, ‘fearing’: -2.7, ‘fearless’: 1.9, ‘fearlessly’: 1.1, ‘fearlessness’: 1.1, ‘fears’: -1.8, ‘fearsome’: -1.7, ‘fed up’: -1.8, ‘feeble’: -1.2, ‘feeling’: 0.5, ‘felonies’: -2.5, ‘felony’: -2.5, ‘ferocious’: -0.4, ‘ferociously’: -1.1, ‘ferociousness’: -1.0, ‘ferocities’: -1.0, ‘ferocity’: -0.7, ‘fervent’: 1.1, ‘fervid’: 0.5, ‘festival’: 2.2, ‘festivalgoer’: 1.3, ‘festivalgoers’: 1.2, ‘festivals’: 1.5, ‘festive’: 2.0, ‘festively’: 2.2, ‘festiveness’: 2.4, ‘festivities’: 2.1, ‘festivity’: 2.2, ‘feud’: -1.4, ‘feudal’: -0.8, ‘feudalism’: -0.9, ‘feudalisms’: -0.2, ‘feudalist’: -0.9, ‘feudalistic’: -1.1, ‘feudalities’: -0.4, ‘feudality’: -0.5, ‘feudalization’: -0.3, ‘feudalize’: -0.5, ‘feudalized’: -0.8, ‘feudalizes’: -0.1, ‘feudalizing’: -0.7, ‘feudally’: -0.6, ‘feudaries’: -0.3, ‘feudary’: -0.8, ‘feudatories’: -0.5, ‘feudatory’: -0.1, ‘feuded’: -2.2, ‘feuding’: -1.6, ‘feudist’: -1.1, ‘feudists’: -0.7, ‘feuds’: -1.4, ‘fiasco’: -2.3, ‘fidgety’: -1.4, ‘fiery’: -1.4, ‘fiesta’: 2.1, ‘fiestas’: 1.5, ‘fight’: -1.6, ‘fighter’: 0.6, ‘fighters’: -0.2, ‘fighting’: -1.5, ‘fightings’: -1.9, ‘fights’: -1.7, ‘fine’: 0.8, ‘fire’: -1.4, ‘fired’: -2.6, ‘firing’: -1.4, ‘fit’: 1.5, ‘fitness’: 1.1, ‘flagship’: 0.4, ‘flatter’: 0.4, ‘flattered’: 1.6, ‘flatterer’: -0.3, ‘flatterers’: 0.3, ‘flatteries’: 1.2, ‘flattering’: 1.3, ‘flatteringly’: 1.0, ‘flatters’: 0.6, ‘flattery’: 0.4, ‘flawless’: 2.3, ‘flawlessly’: 0.8, ‘flees’: -0.7, ‘flexibilities’: 1.0, ‘flexibility’: 1.4, ‘flexible’: 0.9, ‘flexibly’: 1.3, ‘flirtation’: 1.7, ‘flirtations’: -0.1, ‘flirtatious’: 0.5, ‘flirtatiously’: -0.1, ‘flirtatiousness’: 0.6, ‘flirted’: -0.2, ‘flirter’: -0.4, ‘flirters’: 0.6, ‘flirtier’: -0.1, ‘flirtiest’: 0.4, ‘flirting’: 0.8, ‘flirts’: 0.7, ‘flirty’: 0.6, ‘flop’: -1.4, ‘flops’: -1.4, ‘flu’: -1.6, ‘flunk’: -1.3, ‘flunked’: -2.1, ‘flunker’: -1.9, ‘flunkers’: -1.6, ‘flunkey’: -1.8, ‘flunkeys’: -0.6, ‘flunkies’: -1.4, ‘flunking’: -1.5, ‘flunks’: -1.8, ‘flunky’: -1.8, ‘flustered’: -1.0, ‘focused’: 1.6, ‘foe’: -1.9, ‘foehns’: 0.2, ‘foeman’: -1.8, ‘foemen’: -0.3, ‘foes’: -2.0, ‘foetal’: -0.1, ‘foetid’: -2.3, ‘foetor’: -3.0, ‘foetors’: -2.1, ‘foetus’: 0.2, ‘foetuses’: 0.2, ‘fond’: 1.9, ‘fondly’: 1.9, ‘fondness’: 2.5, ‘fool’: -1.9, ‘fooled’: -1.6, ‘fooleries’: -1.8, ‘foolery’: -1.8, ‘foolfish’: -0.8, ‘foolfishes’: -0.4, ‘foolhardier’: -1.5, ‘foolhardiest’: -1.3, ‘foolhardily’: -1.0, ‘foolhardiness’: -1.6, ‘foolhardy’: -1.4, ‘fooling’: -1.7, ‘foolish’: -1.1, ‘foolisher’: -1.7, ‘foolishest’: -1.4, ‘foolishly’: -1.8, ‘foolishness’: -1.8, ‘foolishnesses’: -2.0, ‘foolproof’: 1.6, ‘fools’: -2.2, ‘foolscaps’: -0.8, ‘forbid’: -1.3, ‘forbiddance’: -1.4, ‘forbiddances’: -1.0, ‘forbidden’: -1.8, ‘forbidder’: -1.6, ‘forbidders’: -1.5, ‘forbidding’: -1.9, ‘forbiddingly’: -1.9, ‘forbids’: -1.3, ‘forced’: -2.0, ‘foreclosure’: -0.5, ‘foreclosures’: -2.4, ‘forgave’: 1.4, ‘forget’: -0.9, ‘forgetful’: -1.1, ‘forgivable’: 1.7, ‘forgivably’: 1.6, ‘forgive’: 1.1, ‘forgiven’: 1.6, ‘forgiveness’: 1.1, ‘forgiver’: 1.7, ‘forgivers’: 1.2, ‘forgives’: 1.7, ‘forgiving’: 1.9, ‘forgivingly’: 1.4, ‘forgivingness’: 1.8, ‘forgotten’: -0.9, ‘fortunate’: 1.9, ‘fought’: -1.3, ‘foughten’: -1.9, ‘frantic’: -1.9, ‘frantically’: -1.4, ‘franticness’: -0.7, ‘fraud’: -2.8, ‘frauds’: -2.3, ‘fraudster’: -2.5, ‘fraudsters’: -2.4, ‘fraudulence’: -2.3, ‘fraudulent’: -2.2, ‘freak’: -1.9, ‘freaked’: -1.2, ‘freakier’: -1.3, ‘freakiest’: -1.6, ‘freakiness’: -1.4, ‘freaking’: -1.8, ‘freakish’: -2.1, ‘freakishly’: -0.8, ‘freakishness’: -1.4, ‘freakout’: -1.8, ‘freakouts’: -1.5, ‘freaks’: -0.4, ‘freaky’: -1.5, ‘free’: 2.3, ‘freebase’: -0.1, ‘freebased’: 0.8, ‘freebases’: 0.8, ‘freebasing’: -0.4, ‘freebee’: 1.3, ‘freebees’: 1.3, ‘freebie’: 1.8, ‘freebies’: 1.8, ‘freeboard’: 0.3, ‘freeboards’: 0.7, ‘freeboot’: -0.7, ‘freebooter’: -1.7, ‘freebooters’: -0.2, ‘freebooting’: -0.8, ‘freeborn’: 1.2, ‘freed’: 1.7, ‘freedman’: 1.1, ‘freedmen’: 0.7, ‘freedom’: 3.2, ‘freedoms’: 1.2, ‘freedwoman’: 1.6, ‘freedwomen’: 1.3, ‘freeform’: 0.9, ‘freehand’: 0.5, ‘freehanded’: 1.4, ‘freehearted’: 1.5, ‘freehold’: 0.7, ‘freeholder’: 0.5, ‘freeholders’: 0.1, ‘freeholds’: 1.0, ‘freeing’: 2.1, ‘freelance’: 1.2, ‘freelanced’: 0.7, ‘freelancer’: 1.1, ‘freelancers’: 0.4, ‘freelances’: 0.7, ‘freelancing’: 0.4, ‘freeload’: -1.9, ‘freeloaded’: -1.6, ‘freeloader’: -0.7, ‘freeloaders’: -0.1, ‘freeloading’: -1.3, ‘freeloads’: -1.3, ‘freely’: 1.9, ‘freeman’: 1.7, ‘freemartin’: -0.5, ‘freemasonries’: 0.7, ‘freemasonry’: 0.3, ‘freemen’: 1.5, ‘freeness’: 1.6, ‘freenesses’: 1.7, ‘freer’: 1.1, ‘freers’: 1.0, ‘frees’: 1.2, ‘freesia’: 0.4, ‘freesias’: 0.4, ‘freest’: 1.6, ‘freestanding’: 1.1, ‘freestyle’: 0.7, ‘freestyler’: 0.4, ‘freestylers’: 0.8, ‘freestyles’: 0.3, ‘freethinker’: 1.0, ‘freethinkers’: 1.0, ‘freethinking’: 1.1, ‘freeware’: 0.7, ‘freeway’: 0.2, ‘freewheel’: 0.5, ‘freewheeled’: 0.3, ‘freewheeler’: 0.2, ‘freewheelers’: -0.3, ‘freewheeling’: 0.5, ‘freewheelingly’: 0.8, ‘freewheels’: 0.6, ‘freewill’: 1.0, ‘freewriting’: 0.8, ‘freeze’: 0.2, ‘freezers’: -0.1, ‘freezes’: -0.1, ‘freezing’: -0.4, ‘freezingly’: -1.6, ‘frenzy’: -1.3, ‘fresh’: 1.3, ‘friend’: 2.2, ‘friended’: 1.7, ‘friending’: 1.8, ‘friendless’: -1.5, ‘friendlessness’: -0.3, ‘friendlier’: 2.0, ‘friendlies’: 2.2, ‘friendliest’: 2.6, ‘friendlily’: 1.8, ‘friendliness’: 2.0, ‘friendly’: 2.2, ‘friends’: 2.1, ‘friendship’: 1.9, ‘friendships’: 1.6, ‘fright’: -1.6, ‘frighted’: -1.4, ‘frighten’: -1.4, ‘frightened’: -1.9, ‘frightening’: -2.2, ‘frighteningly’: -2.1, ‘frightens’: -1.7, ‘frightful’: -2.3, ‘frightfully’: -1.7, ‘frightfulness’: -1.9, ‘frighting’: -1.5, ‘frights’: -1.1, ‘frisky’: 1.0, ‘frowning’: -1.4, ‘frustrate’: -2.0, ‘frustrated’: -2.4, ‘frustrates’: -1.9, ‘frustrating’: -1.9, ‘frustratingly’: -2.0, ‘frustration’: -2.1, ‘frustrations’: -2.0, ‘fuck’: -2.5, ‘fucked’: -3.4, ‘fucker’: -3.3, ‘fuckers’: -2.9, ‘fuckface’: -3.2, ‘fuckhead’: -3.1, ‘fucks’: -2.1, ‘fucktard’: -3.1, ‘fud’: -1.1, ‘fuked’: -2.5, ‘fuking’: -3.2, ‘fulfill’: 1.9, ‘fulfilled’: 1.8, ‘fulfills’: 1.0, ‘fume’: -1.2, ‘fumed’: -1.8, ‘fumeless’: 0.3, ‘fumelike’: -0.7, ‘fumer’: 0.7, ‘fumers’: -0.8, ‘fumes’: -0.1, ‘fumet’: 0.4, ‘fumets’: -0.4, ‘fumette’: -0.6, ‘fuming’: -2.7, ‘fun’: 2.3, ‘funeral’: -1.5, ‘funerals’: -1.6, ‘funky’: -0.4, ‘funned’: 2.3, ‘funnel’: 0.1, ‘funneled’: 0.1, ‘funnelform’: 0.5, ‘funneling’: -0.1, ‘funnelled’: -0.1, ‘funnelling’: 0.1, ‘funnels’: 0.4, ‘funner’: 2.2, ‘funnest’: 2.9, ‘funnier’: 1.7, ‘funnies’: 1.3, ‘funniest’: 2.6, ‘funnily’: 1.9, ‘funniness’: 1.8, ‘funninesses’: 1.6, ‘funning’: 1.8, ‘funny’: 1.9, ‘funnyman’: 1.4, ‘funnymen’: 1.3, ‘furious’: -2.7, ‘furiously’: -1.9, ‘fury’: -2.7, ‘futile’: -1.9, ‘gag’: -1.4, ‘gagged’: -1.3, ‘gain’: 2.4, ‘gained’: 1.6, ‘gaining’: 1.8, ‘gains’: 1.4, ‘gallant’: 1.7, ‘gallantly’: 1.9, ‘gallantry’: 2.6, ‘geek’: -0.8, ‘geekier’: 0.2, ‘geekiest’: -0.1, ‘geeks’: -0.4, ‘geeky’: -0.6, ‘generosities’: 2.6, ‘generosity’: 2.3, ‘generous’: 2.3, ‘generously’: 1.8, ‘generousness’: 2.4, ‘genial’: 1.8, ‘gentle’: 1.9, ‘gentler’: 1.4, ‘gentlest’: 1.8, ‘gently’: 2.0, ‘ghost’: -1.3, ‘giddy’: -0.6, ‘gift’: 1.9, ‘giggle’: 1.8, ‘giggled’: 1.5, ‘giggler’: 0.6, ‘gigglers’: 1.4, ‘giggles’: 0.8, ‘gigglier’: 1.0, ‘giggliest’: 1.7, ‘giggling’: 1.5, ‘gigglingly’: 1.1, ‘giggly’: 1.0, ‘giver’: 1.4, ‘givers’: 1.7, ‘giving’: 1.4, ‘glad’: 2.0, ‘gladly’: 1.4, ‘glamor’: 2.1, ‘glamorise’: 1.3, ‘glamorised’: 1.8, ‘glamorises’: 2.1, ‘glamorising’: 1.2, ‘glamorization’: 1.6, ‘glamorize’: 1.7, ‘glamorized’: 2.1, ‘glamorizer’: 2.4, ‘glamorizers’: 1.6, ‘glamorizes’: 2.4, ‘glamorizing’: 1.8, ‘glamorous’: 2.3, ‘glamorously’: 2.1, ‘glamors’: 1.4, ‘glamour’: 2.4, ‘glamourize’: 0.8, ‘glamourless’: -1.6, ‘glamourous’: 2.0, ‘glamours’: 1.9, ‘glee’: 3.2, ‘gleeful’: 2.9, ‘gloom’: -2.6, ‘gloomed’: -1.9, ‘gloomful’: -2.1, ‘gloomier’: -1.5, ‘gloomiest’: -1.8, ‘gloominess’: -1.8, ‘gloominesses’: -1.0, ‘glooming’: -1.8, ‘glooms’: -0.9, ‘gloomy’: -0.6, ‘gloried’: 2.4, ‘glories’: 2.1, ‘glorification’: 2.0, ‘glorified’: 2.3, ‘glorifier’: 2.3, ‘glorifiers’: 1.6, ‘glorifies’: 2.2, ‘glorify’: 2.7, ‘glorifying’: 2.4, ‘gloriole’: 1.5, ‘glorioles’: 1.2, ‘glorious’: 3.2, ‘gloriously’: 2.9, ‘gloriousness’: 2.6, ‘glory’: 2.5, ‘glum’: -2.1, ‘gn8’: 0.6, ‘god’: 1.1, ‘goddam’: -2.5, ‘goddammed’: -2.4, ‘goddamn’: -2.1, ‘goddamned’: -1.8, ‘goddamns’: -2.1, ‘goddams’: -1.9, ‘godsend’: 2.8, ‘good’: 1.9, ‘goodness’: 2.0, ‘gorgeous’: 3.0, ‘gorgeously’: 2.3, ‘gorgeousness’: 2.9, ‘gorgeousnesses’: 2.1, ‘gossip’: -0.7, ‘gossiped’: -1.1, ‘gossiper’: -1.1, ‘gossipers’: -1.1, ‘gossiping’: -1.6, ‘gossipmonger’: -1.0, ‘gossipmongers’: -1.4, ‘gossipped’: -1.3, ‘gossipping’: -1.8, ‘gossipries’: -0.8, ‘gossipry’: -1.2, ‘gossips’: -1.3, ‘gossipy’: -1.3, ‘grace’: 1.8, ‘graced’: 0.9, ‘graceful’: 2.0, ‘gracefuller’: 2.2, ‘gracefullest’: 2.8, ‘gracefully’: 2.4, ‘gracefulness’: 2.2, ‘graces’: 1.6, ‘gracile’: 1.7, ‘graciles’: 0.6, ‘gracilis’: 0.4, ‘gracility’: 1.2, ‘gracing’: 1.3, ‘gracioso’: 1.0, ‘gracious’: 2.6, ‘graciously’: 2.3, ‘graciousness’: 2.4, ‘grand’: 2.0, ‘grandee’: 1.1, ‘grandees’: 1.2, ‘grander’: 1.7, ‘grandest’: 2.4, ‘grandeur’: 2.4, ‘grandeurs’: 2.1, ‘grant’: 1.5, ‘granted’: 1.0, ‘granting’: 1.3, ‘grants’: 0.9, ‘grateful’: 2.0, ‘gratefuller’: 1.8, ‘gratefully’: 2.1, ‘gratefulness’: 2.2, ‘graticule’: 0.1, ‘graticules’: 0.2, ‘gratification’: 1.6, ‘gratifications’: 1.8, ‘gratified’: 1.6, ‘gratifies’: 1.5, ‘gratify’: 1.3, ‘gratifying’: 2.3, ‘gratifyingly’: 2.0, ‘gratin’: 0.4, ‘grating’: -0.4, ‘gratingly’: -0.2, ‘gratings’: -0.8, ‘gratins’: 0.2, ‘gratis’: 0.2, ‘gratitude’: 2.3, ‘gratz’: 2.0, ‘grave’: -1.6, ‘graved’: -0.9, ‘gravel’: -0.5, ‘graveled’: -0.5, ‘graveless’: -1.3, ‘graveling’: -0.4, ‘gravelled’: -0.9, ‘gravelling’: -0.4, ‘gravelly’: -0.9, ‘gravels’: -0.5, ‘gravely’: -1.5, ‘graven’: -0.9, ‘graveness’: -1.5, ‘graver’: -1.1, ‘gravers’: -1.2, ‘graves’: -1.2, ‘graveside’: -0.8, ‘gravesides’: -1.6, ‘gravest’: -1.3, ‘gravestone’: -0.7, ‘gravestones’: -0.5, ‘graveyard’: -1.2, ‘graveyards’: -1.2, ‘great’: 3.1, ‘greater’: 1.5, ‘greatest’: 3.2, ‘greed’: -1.7, ‘greedier’: -2.0, ‘greediest’: -2.8, ‘greedily’: -1.9, ‘greediness’: -1.7, ‘greeds’: -1.0, ‘greedy’: -1.3, ‘greenwash’: -1.8, ‘greenwashing’: -0.4, ‘greet’: 1.3, ‘greeted’: 1.1, ‘greeting’: 1.6, ‘greetings’: 1.8, ‘greets’: 0.6, ‘grey’: 0.2, ‘grief’: -2.2, ‘grievance’: -2.1, ‘grievances’: -1.5, ‘grievant’: -0.8, ‘grievants’: -1.1, ‘grieve’: -1.6, ‘grieved’: -2.0, ‘griever’: -1.9, ‘grievers’: -0.3, ‘grieves’: -2.1, ‘grieving’: -2.3, ‘grievous’: -2.0, ‘grievously’: -1.7, ‘grievousness’: -2.7, ‘grim’: -2.7, ‘grimace’: -1.0, ‘grimaced’: -2.0, ‘grimaces’: -1.8, ‘grimacing’: -1.4, ‘grimalkin’: -0.9, ‘grimalkins’: -0.9, ‘grime’: -1.5, ‘grimed’: -1.2, ‘grimes’: -1.0, ‘grimier’: -1.6, ‘grimiest’: -0.7, ‘grimily’: -0.7, ‘griminess’: -1.6, ‘griming’: -0.7, ‘grimly’: -1.3, ‘grimmer’: -1.5, ‘grimmest’: -0.8, ‘grimness’: -0.8, ‘grimy’: -1.8, ‘grin’: 2.1, ‘grinned’: 1.1, ‘grinner’: 1.1, ‘grinners’: 1.6, ‘grinning’: 1.5, ‘grins’: 0.9, ‘gross’: -2.1, ‘grossed’: -0.4, ‘grosser’: -0.3, ‘grosses’: -0.8, ‘grossest’: -2.1, ‘grossing’: -0.3, ‘grossly’: -0.9, ‘grossness’: -1.8, ‘grossular’: -0.3, ‘grossularite’: -0.1, ‘grossularites’: -0.7, ‘grossulars’: -0.3, ‘grouch’: -2.2, ‘grouched’: -0.8, ‘grouches’: -0.9, ‘grouchier’: -2.0, ‘grouchiest’: -2.3, ‘grouchily’: -1.4, ‘grouchiness’: -2.0, ‘grouching’: -1.7, ‘grouchy’: -1.9, ‘growing’: 0.7, ‘growth’: 1.6, ‘guarantee’: 1.0, ‘guilt’: -1.1, ‘guiltier’: -2.0, ‘guiltiest’: -1.7, ‘guiltily’: -1.1, ‘guiltiness’: -1.8, ‘guiltless’: 0.8, ‘guiltlessly’: 0.7, ‘guiltlessness’: 0.6, ‘guilts’: -1.4, ‘guilty’: -1.8, ‘gullibility’: -1.6, ‘gullible’: -1.5, ‘gun’: -1.4, ‘h8’: -2.7, ‘ha’: 1.4, ‘hacked’: -1.7, ‘haha’: 2.0, ‘hahaha’: 2.6, ‘hahas’: 1.8, ‘hail’: 0.3, ‘hailed’: 0.9, ‘hallelujah’: 3.0, ‘handsome’: 2.2, ‘handsomely’: 1.9, ‘handsomeness’: 2.4, ‘handsomer’: 2.0, ‘handsomest’: 2.6, ‘hapless’: -1.4, ‘haplessness’: -1.4, ‘happier’: 2.4, ‘happiest’: 3.2, ‘happily’: 2.6, ‘happiness’: 2.6, ‘happing’: 1.1, ‘happy’: 2.7, ‘harass’: -2.2, ‘harassed’: -2.5, ‘harasser’: -2.4, ‘harassers’: -2.8, ‘harasses’: -2.5, ‘harassing’: -2.5, ‘harassment’: -2.5, ‘harassments’: -2.6, ‘hard’: -0.4, ‘hardier’: -0.6, ‘hardship’: -1.3, ‘hardy’: 1.7, ‘harm’: -2.5, ‘harmed’: -2.1, ‘harmfully’: -2.6, ‘harmfulness’: -2.6, ‘harming’: -2.6, ‘harmless’: 1.0, ‘harmlessly’: 1.4, ‘harmlessness’: 0.8, ‘harmonic’: 1.8, ‘harmonica’: 0.6, ‘harmonically’: 2.1, ‘harmonicas’: 0.1, ‘harmonicist’: 0.5, ‘harmonicists’: 0.9, ‘harmonics’: 1.5, ‘harmonies’: 1.3, ‘harmonious’: 2.0, ‘harmoniously’: 1.9, ‘harmoniousness’: 1.8, ‘harmonise’: 1.8, ‘harmonised’: 1.3, ‘harmonising’: 1.4, ‘harmonium’: 0.9, ‘harmoniums’: 0.8, ‘harmonization’: 1.9, ‘harmonizations’: 0.9, ‘harmonize’: 1.7, ‘harmonized’: 1.6, ‘harmonizer’: 1.6, ‘harmonizers’: 1.6, ‘harmonizes’: 1.5, ‘harmonizing’: 1.4, ‘harmony’: 1.7, ‘harms’: -2.2, ‘harried’: -1.4, ‘harsh’: -1.9, ‘harsher’: -2.2, ‘harshest’: -2.9, ‘hate’: -2.7, ‘hated’: -3.2, ‘hateful’: -2.2, ‘hatefully’: -2.3, ‘hatefulness’: -3.6, ‘hater’: -1.8, ‘haters’: -2.2, ‘hates’: -1.9, ‘hating’: -2.3, ‘hatred’: -3.2, ‘haunt’: -1.7, ‘haunted’: -2.1, ‘haunting’: -1.1, ‘haunts’: -1.0, ‘havoc’: -2.9, ‘healthy’: 1.7, ‘heartbreak’: -2.7, ‘heartbreaker’: -2.2, ‘heartbreakers’: -2.1, ‘heartbreaking’: -2.0, ‘heartbreakingly’: -1.8, ‘heartbreaks’: -1.8, ‘heartbroken’: -3.3, ‘heartfelt’: 2.5, ‘heartless’: -2.2, ‘heartlessly’: -2.8, ‘heartlessness’: -2.8, ‘heartwarming’: 2.1, ‘heaven’: 2.3, ‘heavenlier’: 3.0, ‘heavenliest’: 2.7, ‘heavenliness’: 2.7, ‘heavenlinesses’: 2.3, ‘heavenly’: 3.0, ‘heavens’: 1.7, ‘heavenward’: 1.4, ‘heavenwards’: 1.2, ‘heavyhearted’: -2.1, ‘heh’: -0.6, ‘hell’: -3.6, ‘hellish’: -3.2, ‘help’: 1.7, ‘helper’: 1.4, ‘helpers’: 1.1, ‘helpful’: 1.8, ‘helpfully’: 2.3, ‘helpfulness’: 1.9, ‘helping’: 1.2, ‘helpless’: -2.0, ‘helplessly’: -1.4, ‘helplessness’: -2.1, ‘helplessnesses’: -1.7, ‘helps’: 1.6, ‘hero’: 2.6, ‘heroes’: 2.3, ‘heroic’: 2.6, ‘heroical’: 2.9, ‘heroically’: 2.4, ‘heroicomic’: 1.0, ‘heroicomical’: 1.1, ‘heroics’: 2.4, ‘heroin’: -2.2, ‘heroine’: 2.7, ‘heroines’: 1.8, ‘heroinism’: -2.0, ‘heroism’: 2.8, ‘heroisms’: 2.2, ‘heroize’: 2.1, ‘heroized’: 2.0, ‘heroizes’: 2.2, ‘heroizing’: 1.9, ‘heron’: 0.1, ‘heronries’: 0.7, ‘heronry’: 0.1, ‘herons’: 0.5, ‘heros’: 1.3, ‘hesitance’: -0.9, ‘hesitancies’: -1.0, ‘hesitancy’: -0.9, ‘hesitant’: -1.0, ‘hesitantly’: -1.2, ‘hesitate’: -1.1, ‘hesitated’: -1.3, ‘hesitater’: -1.4, ‘hesitaters’: -1.4, ‘hesitates’: -1.4, ‘hesitating’: -1.4, ‘hesitatingly’: -1.5, ‘hesitation’: -1.1, ‘hesitations’: -1.1, ‘hid’: -0.4, ‘hide’: -0.7, ‘hides’: -0.7, ‘hiding’: -1.2, ‘highlight’: 1.4, ‘hilarious’: 1.7, ‘hindrance’: -1.7, ‘hoax’: -1.1, ‘holiday’: 1.7, ‘holidays’: 1.6, ‘homesick’: -0.7, ‘homesickness’: -1.8, ‘homesicknesses’: -1.8, ‘honest’: 2.3, ‘honester’: 1.9, ‘honestest’: 3.0, ‘honesties’: 1.8, ‘honestly’: 2.0, ‘honesty’: 2.2, ‘honor’: 2.2, ‘honorability’: 2.2, ‘honorable’: 2.5, ‘honorableness’: 2.2, ‘honorably’: 2.4, ‘honoraria’: 0.6, ‘honoraries’: 1.5, ‘honorarily’: 1.9, ‘honorarium’: 0.7, ‘honorariums’: 1.0, ‘honorary’: 1.4, ‘honored’: 2.8, ‘honoree’: 2.1, ‘honorees’: 2.3, ‘honorer’: 1.7, ‘honorers’: 1.3, ‘honorific’: 1.4, ‘honorifically’: 2.2, ‘honorifics’: 1.7, ‘honoring’: 2.3, ‘honors’: 2.3, ‘honour’: 2.7, ‘honourable’: 2.1, ‘honoured’: 2.2, ‘honourer’: 1.8, ‘honourers’: 1.6, ‘honouring’: 2.1, ‘honours’: 2.2, ‘hooligan’: -1.5, ‘hooliganism’: -2.1, ‘hooligans’: -1.1, ‘hooray’: 2.3, ‘hope’: 1.9, ‘hoped’: 1.6, ‘hopeful’: 2.3, ‘hopefully’: 1.7, ‘hopefulness’: 1.6, ‘hopeless’: -2.0, ‘hopelessly’: -2.2, ‘hopelessness’: -3.1, ‘hopes’: 1.8, ‘hoping’: 1.8, ‘horrendous’: -2.8, ‘horrendously’: -1.9, ‘horrent’: -0.9, ‘horrible’: -2.5, ‘horribleness’: -2.4, ‘horribles’: -2.1, ‘horribly’: -2.4, ‘horrid’: -2.5, ‘horridly’: -1.4, ‘horridness’: -2.3, ‘horridnesses’: -3.0, ‘horrific’: -3.4, ‘horrifically’: -2.9, ‘horrified’: -2.5, ‘horrifies’: -2.9, ‘horrify’: -2.5, ‘horrifying’: -2.7, ‘horrifyingly’: -3.3, ‘horror’: -2.7, ‘horrors’: -2.7, ‘hostile’: -1.6, ‘hostilely’: -2.2, ‘hostiles’: -1.3, ‘hostilities’: -2.1, ‘hostility’: -2.5, ‘huckster’: -0.9, ‘hug’: 2.1, ‘huge’: 1.3, ‘huggable’: 1.6, ‘hugged’: 1.7, ‘hugger’: 1.6, ‘huggers’: 1.8, ‘hugging’: 1.8, ‘hugs’: 2.2, ‘humerous’: 1.4, ‘humiliate’: -2.5, ‘humiliated’: -1.4, ‘humiliates’: -1.0, ‘humiliating’: -1.2, ‘humiliatingly’: -2.6, ‘humiliation’: -2.7, ‘humiliations’: -2.4, ‘humor’: 1.1, ‘humoral’: 0.6, ‘humored’: 1.2, ‘humoresque’: 1.2, ‘humoresques’: 0.9, ‘humoring’: 2.1, ‘humorist’: 1.2, ‘humoristic’: 1.5, ‘humorists’: 1.3, ‘humorless’: -1.3, ‘humorlessness’: -1.4, ‘humorous’: 1.6, ‘humorously’: 2.3, ‘humorousness’: 2.4, ‘humors’: 1.6, ‘humour’: 2.1, ‘humoured’: 1.1, ‘humouring’: 1.7, ‘humourous’: 2.0, ‘hunger’: -1.0, ‘hurrah’: 2.6, ‘hurrahed’: 1.9, ‘hurrahing’: 2.4, ‘hurrahs’: 2.1, ‘hurray’: 2.7, ‘hurrayed’: 1.8, ‘hurraying’: 1.2, ‘hurrays’: 2.4, ‘hurt’: -2.4, ‘hurter’: -2.3, ‘hurters’: -1.9, ‘hurtful’: -2.4, ‘hurtfully’: -2.6, ‘hurtfulness’: -1.9, ‘hurting’: -1.7, ‘hurtle’: -0.3, ‘hurtled’: -0.6, ‘hurtles’: -1.0, ‘hurtless’: 0.3, ‘hurtling’: -1.4, ‘hurts’: -2.1, ‘hypocritical’: -2.0, ‘hysteria’: -1.9, ‘hysterical’: -0.1, ‘hysterics’: -1.8, ‘ideal’: 2.4, ‘idealess’: -1.9, ‘idealise’: 1.4, ‘idealised’: 2.1, ‘idealises’: 2.0, ‘idealising’: 0.6, ‘idealism’: 1.7, ‘idealisms’: 0.8, ‘idealist’: 1.6, ‘idealistic’: 1.8, ‘idealistically’: 1.7, ‘idealists’: 0.7, ‘idealities’: 1.5, ‘ideality’: 1.9, ‘idealization’: 1.8, ‘idealizations’: 1.4, ‘idealize’: 1.2, ‘idealized’: 1.8, ‘idealizer’: 1.3, ‘idealizers’: 1.9, ‘idealizes’: 2.0, ‘idealizing’: 1.4, ‘idealless’: -1.7, ‘ideally’: 1.8, ‘idealogues’: 0.5, ‘idealogy’: 0.8, ‘ideals’: 0.8, ‘idiot’: -2.3, ‘idiotic’: -2.6, ‘ignorable’: -1.0, ‘ignorami’: -1.9, ‘ignoramus’: -1.9, ‘ignoramuses’: -2.3, ‘ignorance’: -1.5, ‘ignorances’: -1.2, ‘ignorant’: -1.1, ‘ignorantly’: -1.6, ‘ignorantness’: -1.1, ‘ignore’: -1.5, ‘ignored’: -1.3, ‘ignorer’: -1.3, ‘ignorers’: -0.7, ‘ignores’: -1.1, ‘ignoring’: -1.7, ‘ill’: -1.8, ‘illegal’: -2.6, ‘illiteracy’: -1.9, ‘illness’: -1.7, ‘illnesses’: -2.2, ‘imbecile’: -2.2, ‘immobilized’: -1.2, ‘immoral’: -2.0, ‘immoralism’: -1.6, ‘immoralist’: -2.1, ‘immoralists’: -1.7, ‘immoralities’: -1.1, ‘immorality’: -0.6, ‘immorally’: -2.1, ‘immortal’: 1.0, ‘immune’: 1.2, ‘impatience’: -1.8, ‘impatiens’: -0.2, ‘impatient’: -1.2, ‘impatiently’: -1.7, ‘imperfect’: -1.3, ‘impersonal’: -1.3, ‘impolite’: -1.6, ‘impolitely’: -1.8, ‘impoliteness’: -1.8, ‘impolitenesses’: -2.3, ‘importance’: 1.5, ‘importancies’: 0.4, ‘importancy’: 1.4, ‘important’: 0.8, ‘importantly’: 1.3, ‘impose’: -1.2, ‘imposed’: -0.3, ‘imposes’: -0.4, ‘imposing’: -0.4, ‘impotent’: -1.1, ‘impress’: 1.9, ‘impressed’: 2.1, ‘impresses’: 2.1, ‘impressibility’: 1.2, ‘impressible’: 0.8, ‘impressing’: 2.5, ‘impression’: 0.9, ‘impressionable’: 0.2, ‘impressionism’: 0.8, ‘impressionisms’: 0.5, ‘impressionist’: 1.0, ‘impressionistic’: 1.5, ‘impressionistically’: 1.6, ‘impressionists’: 0.5, ‘impressions’: 0.9, ‘impressive’: 2.3, ‘impressively’: 2.0, ‘impressiveness’: 1.7, ‘impressment’: -0.4, ‘impressments’: 0.5, ‘impressure’: 0.6, ‘imprisoned’: -2.0, ‘improve’: 1.9, ‘improved’: 2.1, ‘improvement’: 2.0, ‘improvements’: 1.3, ‘improver’: 1.8, ‘improvers’: 1.3, ‘improves’: 1.8, ‘improving’: 1.8, ‘inability’: -1.7, ‘inaction’: -1.0, ‘inadequacies’: -1.7, ‘inadequacy’: -1.7, ‘inadequate’: -1.7, ‘inadequately’: -1.0, ‘inadequateness’: -1.7, ‘inadequatenesses’: -1.6, ‘incapable’: -1.6, ‘incapacitated’: -1.9, ‘incensed’: -2.0, ‘incentive’: 1.5, ‘incentives’: 1.3, ‘incompetence’: -2.3, ‘incompetent’: -2.1, ‘inconsiderate’: -1.9, ‘inconvenience’: -1.5, ‘inconvenient’: -1.4, ‘increase’: 1.3, ‘increased’: 1.1, ‘indecision’: -0.8, ‘indecisions’: -1.1, ‘indecisive’: -1.0, ‘indecisively’: -0.7, ‘indecisiveness’: -1.3, ‘indecisivenesses’: -0.9, ‘indestructible’: 0.6, ‘indifference’: -0.2, ‘indifferent’: -0.8, ‘indignant’: -1.8, ‘indignation’: -2.4, ‘indoctrinate’: -1.4, ‘indoctrinated’: -0.4, ‘indoctrinates’: -0.6, ‘indoctrinating’: -0.7, ‘ineffective’: -0.5, ‘ineffectively’: -1.3, ‘ineffectiveness’: -1.3, ‘ineffectual’: -1.2, ‘ineffectuality’: -1.6, ‘ineffectually’: -1.1, ‘ineffectualness’: -1.3, ‘infatuated’: 0.2, ‘infatuation’: 0.6, ‘infected’: -2.2, ‘inferior’: -1.7, ‘inferiorities’: -1.9, ‘inferiority’: -1.1, ‘inferiorly’: -2.0, ‘inferiors’: -0.5, ‘inflamed’: -1.4, ‘influential’: 1.9, ‘infringement’: -2.1, ‘infuriate’: -2.2, ‘infuriated’: -3.0, ‘infuriates’: -2.6, ‘infuriating’: -2.4, ‘inhibin’: -0.2, ‘inhibit’: -1.6, ‘inhibited’: -0.4, ‘inhibiting’: -0.4, ‘inhibition’: -1.5, ‘inhibitions’: -0.8, ‘inhibitive’: -1.4, ‘inhibitor’: -0.3, ‘inhibitors’: -1.0, ‘inhibitory’: -1.0, ‘inhibits’: -0.9, ‘injured’: -1.7, ‘injury’: -1.8, ‘injustice’: -2.7, ‘innocence’: 1.6, ‘innocency’: 1.9, ‘innocent’: 1.4, ‘innocenter’: 0.9, ‘innocently’: 1.4, ‘innocents’: 1.1, ‘innovate’: 2.2, ‘innovates’: 2.0, ‘innovation’: 1.6, ‘innovative’: 1.9, ‘inquisition’: -1.2, ‘inquisitive’: 0.7, ‘insane’: -1.7, ‘insanity’: -2.7, ‘insecure’: -1.8, ‘insecurely’: -1.4, ‘insecureness’: -1.8, ‘insecurities’: -1.8, ‘insecurity’: -1.8, ‘insensitive’: -0.9, ‘insensitivity’: -1.8, ‘insignificant’: -1.4, ‘insincere’: -1.8, ‘insincerely’: -1.9, ‘insincerity’: -1.4, ‘insipid’: -2.0, ‘inspiration’: 2.4, ‘inspirational’: 2.3, ‘inspirationally’: 2.3, ‘inspirations’: 2.1, ‘inspirator’: 1.9, ‘inspirators’: 1.2, ‘inspiratory’: 1.5, ‘inspire’: 2.7, ‘inspired’: 2.2, ‘inspirer’: 2.2, ‘inspirers’: 2.0, ‘inspires’: 1.9, ‘inspiring’: 1.8, ‘inspiringly’: 2.6, ‘inspirit’: 1.9, ‘inspirited’: 1.3, ‘inspiriting’: 1.8, ‘inspiritingly’: 2.1, ‘inspirits’: 0.8, ‘insult’: -2.3, ‘insulted’: -2.3, ‘insulter’: -2.0, ‘insulters’: -2.0, ‘insulting’: -2.2, ‘insultingly’: -2.3, ‘insults’: -1.8, ‘intact’: 0.8, ‘integrity’: 1.6, ‘intellect’: 2.0, ‘intellection’: 0.6, ‘intellections’: 0.8, ‘intellective’: 1.7, ‘intellectively’: 0.8, ‘intellects’: 1.8, ‘intellectual’: 2.3, ‘intellectualism’: 2.2, ‘intellectualist’: 2.0, ‘intellectualistic’: 1.3, ‘intellectualists’: 0.8, ‘intellectualities’: 1.7, ‘intellectuality’: 1.7, ‘intellectualization’: 1.5, ‘intellectualize’: 1.5, ‘intellectualized’: 1.2, ‘intellectualizes’: 1.8, ‘intellectualizing’: 0.8, ‘intellectually’: 1.4, ‘intellectualness’: 1.5, ‘intellectuals’: 1.6, ‘intelligence’: 2.1, ‘intelligencer’: 1.5, ‘intelligencers’: 1.6, ‘intelligences’: 1.6, ‘intelligent’: 2.0, ‘intelligential’: 1.9, ‘intelligently’: 2.0, ‘intelligentsia’: 1.5, ‘intelligibility’: 1.5, ‘intelligible’: 1.4, ‘intelligibleness’: 1.5, ‘intelligibly’: 1.2, ‘intense’: 0.3, ‘interest’: 2.0, ‘interested’: 1.7, ‘interestedly’: 1.5, ‘interesting’: 1.7, ‘interestingly’: 1.7, ‘interestingness’: 1.8, ‘interests’: 1.0, ‘interrogated’: -1.6, ‘interrupt’: -1.4, ‘interrupted’: -1.2, ‘interrupter’: -1.1, ‘interrupters’: -1.3, ‘interruptible’: -1.3, ‘interrupting’: -1.2, ‘interruption’: -1.5, ‘interruptions’: -1.7, ‘interruptive’: -1.4, ‘interruptor’: -1.3, ‘interrupts’: -1.3, ‘intimidate’: -0.8, ‘intimidated’: -1.9, ‘intimidates’: -1.3, ‘intimidating’: -1.9, ‘intimidatingly’: -1.1, ‘intimidation’: -1.8, ‘intimidations’: -1.4, ‘intimidator’: -1.6, ‘intimidators’: -1.6, ‘intimidatory’: -1.1, ‘intricate’: 0.6, ‘intrigues’: 0.9, ‘invigorate’: 1.9, ‘invigorated’: 0.8, ‘invigorates’: 2.1, ‘invigorating’: 2.1, ‘invigoratingly’: 2.0, ‘invigoration’: 1.5, ‘invigorations’: 1.2, ‘invigorator’: 1.1, ‘invigorators’: 1.2, ‘invincible’: 2.2, ‘invite’: 0.6, ‘inviting’: 1.3, ‘invulnerable’: 1.3, ‘irate’: -2.9, ‘ironic’: -0.5, ‘irony’: -0.2, ‘irrational’: -1.4, ‘irrationalism’: -1.5, ‘irrationalist’: -2.1, ‘irrationalists’: -1.5, ‘irrationalities’: -1.5, ‘irrationality’: -1.7, ‘irrationally’: -1.6, ‘irrationals’: -1.1, ‘irresistible’: 1.4, ‘irresolute’: -1.4, ‘irresponsible’: -1.9, ‘irreversible’: -0.8, ‘irritabilities’: -1.7, ‘irritability’: -1.4, ‘irritable’: -2.1, ‘irritableness’: -1.7, ‘irritably’: -1.8, ‘irritant’: -2.3, ‘irritants’: -2.1, ‘irritate’: -1.8, ‘irritated’: -2.0, ‘irritates’: -1.7, ‘irritating’: -2.0, ‘irritatingly’: -2.0, ‘irritation’: -2.3, ‘irritations’: -1.5, ‘irritative’: -2.0, ‘isolatable’: 0.2, ‘isolate’: -0.8, ‘isolated’: -1.3, ‘isolates’: -1.3, ‘isolation’: -1.7, ‘isolationism’: 0.4, ‘isolationist’: 0.7, ‘isolations’: -0.5, ‘isolator’: -0.4, ‘isolators’: -0.4, ‘itchy’: -1.1, ‘jackass’: -1.8, ‘jackasses’: -2.8, ‘jaded’: -1.6, ‘jailed’: -2.2, ‘jaunty’: 1.2, ‘jealous’: -2.0, ‘jealousies’: -2.0, ‘jealously’: -2.0, ‘jealousness’: -1.7, ‘jealousy’: -1.3, ‘jeopardy’: -2.1, ‘jerk’: -1.4, ‘jerked’: -0.8, ‘jerks’: -1.1, ‘jewel’: 1.5, ‘jewels’: 2.0, ‘jocular’: 1.2, ‘join’: 1.2, ‘joke’: 1.2, ‘joked’: 1.3, ‘joker’: 0.5, ‘jokes’: 1.0, ‘jokester’: 1.5, ‘jokesters’: 0.9, ‘jokey’: 1.1, ‘joking’: 0.9, ‘jollied’: 2.4, ‘jollier’: 2.4, ‘jollies’: 2.0, ‘jolliest’: 2.9, ‘jollification’: 2.2, ‘jollifications’: 2.0, ‘jollify’: 2.1, ‘jollily’: 2.7, ‘jolliness’: 2.5, ‘jollities’: 1.7, ‘jollity’: 1.8, ‘jolly’: 2.3, ‘jollying’: 2.3, ‘jovial’: 1.9, ‘joy’: 2.8, ‘joyance’: 2.3, ‘joyed’: 2.9, ‘joyful’: 2.9, ‘joyfuller’: 2.4, ‘joyfully’: 2.5, ‘joyfulness’: 2.7, ‘joying’: 2.5, ‘joyless’: -2.5, ‘joylessly’: -1.7, ‘joylessness’: -2.7, ‘joyous’: 3.1, ‘joyously’: 2.9, ‘joyousness’: 2.8, ‘joypop’: -0.2, ‘joypoppers’: -0.1, ‘joyridden’: 0.6, ‘joyride’: 1.1, ‘joyrider’: 0.7, ‘joyriders’: 1.3, ‘joyrides’: 0.8, ‘joyriding’: 0.9, ‘joyrode’: 1.0, ‘joys’: 2.2, ‘joystick’: 0.7, ‘joysticks’: 0.2, ‘jubilant’: 3.0, ‘jumpy’: -1.0, ‘justice’: 2.4, ‘justifiably’: 1.0, ‘justified’: 1.7, ‘keen’: 1.5, ‘keened’: 0.3, ‘keener’: 0.5, ‘keeners’: 0.6, ‘keenest’: 1.9, ‘keening’: -0.7, ‘keenly’: 1.0, ‘keenness’: 1.4, ‘keens’: 0.1, ‘kewl’: 1.3, ‘kidding’: 0.4, ‘kill’: -3.7, ‘killdeer’: -1.1, ‘killdeers’: -0.1, ‘killdees’: -0.6, ‘killed’: -3.5, ‘killer’: -3.3, ‘killers’: -3.3, ‘killick’: 0.1, ‘killie’: -0.1, ‘killifish’: -0.1, ‘killifishes’: -0.1, ‘killing’: -3.4, ‘killingly’: -2.6, ‘killings’: -3.5, ‘killjoy’: -2.1, ‘killjoys’: -1.7, ‘killock’: -0.3, ‘killocks’: -0.4, ‘kills’: -2.5, ‘kind’: 2.4, ‘kinder’: 2.2, ‘kindly’: 2.2, ‘kindness’: 2.0, ‘kindnesses’: 2.3, ‘kiss’: 1.8, ‘kissable’: 2.0, ‘kissably’: 1.9, ‘kissed’: 1.6, ‘kisser’: 1.7, ‘kissers’: 1.5, ‘kisses’: 2.3, ‘kissing’: 2.7, ‘kissy’: 1.8, ‘kudos’: 2.3, ‘lack’: -1.3, ‘lackadaisical’: -1.6, ‘lag’: -1.4, ‘lagged’: -1.2, ‘lagging’: -1.1, ‘lags’: -1.5, ‘laidback’: 0.5, ‘lame’: -1.8, ‘lamebrain’: -1.6, ‘lamebrained’: -2.5, ‘lamebrains’: -1.2, ‘lamedh’: 0.1, ‘lamella’: -0.1, ‘lamellae’: -0.1, ‘lamellas’: 0.1, ‘lamellibranch’: 0.2, ‘lamellibranchs’: -0.1, ‘lamely’: -2.0, ‘lameness’: -0.8, ‘lament’: -2.0, ‘lamentable’: -1.5, ‘lamentableness’: -1.3, ‘lamentably’: -1.5, ‘lamentation’: -1.4, ‘lamentations’: -1.9, ‘lamented’: -1.4, ‘lamenter’: -1.2, ‘lamenters’: -0.5, ‘lamenting’: -2.0, ‘laments’: -1.5, ‘lamer’: -1.4, ‘lames’: -1.2, ‘lamest’: -1.5, ‘landmark’: 0.3, ‘laugh’: 2.6, ‘laughable’: 0.2, ‘laughableness’: 1.2, ‘laughably’: 1.2, ‘laughed’: 2.0, ‘laugher’: 1.7, ‘laughers’: 1.7, ‘laughing’: 2.2, ‘laughingly’: 2.3, ‘laughings’: 1.9, ‘laughingstocks’: -1.3, ‘laughs’: 2.2, ‘laughter’: 2.2, ‘laughters’: 2.2, ‘launched’: 0.5, ‘lawl’: 1.4, ‘lawsuit’: -0.9, ‘lawsuits’: -0.6, ‘lazier’: -2.3, ‘laziest’: -2.7, ‘lazy’: -1.5, ‘leak’: -1.4, ‘leaked’: -1.3, ‘leave’: -0.2, ‘leet’: 1.3, ‘legal’: 0.5, ‘legally’: 0.4, ‘lenient’: 1.1, ‘lethargic’: -1.2, ‘lethargy’: -1.4, ‘liabilities’: -0.8, ‘liability’: -0.8, ‘liar’: -2.3, ‘liards’: -0.4, ‘liars’: -2.4, ‘libelous’: -2.1, ‘libertarian’: 0.9, ‘libertarianism’: 0.4, ‘libertarianisms’: 0.1, ‘libertarians’: 0.1, ‘liberties’: 2.3, ‘libertinage’: 0.2, ‘libertine’: -0.9, ‘libertines’: 0.4, ‘libertinisms’: 1.2, ‘liberty’: 2.4, ‘lied’: -1.6, ‘lies’: -1.8, ‘lifesaver’: 2.8, ‘lighthearted’: 1.8, ‘like’: 1.5, ‘likeable’: 2.0, ‘liked’: 1.8, ‘likes’: 1.8, ‘liking’: 1.7, ‘limitation’: -1.2, ‘limited’: -0.9, ‘litigation’: -0.8, ‘litigious’: -0.8, ‘livelier’: 1.7, ‘liveliest’: 2.1, ‘livelihood’: 0.8, ‘livelihoods’: 0.9, ‘livelily’: 1.8, ‘liveliness’: 1.6, ‘livelong’: 1.7, ‘lively’: 1.9, ‘livid’: -2.5, ‘loathe’: -2.2, ‘loathed’: -2.1, ‘loathes’: -1.9, ‘loathing’: -2.7, ‘lobby’: 0.1, ‘lobbying’: -0.3, ‘lone’: -1.1, ‘lonelier’: -1.4, ‘loneliest’: -2.4, ‘loneliness’: -1.8, ‘lonelinesses’: -1.5, ‘lonely’: -1.5, ‘loneness’: -1.1, ‘loner’: -1.3, ‘loners’: -0.9, ‘lonesome’: -1.5, ‘lonesomely’: -1.3, ‘lonesomeness’: -1.8, ‘lonesomes’: -1.4, ‘longing’: -0.1, ‘longingly’: 0.7, ‘longings’: 0.4, ‘loom’: -0.9, ‘loomed’: -1.1, ‘looming’: -0.5, ‘looms’: -0.6, ‘loose’: -1.3, ‘looses’: -0.6, ‘lose’: -1.7, ‘loser’: -2.4, ‘losers’: -2.4, ‘loses’: -1.3, ‘losing’: -1.6, ‘loss’: -1.3, ‘losses’: -1.7, ‘lossy’: -1.2, ‘lost’: -1.3, ‘louse’: -1.6, ‘loused’: -1.0, ‘louses’: -1.3, ‘lousewort’: 0.1, ‘louseworts’: -0.6, ‘lousier’: -2.2, ‘lousiest’: -2.6, ‘lousily’: -1.2, ‘lousiness’: -1.7, ‘lousing’: -1.1, ‘lousy’: -2.5, ‘lovable’: 3.0, ‘love’: 3.2, ‘loved’: 2.9, ‘lovelies’: 2.2, ‘lovely’: 2.8, ‘lover’: 2.8, ‘loverly’: 2.8, ‘lovers’: 2.4, ‘loves’: 2.7, ‘loving’: 2.9, ‘lovingly’: 3.2, ‘lovingness’: 2.7, ‘low’: -1.1, ‘lowball’: -0.8, ‘lowballed’: -1.5, ‘lowballing’: -0.7, ‘lowballs’: -1.2, ‘lowborn’: -0.7, ‘lowboys’: -0.6, ‘lowbred’: -2.6, ‘lowbrow’: -1.9, ‘lowbrows’: -0.6, ‘lowdown’: -0.8, ‘lowdowns’: -0.2, ‘lowe’: 0.5, ‘lowed’: -0.8, ‘lower’: -1.2, ‘lowercase’: 0.3, ‘lowercased’: -0.2, ‘lowerclassman’: -0.4, ‘lowered’: -0.5, ‘lowering’: -1.0, ‘lowermost’: -1.4, ‘lowers’: -0.5, ‘lowery’: -1.8, ‘lowest’: -1.6, ‘lowing’: -0.5, ‘lowish’: -0.9, ‘lowland’: -0.1, ‘lowlander’: -0.4, ‘lowlanders’: -0.3, ‘lowlands’: -0.1, ‘lowlier’: -1.7, ‘lowliest’: -1.8, ‘lowlife’: -1.5, ‘lowlifes’: -2.2, ‘lowlight’: -2.0, ‘lowlights’: -0.3, ‘lowlihead’: -0.3, ‘lowliness’: -1.1, ‘lowlinesses’: -1.2, ‘lowlives’: -2.1, ‘lowly’: -1.0, ‘lown’: 0.9, ‘lowness’: -1.3, ‘lowrider’: -0.2, ‘lowriders’: 0.1, ‘lows’: -0.8, ‘lowse’: -0.7, ‘loyal’: 2.1, ‘loyalism’: 1.0, ‘loyalisms’: 0.9, ‘loyalist’: 1.5, ‘loyalists’: 1.1, ‘loyally’: 2.1, ‘loyalties’: 1.9, ‘loyalty’: 2.5, ‘luck’: 2.0, ‘lucked’: 1.9, ‘luckie’: 1.6, ‘luckier’: 1.9, ‘luckiest’: 2.9, ‘luckily’: 2.3, ‘luckiness’: 1.0, ‘lucking’: 1.2, ‘luckless’: -1.3, ‘lucks’: 1.6, ‘lucky’: 1.8, ‘ludicrous’: -1.5, ‘ludicrously’: -0.2, ‘ludicrousness’: -1.9, ‘lugubrious’: -2.1, ‘lulz’: 2.0, ‘lunatic’: -2.2, ‘lunatics’: -1.6, ‘lurk’: -0.8, ‘lurking’: -0.5, ‘lurks’: -0.9, ‘lying’: -2.4, ‘mad’: -2.2, ‘maddening’: -2.2, ‘madder’: -1.2, ‘maddest’: -2.8, ‘madly’: -1.7, ‘madness’: -1.9, ‘magnific’: 2.3, ‘magnifical’: 2.4, ‘magnifically’: 2.4, ‘magnification’: 1.0, ‘magnifications’: 1.2, ‘magnificence’: 2.4, ‘magnificences’: 2.3, ‘magnificent’: 2.9, ‘magnificently’: 3.4, ‘magnifico’: 1.8, ‘magnificoes’: 1.4, ‘mandatory’: 0.3, ‘maniac’: -2.1, ‘maniacal’: -0.3, ‘maniacally’: -1.7, ‘maniacs’: -1.2, ‘manipulated’: -1.6, ‘manipulating’: -1.5, ‘manipulation’: -1.2, ‘marvel’: 1.8, ‘marvelous’: 2.9, ‘marvels’: 2.0, ‘masochism’: -1.6, ‘masochisms’: -1.1, ‘masochist’: -1.7, ‘masochistic’: -2.2, ‘masochistically’: -1.6, ‘masochists’: -1.2, ‘masterpiece’: 3.1, ‘masterpieces’: 2.5, ‘matter’: 0.1, ‘matters’: 0.1, ‘mature’: 1.8, ‘meaningful’: 1.3, ‘meaningless’: -1.9, ‘medal’: 2.1, ‘mediocrity’: -0.3, ‘meditative’: 1.4, ‘meh’: -0.3, ‘melancholia’: -0.5, ‘melancholiac’: -2.0, ‘melancholias’: -1.6, ‘melancholic’: -0.3, ‘melancholics’: -1.0, ‘melancholies’: -1.1, ‘melancholy’: -1.9, ‘menace’: -2.2, ‘menaced’: -1.7, ‘mercy’: 1.5, ‘merit’: 1.8, ‘merited’: 1.4, ‘meriting’: 1.1, ‘meritocracy’: 0.6, ‘meritocrat’: 0.4, ‘meritocrats’: 1.1, ‘meritorious’: 2.1, ‘meritoriously’: 1.3, ‘meritoriousness’: 1.7, ‘merits’: 1.7, ‘merrier’: 1.7, ‘merriest’: 2.7, ‘merrily’: 2.4, ‘merriment’: 2.4, ‘merriments’: 2.0, ‘merriness’: 2.2, ‘merry’: 2.5, ‘merrymaker’: 2.2, ‘merrymakers’: 1.7, ‘merrymaking’: 2.2, ‘merrymakings’: 2.4, ‘merrythought’: 1.1, ‘merrythoughts’: 1.6, ‘mess’: -1.5, ‘messed’: -1.4, ‘messy’: -1.5, ‘methodical’: 0.6, ‘mindless’: -1.9, ‘miracle’: 2.8, ‘mirth’: 2.6, ‘mirthful’: 2.7, ‘mirthfully’: 2.0, ‘misbehave’: -1.9, ‘misbehaved’: -1.6, ‘misbehaves’: -1.6, ‘misbehaving’: -1.7, ‘mischief’: -1.5, ‘mischiefs’: -0.8, ‘miser’: -1.8, ‘miserable’: -2.2, ‘miserableness’: -2.8, ‘miserably’: -2.1, ‘miserere’: -0.8, ‘misericorde’: 0.1, ‘misericordes’: -0.5, ‘miseries’: -2.7, ‘miserliness’: -2.6, ‘miserly’: -1.4, ‘misers’: -1.5, ‘misery’: -2.7, ‘misgiving’: -1.4, ‘misinformation’: -1.3, ‘misinformed’: -1.6, ‘misinterpreted’: -1.3, ‘misleading’: -1.7, ‘misread’: -1.1, ‘misreporting’: -1.5, ‘misrepresentation’: -2.0, ‘miss’: -0.6, ‘missed’: -1.2, ‘misses’: -0.9, ‘missing’: -1.2, ‘mistakable’: -0.8, ‘mistake’: -1.4, ‘mistaken’: -1.5, ‘mistakenly’: -1.2, ‘mistaker’: -1.6, ‘mistakers’: -1.6, ‘mistakes’: -1.5, ‘mistaking’: -1.1, ‘misunderstand’: -1.5, ‘misunderstanding’: -1.8, ‘misunderstands’: -1.3, ‘misunderstood’: -1.4, ‘mlm’: -1.4, ‘mmk’: 0.6, ‘moan’: -0.6, ‘moaned’: -0.4, ‘moaning’: -0.4, ‘moans’: -0.6, ‘mock’: -1.8, ‘mocked’: -1.3, ‘mocker’: -0.8, ‘mockeries’: -1.6, ‘mockers’: -1.3, ‘mockery’: -1.3, ‘mocking’: -1.7, ‘mocks’: -2.0, ‘molest’: -2.1, ‘molestation’: -1.9, ‘molestations’: -2.9, ‘molested’: -1.9, ‘molester’: -2.3, ‘molesters’: -2.2, ‘molesting’: -2.8, ‘molests’: -3.1, ‘mongering’: -0.8, ‘monopolize’: -0.8, ‘monopolized’: -0.9, ‘monopolizes’: -1.1, ‘monopolizing’: -0.5, ‘mooch’: -1.7, ‘mooched’: -1.4, ‘moocher’: -1.5, ‘moochers’: -1.9, ‘mooches’: -1.4, ‘mooching’: -1.7, ‘moodier’: -1.1, ‘moodiest’: -2.1, ‘moodily’: -1.3, ‘moodiness’: -1.4, ‘moodinesses’: -1.4, ‘moody’: -1.5, ‘mope’: -1.9, ‘moping’: -1.0, ‘moron’: -2.2, ‘moronic’: -2.7, ‘moronically’: -1.4, ‘moronity’: -1.1, ‘morons’: -1.3, ‘motherfucker’: -3.6, ‘motherfucking’: -2.8, ‘motivate’: 1.6, ‘motivated’: 2.0, ‘motivating’: 2.2, ‘motivation’: 1.4, ‘mourn’: -1.8, ‘mourned’: -1.3, ‘mourner’: -1.6, ‘mourners’: -1.8, ‘mournful’: -1.6, ‘mournfuller’: -1.9, ‘mournfully’: -1.7, ‘mournfulness’: -1.8, ‘mourning’: -1.9, ‘mourningly’: -2.3, ‘mourns’: -2.4, ‘mumpish’: -1.4, ‘murder’: -3.7, ‘murdered’: -3.4, ‘murderee’: -3.2, ‘murderees’: -3.1, ‘murderer’: -3.6, ‘murderers’: -3.3, ‘murderess’: -2.2, ‘murderesses’: -2.6, ‘murdering’: -3.3, ‘murderous’: -3.2, ‘murderously’: -3.1, ‘murderousness’: -2.9, ‘murders’: -3.0, ‘n00b’: -1.6, ‘nag’: -1.5, ‘nagana’: -1.7, ‘nagged’: -1.7, ‘nagger’: -1.8, ‘naggers’: -1.5, ‘naggier’: -1.4, ‘naggiest’: -2.4, ‘nagging’: -1.7, ‘naggingly’: -0.9, ‘naggy’: -1.7, ‘nags’: -1.1, ‘nah’: -0.4, ‘naive’: -1.1, ‘nastic’: 0.2, ‘nastier’: -2.3, ‘nasties’: -2.1, ‘nastiest’: -2.4, ‘nastily’: -1.9, ‘nastiness’: -1.1, ‘nastinesses’: -2.6, ‘nasturtium’: 0.4, ‘nasturtiums’: 0.1, ‘nasty’: -2.6, ‘natural’: 1.5, ‘neat’: 2.0, ‘neaten’: 1.2, ‘neatened’: 2.0, ‘neatening’: 1.3, ‘neatens’: 1.1, ‘neater’: 1.0, ‘neatest’: 1.7, ‘neath’: 0.2, ‘neatherd’: -0.4, ‘neatly’: 1.4, ‘neatness’: 1.3, ‘neats’: 1.1, ‘needy’: -1.4, ‘negative’: -2.7, ‘negativity’: -2.3, ‘neglect’: -2.0, ‘neglected’: -2.4, ‘neglecter’: -1.7, ‘neglecters’: -1.5, ‘neglectful’: -2.0, ‘neglectfully’: -2.1, ‘neglectfulness’: -2.0, ‘neglecting’: -1.7, ‘neglects’: -2.2, ‘nerd’: -1.2, ‘nerdier’: -0.2, ‘nerdiest’: 0.6, ‘nerdish’: -0.1, ‘nerdy’: -0.2, ‘nerves’: -0.4, ‘nervous’: -1.1, ‘nervously’: -0.6, ‘nervousness’: -1.2, ‘neurotic’: -1.4, ‘neurotically’: -1.8, ‘neuroticism’: -0.9, ‘neurotics’: -0.7, ‘nice’: 1.8, ‘nicely’: 1.9, ‘niceness’: 1.6, ‘nicenesses’: 2.1, ‘nicer’: 1.9, ‘nicest’: 2.2, ‘niceties’: 1.5, ‘nicety’: 1.2, ‘nifty’: 1.7, ‘niggas’: -1.4, ‘nigger’: -3.3, ‘no’: -1.2, ‘noble’: 2.0, ‘noisy’: -0.7, ‘nonsense’: -1.7, ‘noob’: -0.2, ‘nosey’: -0.8, ‘notorious’: -1.9, ‘novel’: 1.3, ‘numb’: -1.4, ‘numbat’: 0.2, ‘numbed’: -0.9, ‘number’: 0.3, ‘numberable’: 0.6, ‘numbest’: -1.0, ‘numbfish’: -0.4, ‘numbfishes’: -0.7, ‘numbing’: -1.1, ‘numbingly’: -1.3, ‘numbles’: 0.4, ‘numbly’: -1.4, ‘numbness’: -1.1, ‘numbs’: -0.7, ‘numbskull’: -2.3, ‘numbskulls’: -2.2, ‘nurtural’: 1.5, ‘nurturance’: 1.6, ‘nurturances’: 1.3, ‘nurturant’: 1.7, ‘nurture’: 1.4, ‘nurtured’: 1.9, ‘nurturer’: 1.9, ‘nurturers’: 0.8, ‘nurtures’: 1.9, ‘nurturing’: 2.0, ‘nuts’: -1.3, ‘o/\\o’: 2.1, ‘o_0’: -0.1, ‘obliterate’: -2.9, ‘obliterated’: -2.1, ‘obnoxious’: -2.0, ‘obnoxiously’: -2.3, ‘obnoxiousness’: -2.1, ‘obscene’: -2.8, ‘obsess’: -1.0, ‘obsessed’: -0.7, ‘obsesses’: -1.0, ‘obsessing’: -1.4, ‘obsession’: -1.4, ‘obsessional’: -1.5, ‘obsessionally’: -1.3, ‘obsessions’: -0.9, ‘obsessive’: -0.9, ‘obsessively’: -0.4, ‘obsessiveness’: -1.2, ‘obsessives’: -0.7, ‘obsolete’: -1.2, ‘obstacle’: -1.5, ‘obstacles’: -1.6, ‘obstinate’: -1.2, ‘odd’: -1.3, ‘offence’: -1.2, ‘offences’: -1.4, ‘offend’: -1.2, ‘offended’: -1.0, ‘offender’: -1.5, ‘offenders’: -1.5, ‘offending’: -2.3, ‘offends’: -2.0, ‘offense’: -1.0, ‘offenseless’: 0.7, ‘offenses’: -1.5, ‘offensive’: -2.0, ‘offensively’: -2.8, ‘offensiveness’: -2.3, ‘offensives’: -0.8, ‘offline’: -0.5, ‘okay’: 0.9, ‘okays’: 2.1, ‘ominous’: -1.4, ‘once-in-a-lifetime’: 1.8, ‘openness’: 1.4, ‘opportune’: 1.7, ‘opportunely’: 1.5, ‘opportuneness’: 1.2, ‘opportunism’: 0.4, ‘opportunisms’: 0.2, ‘opportunist’: 0.2, ‘opportunistic’: -0.1, ‘opportunistically’: 0.9, ‘opportunists’: 0.3, ‘opportunities’: 1.6, ‘opportunity’: 1.8, ‘oppressed’: -2.1, ‘oppressive’: -1.7, ‘optimal’: 1.5, ‘optimality’: 1.9, ‘optimally’: 1.3, ‘optimisation’: 1.6, ‘optimisations’: 1.8, ‘optimise’: 1.9, ‘optimised’: 1.7, ‘optimises’: 1.6, ‘optimising’: 1.7, ‘optimism’: 2.5, ‘optimisms’: 2.0, ‘optimist’: 2.4, ‘optimistic’: 1.3, ‘optimistically’: 2.1, ‘optimists’: 1.6, ‘optimization’: 1.6, ‘optimizations’: 0.9, ‘optimize’: 2.2, ‘optimized’: 2.0, ‘optimizer’: 1.5, ‘optimizers’: 2.1, ‘optimizes’: 1.8, ‘optimizing’: 2.0, ‘optionless’: -1.7, ‘original’: 1.3, ‘outcry’: -2.3, ‘outgoing’: 1.2, ‘outmaneuvered’: 0.5, ‘outrage’: -2.3, ‘outraged’: -2.5, ‘outrageous’: -2.0, ‘outrageously’: -1.2, ‘outrageousness’: -1.2, ‘outrageousnesses’: -1.3, ‘outrages’: -2.3, ‘outraging’: -2.0, ‘outreach’: 1.1, ‘outstanding’: 3.0, ‘overjoyed’: 2.7, ‘overload’: -1.5, ‘overlooked’: -0.1, ‘overreact’: -1.0, ‘overreacted’: -1.7, ‘overreaction’: -0.7, ‘overreacts’: -2.2, ‘oversell’: -0.9, ‘overselling’: -0.8, ‘oversells’: 0.3, ‘oversimplification’: 0.2, ‘oversimplifies’: 0.1, ‘oversimplify’: -0.6, ‘overstatement’: -1.1, ‘overstatements’: -0.7, ‘overweight’: -1.5, ‘overwhelm’: -0.7, ‘overwhelmed’: 0.2, ‘overwhelmingly’: -0.5, ‘overwhelms’: -0.8, ‘oxymoron’: -0.5, ‘pain’: -2.3, ‘pained’: -1.8, ‘painful’: -1.9, ‘painfuller’: -1.7, ‘painfully’: -2.4, ‘painfulness’: -2.7, ‘paining’: -1.7, ‘painless’: 1.2, ‘painlessly’: 1.1, ‘painlessness’: 0.4, ‘pains’: -1.8, ‘palatable’: 1.6, ‘palatableness’: 0.8, ‘palatably’: 1.1, ‘panic’: -2.3, ‘panicked’: -2.0, ‘panicking’: -1.9, ‘panicky’: -1.5, ‘panicle’: 0.5, ‘panicled’: 0.1, ‘panicles’: -0.2, ‘panics’: -1.9, ‘paniculate’: 0.1, ‘panicums’: -0.1, ‘paradise’: 3.2, ‘paradox’: -0.4, ‘paranoia’: -1.0, ‘paranoiac’: -1.3, ‘paranoiacs’: -0.7, ‘paranoias’: -1.5, ‘paranoid’: -1.0, ‘paranoids’: -1.6, ‘pardon’: 1.3, ‘pardoned’: 0.9, ‘pardoning’: 1.7, ‘pardons’: 1.2, ‘parley’: -0.4, ‘partied’: 1.4, ‘partier’: 1.4, ‘partiers’: 0.7, ‘parties’: 1.7, ‘party’: 1.7, ‘partyer’: 1.2, ‘partyers’: 1.1, ‘partying’: 1.6, ‘passion’: 2.0, ‘passional’: 1.6, ‘passionate’: 2.4, ‘passionately’: 2.4, ‘passionateness’: 2.3, ‘passionflower’: 0.3, ‘passionflowers’: 0.4, ‘passionless’: -1.9, ‘passions’: 2.2, ‘passive’: 0.8, ‘passively’: -0.7, ‘pathetic’: -2.7, ‘pathetical’: -1.2, ‘pathetically’: -1.8, ‘pay’: -0.4, ‘peace’: 2.5, ‘peaceable’: 1.7, ‘peaceableness’: 1.8, ‘peaceably’: 2.0, ‘peaceful’: 2.2, ‘peacefuller’: 1.9, ‘peacefullest’: 3.1, ‘peacefully’: 2.4, ‘peacefulness’: 2.1, ‘peacekeeper’: 1.6, ‘peacekeepers’: 1.6, ‘peacekeeping’: 2.0, ‘peacekeepings’: 1.6, ‘peacemaker’: 2.0, ‘peacemakers’: 2.4, ‘peacemaking’: 1.7, ‘peacenik’: 0.8, ‘peaceniks’: 0.7, ‘peaces’: 2.1, ‘peacetime’: 2.2, ‘peacetimes’: 2.1, ‘peculiar’: 0.6, ‘peculiarities’: 0.1, ‘peculiarity’: 0.6, ‘peculiarly’: -0.4, ‘penalty’: -2.0, ‘pensive’: 0.3, ‘perfect’: 2.7, ‘perfecta’: 1.4, ‘perfectas’: 0.6, ‘perfected’: 2.7, ‘perfecter’: 1.8, ‘perfecters’: 1.4, ‘perfectest’: 3.1, ‘perfectibilities’: 2.1, ‘perfectibility’: 1.8, ‘perfectible’: 1.5, ‘perfecting’: 2.3, ‘perfection’: 2.7, ‘perfectionism’: 1.3, ‘perfectionist’: 1.5, ‘perfectionistic’: 0.7, ‘perfectionists’: 0.1, ‘perfections’: 2.5, ‘perfective’: 1.2, ‘perfectively’: 2.1, ‘perfectiveness’: 0.9, ‘perfectives’: 0.9, ‘perfectivity’: 2.2, ‘perfectly’: 3.2, ‘perfectness’: 3.0, ‘perfecto’: 1.3, ‘perfects’: 1.6, ‘peril’: -1.7, ‘perjury’: -1.9, ‘perpetrator’: -2.2, ‘perpetrators’: -1.0, ‘perplexed’: -1.3, ‘persecute’: -2.1, ‘persecuted’: -1.3, ‘persecutes’: -1.2, ‘persecuting’: -1.5, ‘perturbed’: -1.4, ‘perverse’: -1.8, ‘perversely’: -2.2, ‘perverseness’: -2.1, ‘perversenesses’: -0.5, ‘perversion’: -1.3, ‘perversions’: -1.2, ‘perversities’: -1.1, ‘perversity’: -2.6, ‘perversive’: -2.1, ‘pervert’: -2.3, ‘perverted’: -2.5, ‘pervertedly’: -1.2, ‘pervertedness’: -1.2, ‘perverter’: -1.7, ‘perverters’: -0.6, ‘perverting’: -1.0, ‘perverts’: -2.8, ‘pesky’: -1.2, ‘pessimism’: -1.5, ‘pessimisms’: -2.0, ‘pessimist’: -1.5, ‘pessimistic’: -1.5, ‘pessimistically’: -2.0, ‘pessimists’: -1.0, ‘petrifaction’: -1.9, ‘petrifactions’: -0.3, ‘petrification’: -0.1, ‘petrifications’: -0.4, ‘petrified’: -2.5, ‘petrifies’: -2.3, ‘petrify’: -1.7, ‘petrifying’: -2.6, ‘pettier’: -0.3, ‘pettiest’: -1.3, ‘petty’: -0.8, ‘phobia’: -1.6, ‘phobias’: -2.0, ‘phobic’: -1.2, ‘phobics’: -1.3, ‘picturesque’: 1.6, ‘pileup’: -1.1, ‘pique’: -1.1, ‘piqued’: 0.1, ‘piss’: -1.7, ‘pissant’: -1.5, ‘pissants’: -2.5, ‘pissed’: -3.2, ‘pisser’: -2.0, ‘pissers’: -1.4, ‘pisses’: -1.4, ‘pissing’: -1.7, ‘pissoir’: -0.8, ‘piteous’: -1.2, ‘pitiable’: -1.1, ‘pitiableness’: -1.1, ‘pitiably’: -1.1, ‘pitied’: -1.3, ‘pitier’: -1.2, ‘pitiers’: -1.3, ‘pities’: -1.2, ‘pitiful’: -2.2, ‘pitifuller’: -1.8, ‘pitifullest’: -1.1, ‘pitifully’: -1.2, ‘pitifulness’: -1.2, ‘pitiless’: -1.8, ‘pitilessly’: -2.1, ‘pitilessness’: -0.5, ‘pity’: -1.2, ‘pitying’: -1.4, ‘pityingly’: -1.0, ‘pityriasis’: -0.8, ‘play’: 1.4, ‘played’: 1.4, ‘playful’: 1.9, ‘playfully’: 1.6, ‘playfulness’: 1.2, ‘playing’: 0.8, ‘plays’: 1.0, ‘pleasant’: 2.3, ‘pleasanter’: 1.5, ‘pleasantest’: 2.6, ‘pleasantly’: 2.1, ‘pleasantness’: 2.3, ‘pleasantnesses’: 2.3, ‘pleasantries’: 1.3, ‘pleasantry’: 2.0, ‘please’: 1.3, ‘pleased’: 1.9, ‘pleaser’: 1.7, ‘pleasers’: 1.0, ‘pleases’: 1.7, ‘pleasing’: 2.4, ‘pleasurability’: 1.9, ‘pleasurable’: 2.4, ‘pleasurableness’: 2.4, ‘pleasurably’: 2.6, ‘pleasure’: 2.7, ‘pleasured’: 2.3, ‘pleasureless’: -1.6, ‘pleasures’: 1.9, ‘pleasuring’: 2.8, ‘poised’: 1.0, ‘poison’: -2.5, ‘poisoned’: -2.2, ‘poisoner’: -2.7, ‘poisoners’: -3.1, ‘poisoning’: -2.8, ‘poisonings’: -2.4, ‘poisonous’: -2.7, ‘poisonously’: -2.9, ‘poisons’: -2.7, ‘poisonwood’: -1.0, ‘pollute’: -2.3, ‘polluted’: -2.0, ‘polluter’: -1.8, ‘polluters’: -2.0, ‘pollutes’: -2.2, ‘poor’: -2.1, ‘poorer’: -1.5, ‘poorest’: -2.5, ‘popular’: 1.8, ‘popularise’: 1.6, ‘popularised’: 1.1, ‘popularises’: 0.5, ‘popularising’: 1.2, ‘popularities’: 1.6, ‘popularity’: 2.1, ‘popularization’: 1.3, ‘popularizations’: 0.9, ‘popularize’: 1.3, ‘popularized’: 1.9, ‘popularizer’: 1.8, ‘popularizers’: 1.0, ‘popularizes’: 1.4, ‘popularizing’: 1.5, ‘popularly’: 1.8, ‘positive’: 2.6, ‘positively’: 2.4, ‘positiveness’: 2.3, ‘positivenesses’: 2.2, ‘positiver’: 2.3, ‘positives’: 2.4, ‘positivest’: 2.9, ‘positivism’: 1.6, ‘positivisms’: 1.8, ‘positivist’: 2.0, ‘positivistic’: 1.9, ‘positivists’: 1.7, ‘positivities’: 2.6, ‘positivity’: 2.3, ‘possessive’: -0.9, ‘postpone’: -0.9, ‘postponed’: -0.8, ‘postpones’: -1.1, ‘postponing’: -0.5, ‘poverty’: -2.3, ‘powerful’: 1.8, ‘powerless’: -2.2, ‘praise’: 2.6, ‘praised’: 2.2, ‘praiser’: 2.0, ‘praisers’: 2.0, ‘praises’: 2.4, ‘praiseworthily’: 1.9, ‘praiseworthiness’: 2.4, ‘praiseworthy’: 2.6, ‘praising’: 2.5, ‘pray’: 1.3, ‘praying’: 1.5, ‘prays’: 1.4, ‘prblm’: -1.6, ‘prblms’: -2.3, ‘precious’: 2.7, ‘preciously’: 2.2, ‘preciousness’: 1.9, ‘prejudice’: -2.3, ‘prejudiced’: -1.9, ‘prejudices’: -1.8, ‘prejudicial’: -2.6, ‘prejudicially’: -1.5, ‘prejudicialness’: -2.4, ‘prejudicing’: -1.8, ‘prepared’: 0.9, ‘pressure’: -1.2, ‘pressured’: -0.9, ‘pressureless’: 1.0, ‘pressures’: -1.3, ‘pressuring’: -1.4, ‘pressurise’: -0.6, ‘pressurised’: -0.4, ‘pressurises’: -0.8, ‘pressurising’: -0.6, ‘pressurizations’: -0.3, ‘pressurize’: -0.7, ‘pressurized’: 0.1, ‘pressurizer’: 0.1, ‘pressurizers’: -0.7, ‘pressurizes’: -0.2, ‘pressurizing’: -0.2, ‘pretend’: -0.4, ‘pretending’: 0.4, ‘pretends’: -0.4, ‘prettied’: 1.6, ‘prettier’: 2.1, ‘pretties’: 1.7, ‘prettiest’: 2.7, ‘pretty’: 2.2, ‘prevent’: 0.1, ‘prevented’: 0.1, ‘preventing’: -0.1, ‘prevents’: 0.3, ‘prick’: -1.4, ‘pricked’: -0.6, ‘pricker’: -0.3, ‘prickers’: -0.2, ‘pricket’: -0.5, ‘prickets’: 0.3, ‘pricking’: -0.9, ‘prickle’: -1.0, ‘prickled’: -0.2, ‘prickles’: -0.8, ‘pricklier’: -1.6, ‘prickliest’: -1.4, ‘prickliness’: -0.6, ‘prickling’: -0.8, ‘prickly’: -0.9, ‘pricks’: -0.9, ‘pricky’: -0.6, ‘pride’: 1.4, ‘prison’: -2.3, ‘prisoner’: -2.5, ‘prisoners’: -2.3, ‘privilege’: 1.5, ‘privileged’: 1.9, ‘privileges’: 1.6, ‘privileging’: 0.7, ‘prize’: 2.3, ‘prized’: 2.4, ‘prizefight’: -0.1, ‘prizefighter’: 1.0, ‘prizefighters’: -0.1, ‘prizefighting’: 0.4, ‘prizefights’: 0.3, ‘prizer’: 1.0, ‘prizers’: 0.8, ‘prizes’: 2.0, ‘prizewinner’: 2.3, ‘prizewinners’: 2.4, ‘prizewinning’: 3.0, ‘proactive’: 1.8, ‘problem’: -1.7, ‘problematic’: -1.9, ‘problematical’: -1.8, ‘problematically’: -2.0, ‘problematics’: -1.3, ‘problems’: -1.7, ‘profit’: 1.9, ‘profitabilities’: 1.1, ‘profitability’: 1.1, ‘profitable’: 1.9, ‘profitableness’: 2.4, ‘profitably’: 1.6, ‘profited’: 1.3, ‘profiteer’: 0.8, ‘profiteered’: -0.5, ‘profiteering’: -0.6, ‘profiteers’: 0.5, ‘profiter’: 0.7, ‘profiterole’: 0.4, ‘profiteroles’: 0.5, ‘profiting’: 1.6, ‘profitless’: -1.5, ‘profits’: 1.9, ‘profitwise’: 0.9, ‘progress’: 1.8, ‘prominent’: 1.3, ‘promiscuities’: -0.8, ‘promiscuity’: -1.8, ‘promiscuous’: -0.3, ‘promiscuously’: -1.5, ‘promiscuousness’: -0.9, ‘promise’: 1.3, ‘promised’: 1.5, ‘promisee’: 0.8, ‘promisees’: 1.1, ‘promiser’: 1.3, ‘promisers’: 1.6, ‘promises’: 1.6, ‘promising’: 1.7, ‘promisingly’: 1.2, ‘promisor’: 1.0, ‘promisors’: 0.4, ‘promissory’: 0.9, ‘promote’: 1.6, ‘promoted’: 1.8, ‘promotes’: 1.4, ‘promoting’: 1.5, ‘propaganda’: -1.0, ‘prosecute’: -1.7, ‘prosecuted’: -1.6, ‘prosecutes’: -1.8, ‘prosecution’: -2.2, ‘prospect’: 1.2, ‘prospects’: 1.2, ‘prosperous’: 2.1, ‘protect’: 1.6, ‘protected’: 1.9, ‘protects’: 1.3, ‘protest’: -1.0, ‘protested’: -0.5, ‘protesters’: -0.9, ‘protesting’: -1.8, ‘protests’: -0.9, ‘proud’: 2.1, ‘prouder’: 2.2, ‘proudest’: 2.6, ‘proudful’: 1.9, ‘proudhearted’: 1.4, ‘proudly’: 2.6, ‘provoke’: -1.7, ‘provoked’: -1.1, ‘provokes’: -1.3, ‘provoking’: -0.8, ‘pseudoscience’: -1.2, ‘puke’: -2.4, ‘puked’: -1.8, ‘pukes’: -1.9, ‘puking’: -1.8, ‘pukka’: 2.8, ‘punish’: -2.4, ‘punishabilities’: -1.7, ‘punishability’: -1.6, ‘punishable’: -1.9, ‘punished’: -2.0, ‘punisher’: -1.9, ‘punishers’: -2.6, ‘punishes’: -2.1, ‘punishing’: -2.6, ‘punishment’: -2.2, ‘punishments’: -1.8, ‘punitive’: -2.3, ‘pushy’: -1.1, ‘puzzled’: -0.7, ‘quaking’: -1.5, ‘questionable’: -1.2, ‘questioned’: -0.4, ‘questioning’: -0.4, ‘racism’: -3.1, ‘racist’: -3.0, ‘racists’: -2.5, ‘radian’: 0.4, ‘radiance’: 1.4, ‘radiances’: 1.1, ‘radiancies’: 0.8, ‘radiancy’: 1.4, ‘radians’: 0.2, ‘radiant’: 2.1, ‘radiantly’: 1.3, ‘radiants’: 1.2, ‘rage’: -2.6, ‘raged’: -2.0, ‘ragee’: -0.4, ‘rageful’: -2.8, ‘rages’: -2.1, ‘raging’: -2.4, ‘rainy’: -0.3, ‘rancid’: -2.5, ‘rancidity’: -2.6, ‘rancidly’: -2.5, ‘rancidness’: -2.6, ‘rancidnesses’: -1.6, ‘rant’: -1.4, ‘ranter’: -1.2, ‘ranters’: -1.2, ‘rants’: -1.3, ‘rape’: -3.7, ‘raped’: -3.6, ‘raper’: -3.4, ‘rapers’: -3.6, ‘rapes’: -3.5, ‘rapeseeds’: -0.5, ‘raping’: -3.8, ‘rapist’: -3.9, ‘rapists’: -3.3, ‘rapture’: 0.6, ‘raptured’: 0.9, ‘raptures’: 0.7, ‘rapturous’: 1.7, ‘rash’: -1.7, ‘ratified’: 0.6, ‘reach’: 0.1, ‘reached’: 0.4, ‘reaches’: 0.2, ‘reaching’: 0.8, ‘readiness’: 1.0, ‘ready’: 1.5, ‘reassurance’: 1.5, ‘reassurances’: 1.4, ‘reassure’: 1.4, ‘reassured’: 1.7, ‘reassures’: 1.5, ‘reassuring’: 1.7, ‘reassuringly’: 1.8, ‘rebel’: -0.6, ‘rebeldom’: -1.5, ‘rebelled’: -1.0, ‘rebelling’: -1.1, ‘rebellion’: -0.5, ‘rebellions’: -1.1, ‘rebellious’: -1.2, ‘rebelliously’: -1.8, ‘rebelliousness’: -1.2, ‘rebels’: -0.8, ‘recession’: -1.8, ‘reckless’: -1.7, ‘recommend’: 1.5, ‘recommended’: 0.8, ‘recommends’: 0.9, ‘redeemed’: 1.3, ‘reek’: -2.4, ‘reeked’: -2.0, ‘reeker’: -1.7, ‘reekers’: -1.5, ‘reeking’: -2.0, ‘refuse’: -1.2, ‘refused’: -1.2, ‘refusing’: -1.7, ‘regret’: -1.8, ‘regretful’: -1.9, ‘regretfully’: -1.9, ‘regretfulness’: -1.6, ‘regrets’: -1.5, ‘regrettable’: -2.3, ‘regrettably’: -2.0, ‘regretted’: -1.6, ‘regretter’: -1.6, ‘regretters’: -2.0, ‘regretting’: -1.7, ‘reinvigorate’: 2.3, ‘reinvigorated’: 1.9, ‘reinvigorates’: 1.8, ‘reinvigorating’: 1.7, ‘reinvigoration’: 2.2, ‘reject’: -1.7, ‘rejected’: -2.3, ‘rejectee’: -2.3, ‘rejectees’: -1.8, ‘rejecter’: -1.6, ‘rejecters’: -1.8, ‘rejecting’: -2.0, ‘rejectingly’: -1.7, ‘rejection’: -2.5, ‘rejections’: -2.1, ‘rejective’: -1.8, ‘rejector’: -1.8, ‘rejects’: -2.2, ‘rejoice’: 1.9, ‘rejoiced’: 2.0, ‘rejoices’: 2.1, ‘rejoicing’: 2.8, ‘relax’: 1.9, ‘relaxant’: 1.0, ‘relaxants’: 0.7, ‘relaxation’: 2.4, ‘relaxations’: 1.0, ‘relaxed’: 2.2, ‘relaxedly’: 1.5, ‘relaxedness’: 2.0, ‘relaxer’: 1.6, ‘relaxers’: 1.4, ‘relaxes’: 1.5, ‘relaxin’: 1.7, ‘relaxing’: 2.2, ‘relaxins’: 1.2, ‘relentless’: 0.2, ‘reliant’: 0.5, ‘relief’: 2.1, ‘reliefs’: 1.3, ‘relievable’: 1.1, ‘relieve’: 1.5, ‘relieved’: 1.6, ‘relievedly’: 1.4, ‘reliever’: 1.5, ‘relievers’: 1.0, ‘relieves’: 1.5, ‘relieving’: 1.5, ‘relievo’: 1.3, ‘relishing’: 1.6, ‘reluctance’: -1.4, ‘reluctancy’: -1.6, ‘reluctant’: -1.0, ‘reluctantly’: -0.4, ‘remarkable’: 2.6, ‘remorse’: -1.1, ‘remorseful’: -0.9, ‘remorsefully’: -0.7, ‘remorsefulness’: -0.7, ‘remorseless’: -2.3, ‘remorselessly’: -2.0, ‘remorselessness’: -2.8, ‘repetitive’: -1.0, ‘repress’: -1.4, ‘repressed’: -1.3, ‘represses’: -1.3, ‘repressible’: -1.5, ‘repressing’: -1.8, ‘repression’: -1.6, ‘repressions’: -1.7, ‘repressive’: -1.4, ‘repressively’: -1.7, ‘repressiveness’: -1.0, ‘repressor’: -1.4, ‘repressors’: -2.2, ‘repressurize’: -0.3, ‘repressurized’: 0.1, ‘repressurizes’: 0.1, ‘repressurizing’: -0.1, ‘repulse’: -2.8, ‘repulsed’: -2.2, ‘rescue’: 2.3, ‘rescued’: 1.8, ‘rescues’: 1.3, ‘resent’: -0.7, ‘resented’: -1.6, ‘resentence’: -1.0, ‘resentenced’: -0.8, ‘resentences’: -0.6, ‘resentencing’: 0.2, ‘resentful’: -2.1, ‘resentfully’: -1.4, ‘resentfulness’: -2.0, ‘resenting’: -1.2, ‘resentment’: -1.9, ‘resentments’: -1.9, ‘resents’: -1.2, ‘resign’: -1.4, ‘resignation’: -1.2, ‘resignations’: -1.2, ‘resigned’: -1.0, ‘resignedly’: -0.7, ‘resignedness’: -0.8, ‘resigner’: -1.2, ‘resigners’: -1.0, ‘resigning’: -0.9, ‘resigns’: -1.3, ‘resolute’: 1.1, ‘resolvable’: 1.0, ‘resolve’: 1.6, ‘resolved’: 0.7, ‘resolvent’: 0.7, ‘resolvents’: 0.4, ‘resolver’: 0.7, ‘resolvers’: 1.4, ‘resolves’: 0.7, ‘resolving’: 1.6, ‘respect’: 2.1, ‘respectabilities’: 1.8, ‘respectability’: 2.4, ‘respectable’: 1.9, ‘respectableness’: 1.2, ‘respectably’: 1.7, ‘respected’: 2.1, ‘respecter’: 2.1, ‘respecters’: 1.6, ‘respectful’: 2.0, ‘respectfully’: 1.7, ‘respectfulness’: 1.9, ‘respectfulnesses’: 1.3, ‘respecting’: 2.2, ‘respective’: 1.8, ‘respectively’: 1.4, ‘respectiveness’: 1.1, ‘respects’: 1.3, ‘responsible’: 1.3, ‘responsive’: 1.5, ‘restful’: 1.5, ‘restless’: -1.1, ‘restlessly’: -1.4, ‘restlessness’: -1.2, ‘restore’: 1.2, ‘restored’: 1.4, ‘restores’: 1.2, ‘restoring’: 1.2, ‘restrict’: -1.6, ‘restricted’: -1.6, ‘restricting’: -1.6, ‘restriction’: -1.1, ‘restricts’: -1.3, ‘retained’: 0.1, ‘retard’: -2.4, ‘retarded’: -2.7, ‘retreat’: 0.8, ‘revenge’: -2.4, ‘revenged’: -0.9, ‘revengeful’: -2.4, ‘revengefully’: -1.4, ‘revengefulness’: -2.2, ‘revenger’: -2.1, ‘revengers’: -2.0, ‘revenges’: -1.9, ‘revered’: 2.3, ‘revive’: 1.4, ‘revives’: 1.6, ‘reward’: 2.7, ‘rewardable’: 2.0, ‘rewarded’: 2.2, ‘rewarder’: 1.6, ‘rewarders’: 1.9, ‘rewarding’: 2.4, ‘rewardingly’: 2.4, ‘rewards’: 2.1, ‘rich’: 2.6, ‘richened’: 1.9, ‘richening’: 1.0, ‘richens’: 0.8, ‘richer’: 2.4, ‘riches’: 2.4, ‘richest’: 2.4, ‘richly’: 1.9, ‘richness’: 2.2, ‘richnesses’: 2.1, ‘richweed’: 0.1, ‘richweeds’: -0.1, ‘ridicule’: -2.0, ‘ridiculed’: -1.5, ‘ridiculer’: -1.6, ‘ridiculers’: -1.6, ‘ridicules’: -1.8, ‘ridiculing’: -1.8, ‘ridiculous’: -1.5, ‘ridiculously’: -1.4, ‘ridiculousness’: -1.1, ‘ridiculousnesses’: -1.6, ‘rig’: -0.5, ‘rigged’: -1.5, ‘rigid’: -0.5, ‘rigidification’: -1.1, ‘rigidifications’: -0.8, ‘rigidified’: -0.7, ‘rigidifies’: -0.6, ‘rigidify’: -0.3, ‘rigidities’: -0.7, ‘rigidity’: -0.7, ‘rigidly’: -0.7, ‘rigidness’: -0.3, ‘rigorous’: -1.1, ‘rigorously’: -0.4, ‘riot’: -2.6, ‘riots’: -2.3, ‘risk’: -1.1, ‘risked’: -0.9, ‘risker’: -0.8, ‘riskier’: -1.4, ‘riskiest’: -1.5, ‘riskily’: -0.7, ‘riskiness’: -1.3, ‘riskinesses’: -1.6, ‘risking’: -1.3, ‘riskless’: 1.3, ‘risks’: -1.1, ‘risky’: -0.8, ‘rob’: -2.6, ‘robber’: -2.6, ‘robed’: -0.7, ‘robing’: -1.5, ‘robs’: -2.0, ‘robust’: 1.4, ‘roflcopter’: 2.1, ‘romance’: 2.6, ‘romanced’: 2.2, ‘romancer’: 1.3, ‘romancers’: 1.7, ‘romances’: 1.3, ‘romancing’: 2.0, ‘romantic’: 1.7, ‘romantically’: 1.8, ‘romanticise’: 1.7, ‘romanticised’: 1.7, ‘romanticises’: 1.3, ‘romanticising’: 2.7, ‘romanticism’: 2.2, ‘romanticisms’: 2.1, ‘romanticist’: 1.9, ‘romanticists’: 1.3, ‘romanticization’: 1.5, ‘romanticizations’: 2.0, ‘romanticize’: 1.8, ‘romanticized’: 0.9, ‘romanticizes’: 1.8, ‘romanticizing’: 1.2, ‘romantics’: 1.9, ‘rotten’: -2.3, ‘rude’: -2.0, ‘rudely’: -2.2, ‘rudeness’: -1.5, ‘ruder’: -2.1, ‘ruderal’: -0.8, ‘ruderals’: -0.4, ‘rudesby’: -2.0, ‘rudest’: -2.5, ‘ruin’: -2.8, ‘ruinable’: -1.6, ‘ruinate’: -2.8, ‘ruinated’: -1.5, ‘ruinates’: -1.5, ‘ruinating’: -1.5, ‘ruination’: -2.7, ‘ruinations’: -1.6, ‘ruined’: -2.1, ‘ruiner’: -2.0, ‘ruing’: -1.6, ‘ruining’: -1.0, ‘ruinous’: -2.7, ‘ruinously’: -2.6, ‘ruinousness’: -1.0, ‘ruins’: -1.9, ‘sabotage’: -2.4, ‘sad’: -2.1, ‘sadden’: -2.6, ‘saddened’: -2.4, ‘saddening’: -2.2, ‘saddens’: -1.9, ‘sadder’: -2.4, ‘saddest’: -3.0, ‘sadly’: -1.8, ‘sadness’: -1.9, ‘safe’: 1.9, ‘safecracker’: -0.7, ‘safecrackers’: -0.9, ‘safecracking’: -0.9, ‘safecrackings’: -0.7, ‘safeguard’: 1.6, ‘safeguarded’: 1.5, ‘safeguarding’: 1.1, ‘safeguards’: 1.4, ‘safekeeping’: 1.4, ‘safelight’: 1.1, ‘safelights’: 0.8, ‘safely’: 2.2, ‘safeness’: 1.5, ‘safer’: 1.8, ‘safes’: 0.4, ‘safest’: 1.7, ‘safeties’: 1.5, ‘safety’: 1.8, ‘safetyman’: 0.3, ‘salient’: 1.1, ‘sappy’: -1.0, ‘sarcasm’: -0.9, ‘sarcasms’: -0.9, ‘sarcastic’: -1.0, ‘sarcastically’: -1.1, ‘satisfaction’: 1.9, ‘satisfactions’: 2.1, ‘satisfactorily’: 1.6, ‘satisfactoriness’: 1.5, ‘satisfactory’: 1.5, ‘satisfiable’: 1.9, ‘satisfied’: 1.8, ‘satisfies’: 1.8, ‘satisfy’: 2.0, ‘satisfying’: 2.0, ‘satisfyingly’: 1.9, ‘savage’: -2.0, ‘savaged’: -2.0, ‘savagely’: -2.2, ‘savageness’: -2.6, ‘savagenesses’: -0.9, ‘savageries’: -1.9, ‘savagery’: -2.5, ‘savages’: -2.4, ‘save’: 2.2, ‘saved’: 1.8, ‘scam’: -2.7, ‘scams’: -2.8, ‘scandal’: -1.9, ‘scandalous’: -2.4, ‘scandals’: -2.2, ‘scapegoat’: -1.7, ‘scapegoats’: -1.4, ‘scare’: -2.2, ‘scarecrow’: -0.8, ‘scarecrows’: -0.7, ‘scared’: -1.9, ‘scaremonger’: -2.1, ‘scaremongers’: -2.0, ‘scarer’: -1.7, ‘scarers’: -1.3, ‘scares’: -1.4, ‘scarey’: -1.7, ‘scaring’: -1.9, ‘scary’: -2.2, ‘sceptic’: -1.0, ‘sceptical’: -1.2, ‘scepticism’: -0.8, ‘sceptics’: -0.7, ‘scold’: -1.7, ‘scoop’: 0.6, ‘scorn’: -1.7, ‘scornful’: -1.8, ‘scream’: -1.7, ‘screamed’: -1.3, ‘screamers’: -1.5, ‘screaming’: -1.6, ‘screams’: -1.2, ‘screw’: -0.4, ‘screwball’: -0.2, ‘screwballs’: -0.3, ‘screwbean’: 0.3, ‘screwdriver’: 0.3, ‘screwdrivers’: 0.1, ‘screwed’: -2.2, ‘screwed up’: -1.5, ‘screwer’: -1.2, ‘screwers’: -0.5, ‘screwier’: -0.6, ‘screwiest’: -2.0, ‘screwiness’: -0.5, ‘screwing’: -0.9, ‘screwlike’: 0.1, ‘screws’: -1.0, ‘screwup’: -1.7, ‘screwups’: -1.0, ‘screwworm’: -0.4, ‘screwworms’: -0.1, ‘screwy’: -1.4, ‘scrumptious’: 2.1, ‘scrumptiously’: 1.5, ‘scumbag’: -3.2, ‘secure’: 1.4, ‘secured’: 1.7, ‘securely’: 1.4, ‘securement’: 1.1, ‘secureness’: 1.4, ‘securer’: 1.5, ‘securers’: 0.6, ‘secures’: 1.3, ‘securest’: 2.6, ‘securing’: 1.3, ‘securities’: 1.2, ‘securitization’: 0.2, ‘securitizations’: 0.1, ‘securitize’: 0.3, ‘securitized’: 1.4, ‘securitizes’: 1.6, ‘securitizing’: 0.7, ‘security’: 1.4, ‘sedition’: -1.8, ‘seditious’: -1.7, ‘seduced’: -1.5, ‘self-confident’: 2.5, ‘selfish’: -2.1, ‘selfishly’: -1.4, ‘selfishness’: -1.7, ‘selfishnesses’: -2.0, ‘sentence’: 0.3, ‘sentenced’: -0.1, ‘sentences’: 0.2, ‘sentencing’: -0.6, ‘sentimental’: 1.3, ‘sentimentalise’: 1.2, ‘sentimentalised’: 0.8, ‘sentimentalising’: 0.4, ‘sentimentalism’: 1.0, ‘sentimentalisms’: 0.4, ‘sentimentalist’: 0.8, ‘sentimentalists’: 0.7, ‘sentimentalities’: 0.9, ‘sentimentality’: 1.2, ‘sentimentalization’: 1.2, ‘sentimentalizations’: 0.4, ‘sentimentalize’: 0.8, ‘sentimentalized’: 1.1, ‘sentimentalizes’: 1.1, ‘sentimentalizing’: 0.8, ‘sentimentally’: 1.9, ‘serene’: 2.0, ‘serious’: -0.3, ‘seriously’: -0.7, ‘seriousness’: -0.2, ‘severe’: -1.6, ‘severed’: -1.5, ‘severely’: -2.0, ‘severeness’: -1.0, ‘severer’: -1.6, ‘severest’: -1.5, ‘sexy’: 2.4, ‘shake’: -0.7, ‘shakeable’: -0.3, ‘shakedown’: -1.2, ‘shakedowns’: -1.4, ‘shaken’: -0.3, ‘shakeout’: -1.3, ‘shakeouts’: -0.8, ‘shakers’: 0.3, ‘shakeup’: -0.6, ‘shakeups’: -0.5, ‘shakier’: -0.9, ‘shakiest’: -1.2, ‘shakily’: -0.7, ‘shakiness’: -0.7, ‘shaking’: -0.7, ‘shaky’: -0.9, ‘shame’: -2.1, ‘shamed’: -2.6, ‘shamefaced’: -2.3, ‘shamefacedly’: -1.9, ‘shamefacedness’: -2.0, ‘shamefast’: -1.0, ‘shameful’: -2.2, ‘shamefully’: -1.9, ‘shamefulness’: -2.4, ‘shamefulnesses’: -2.3, ‘shameless’: -1.4, ‘shamelessly’: -1.4, ‘shamelessness’: -1.4, ‘shamelessnesses’: -2.0, ‘shames’: -1.7, ‘share’: 1.2, ‘shared’: 1.4, ‘shares’: 1.2, ‘sharing’: 1.8, ‘shattered’: -2.1, ‘shit’: -2.6, ‘shitake’: -0.3, ‘shitakes’: -1.1, ‘shithead’: -3.1, ‘shitheads’: -2.6, ‘shits’: -2.1, ‘shittah’: 0.1, ‘shitted’: -1.7, ‘shittier’: -2.1, ‘shittiest’: -3.4, ‘shittim’: -0.6, ‘shittimwood’: -0.3, ‘shitting’: -1.8, ‘shitty’: -2.6, ‘shock’: -1.6, ‘shockable’: -1.0, ‘shocked’: -1.3, ‘shocker’: -0.6, ‘shockers’: -1.1, ‘shocking’: -1.7, ‘shockingly’: -0.7, ‘shockproof’: 1.3, ‘shocks’: -1.6, ‘shook’: -0.4, ‘shoot’: -1.4, ‘short-sighted’: -1.2, ‘short-sightedness’: -1.1, ‘shortage’: -1.0, ‘shortages’: -0.6, ‘shrew’: -0.9, ‘shy’: -1.0, ‘shyer’: -0.8, ‘shying’: -0.9, ‘shylock’: -2.1, ‘shylocked’: -0.7, ‘shylocking’: -1.5, ‘shylocks’: -1.4, ‘shyly’: -0.7, ‘shyness’: -1.3, ‘shynesses’: -1.2, ‘shyster’: -1.6, ‘shysters’: -0.9, ‘sick’: -2.3, ‘sicken’: -1.9, ‘sickened’: -2.5, ‘sickener’: -2.2, ‘sickeners’: -2.2, ‘sickening’: -2.4, ‘sickeningly’: -2.1, ‘sickens’: -2.0, ‘sigh’: 0.1, ‘significance’: 1.1, ‘significant’: 0.8, ‘silencing’: -0.5, ‘sillibub’: -0.1, ‘sillier’: 1.0, ‘sillies’: 0.8, ‘silliest’: 0.8, ‘sillily’: -0.1, ‘sillimanite’: 0.1, ‘sillimanites’: 0.2, ‘silliness’: -0.9, ‘sillinesses’: -1.2, ‘silly’: 0.1, ‘sin’: -2.6, ‘sincere’: 1.7, ‘sincerely’: 2.1, ‘sincereness’: 1.8, ‘sincerer’: 2.0, ‘sincerest’: 2.0, ‘sincerities’: 1.5, ‘sinful’: -2.6, ‘singleminded’: 1.2, ‘sinister’: -2.9, ‘sins’: -2.0, ‘skeptic’: -0.9, ‘skeptical’: -1.3, ‘skeptically’: -1.2, ‘skepticism’: -1.0, ‘skepticisms’: -1.2, ‘skeptics’: -0.4, ‘slam’: -1.6, ‘slash’: -1.1, ‘slashed’: -0.9, ‘slashes’: -0.8, ‘slashing’: -1.1, ‘slavery’: -3.8, ‘sleeplessness’: -1.6, ‘slicker’: 0.4, ‘slickest’: 0.3, ‘sluggish’: -1.7, ‘slut’: -2.8, ‘sluts’: -2.7, ‘sluttier’: -2.7, ‘sluttiest’: -3.1, ‘sluttish’: -2.2, ‘sluttishly’: -2.1, ‘sluttishness’: -2.5, ‘sluttishnesses’: -2.0, ‘slutty’: -2.3, ‘smart’: 1.7, ‘smartass’: -2.1, ‘smartasses’: -1.7, ‘smarted’: 0.7, ‘smarten’: 1.9, ‘smartened’: 1.5, ‘smartening’: 1.7, ‘smartens’: 1.5, ‘smarter’: 2.0, ‘smartest’: 3.0, ‘smartie’: 1.3, ‘smarties’: 1.7, ‘smarting’: -0.7, ‘smartly’: 1.5, ‘smartness’: 2.0, ‘smartnesses’: 1.5, ‘smarts’: 1.6, ‘smartweed’: 0.2, ‘smartweeds’: 0.1, ‘smarty’: 1.1, ‘smear’: -1.5, ‘smilax’: 0.6, ‘smilaxes’: 0.3, ‘smile’: 1.5, ‘smiled’: 2.5, ‘smileless’: -1.4, ‘smiler’: 1.7, ‘smiles’: 2.1, ‘smiley’: 1.7, ‘smileys’: 1.5, ‘smiling’: 2.0, ‘smilingly’: 2.3, ‘smog’: -1.2, ‘smother’: -1.8, ‘smothered’: -0.9, ‘smothering’: -1.4, ‘smothers’: -1.9, ‘smothery’: -1.1, ‘smug’: 0.8, ‘smugger’: -1.0, ‘smuggest’: -1.5, ‘smuggle’: -1.6, ‘smuggled’: -1.5, ‘smuggler’: -2.1, ‘smugglers’: -1.4, ‘smuggles’: -1.7, ‘smuggling’: -2.1, ‘smugly’: 0.2, ‘smugness’: -1.4, ‘smugnesses’: -1.7, ‘sneaky’: -0.9, ‘snob’: -2.0, ‘snobbery’: -2.0, ‘snobbier’: -0.7, ‘snobbiest’: -0.5, ‘snobbily’: -1.6, ‘snobbish’: -0.9, ‘snobbishly’: -1.2, ‘snobbishness’: -1.1, ‘snobbishnesses’: -1.7, ‘snobbism’: -1.0, ‘snobbisms’: -0.3, ‘snobby’: -1.7, ‘snobs’: -1.4, ‘snub’: -1.8, ‘snubbed’: -2.0, ‘snubbing’: -0.9, ‘snubs’: -2.1, ‘sobbed’: -1.9, ‘sobbing’: -1.6, ‘sobering’: -0.8, ‘sobs’: -2.5, ‘sociabilities’: 1.2, ‘sociability’: 1.1, ‘sociable’: 1.9, ‘sociableness’: 1.5, ‘sociably’: 1.6, ‘sok’: 1.3, ‘solemn’: -0.3, ‘solemnified’: -0.5, ‘solemnifies’: -0.5, ‘solemnify’: 0.3, ‘solemnifying’: 0.1, ‘solemnities’: 0.3, ‘solemnity’: -1.1, ‘solemnization’: 0.7, ‘solemnize’: 0.3, ‘solemnized’: -0.7, ‘solemnizes’: 0.6, ‘solemnizing’: -0.6, ‘solemnly’: 0.8, ‘solid’: 0.6, ‘solidarity’: 1.2, ‘solution’: 1.3, ‘solutions’: 0.7, ‘solve’: 0.8, ‘solved’: 1.1, ‘solves’: 1.1, ‘solving’: 1.4, ‘somber’: -1.8, ‘son-of-a-bitch’: -2.7, ‘soothe’: 1.5, ‘soothed’: 0.5, ‘soothing’: 1.3, ‘sophisticated’: 2.6, ‘sore’: -1.5, ‘sorrow’: -2.4, ‘sorrowed’: -2.4, ‘sorrower’: -2.3, ‘sorrowful’: -2.2, ‘sorrowfully’: -2.3, ‘sorrowfulness’: -2.5, ‘sorrowing’: -1.7, ‘sorrows’: -1.6, ‘sorry’: -0.3, ‘soulmate’: 2.9, ‘spam’: -1.5, ‘spammer’: -2.2, ‘spammers’: -1.6, ‘spamming’: -2.1, ‘spark’: 0.9, ‘sparkle’: 1.8, ‘sparkles’: 1.3, ‘sparkling’: 1.2, ‘special’: 1.7, ‘speculative’: 0.4, ‘spirit’: 0.7, ‘spirited’: 1.3, ‘spiritless’: -1.3, ‘spite’: -2.4, ‘spited’: -2.4, ‘spiteful’: -1.9, ‘spitefully’: -2.3, ‘spitefulness’: -1.5, ‘spitefulnesses’: -2.3, ‘spites’: -1.4, ‘splendent’: 2.7, ‘splendid’: 2.8, ‘splendidly’: 2.1, ‘splendidness’: 2.3, ‘splendiferous’: 2.6, ‘splendiferously’: 1.9, ‘splendiferousness’: 1.7, ‘splendor’: 3.0, ‘splendorous’: 2.2, ‘splendors’: 2.0, ‘splendour’: 2.2, ‘splendours’: 2.2, ‘splendrous’: 2.2, ‘sprightly’: 2.0, ‘squelched’: -1.0, ‘stab’: -2.8, ‘stabbed’: -1.9, ‘stable’: 1.2, ‘stabs’: -1.9, ‘stall’: -0.8, ‘stalled’: -0.8, ‘stalling’: -0.8, ‘stamina’: 1.2, ‘stammer’: -0.9, ‘stammered’: -0.9, ‘stammerer’: -1.1, ‘stammerers’: -0.8, ‘stammering’: -1.0, ‘stammers’: -0.8, ‘stampede’: -1.8, ‘stank’: -1.9, ‘startle’: -1.3, ‘startled’: -0.7, ‘startlement’: -0.5, ‘startlements’: 0.2, ‘startler’: -0.8, ‘startlers’: -0.5, ‘startles’: -0.5, ‘startling’: 0.3, ‘startlingly’: -0.3, ‘starve’: -1.9, ‘starved’: -2.6, ‘starves’: -2.3, ‘starving’: -1.8, ‘steadfast’: 1.0, ‘steal’: -2.2, ‘stealable’: -1.7, ‘stealer’: -1.7, ‘stealers’: -2.2, ‘stealing’: -2.7, ‘stealings’: -1.9, ‘steals’: -2.3, ‘stealth’: -0.3, ‘stealthier’: -0.3, ‘stealthiest’: 0.4, ‘stealthily’: 0.1, ‘stealthiness’: 0.2, ‘stealths’: -0.3, ‘stealthy’: -0.1, ‘stench’: -2.3, ‘stenches’: -1.5, ‘stenchful’: -2.4, ‘stenchy’: -2.3, ‘stereotype’: -1.3, ‘stereotyped’: -1.2, ‘stifled’: -1.4, ‘stimulate’: 0.9, ‘stimulated’: 0.9, ‘stimulates’: 1.0, ‘stimulating’: 1.9, ‘stingy’: -1.6, ‘stink’: -1.7, ‘stinkard’: -2.3, ‘stinkards’: -1.0, ‘stinkbug’: -0.2, ‘stinkbugs’: -1.0, ‘stinker’: -1.5, ‘stinkers’: -1.2, ‘stinkhorn’: -0.2, ‘stinkhorns’: -0.8, ‘stinkier’: -1.5, ‘stinkiest’: -2.1, ‘stinking’: -2.4, ‘stinkingly’: -1.3, ‘stinko’: -1.5, ‘stinkpot’: -2.5, ‘stinkpots’: -0.7, ‘stinks’: -1.0, ‘stinkweed’: -0.4, ‘stinkwood’: -0.1, ‘stinky’: -1.5, ‘stolen’: -2.2, ‘stop’: -1.2, ‘stopped’: -0.9, ‘stopping’: -0.6, ‘stops’: -0.6, ‘stout’: 0.7, ‘straight’: 0.9, ‘strain’: -0.2, ‘strained’: -1.7, ‘strainer’: -0.8, ‘strainers’: -0.3, ‘straining’: -1.3, ‘strains’: -1.2, ‘strange’: -0.8, ‘strangely’: -1.2, ‘strangled’: -2.5, ‘strength’: 2.2, ‘strengthen’: 1.3, ‘strengthened’: 1.8, ‘strengthener’: 1.8, ‘strengtheners’: 1.4, ‘strengthening’: 2.2, ‘strengthens’: 2.0, ‘strengths’: 1.7, ‘stress’: -1.8, ‘stressed’: -1.4, ‘stresses’: -2.0, ‘stressful’: -2.3, ‘stressfully’: -2.6, ‘stressing’: -1.5, ‘stressless’: 1.6, ‘stresslessness’: 1.6, ‘stressor’: -1.8, ‘stressors’: -2.1, ‘stricken’: -2.3, ‘strike’: -0.5, ‘strikers’: -0.6, ‘strikes’: -1.5, ‘strong’: 2.3, ‘strongbox’: 0.7, ‘strongboxes’: 0.3, ‘stronger’: 1.6, ‘strongest’: 1.9, ‘stronghold’: 0.5, ‘strongholds’: 1.0, ‘strongish’: 1.7, ‘strongly’: 1.1, ‘strongman’: 0.7, ‘strongmen’: 0.5, ‘strongyl’: 0.6, ‘strongyles’: 0.2, ‘strongyloidosis’: -0.8, ‘strongyls’: 0.1, ‘struck’: -1.0, ‘struggle’: -1.3, ‘struggled’: -1.4, ‘struggler’: -1.1, ‘strugglers’: -1.4, ‘struggles’: -1.5, ‘struggling’: -1.8, ‘stubborn’: -1.7, ‘stubborner’: -1.5, ‘stubbornest’: -0.6, ‘stubbornly’: -1.4, ‘stubbornness’: -1.1, ‘stubbornnesses’: -1.5, ‘stuck’: -1.0, ‘stunk’: -1.6, ‘stunned’: -0.4, ‘stunning’: 1.6, ‘stuns’: 0.1, ‘stupid’: -2.4, ‘stupider’: -2.5, ‘stupidest’: -2.4, ‘stupidities’: -2.0, ‘stupidity’: -1.9, ‘stupidly’: -2.0, ‘stupidness’: -1.7, ‘stupidnesses’: -2.6, ‘stupids’: -2.3, ‘stutter’: -1.0, ‘stuttered’: -0.9, ‘stutterer’: -1.0, ‘stutterers’: -1.1, ‘stuttering’: -1.3, ‘stutters’: -1.0, ‘suave’: 2.0, ‘submissive’: -1.3, ‘submissively’: -1.0, ‘submissiveness’: -0.7, ‘substantial’: 0.8, ‘subversive’: -0.9, ‘succeed’: 2.2, ‘succeeded’: 1.8, ‘succeeder’: 1.2, ‘succeeders’: 1.3, ‘succeeding’: 2.2, ‘succeeds’: 2.2, ‘success’: 2.7, ‘successes’: 2.6, ‘successful’: 2.8, ‘successfully’: 2.2, ‘successfulness’: 2.7, ‘succession’: 0.8, ‘successional’: 0.9, ‘successionally’: 1.1, ‘successions’: 0.1, ‘successive’: 1.1, ‘successively’: 0.9, ‘successiveness’: 1.0, ‘successor’: 0.9, ‘successors’: 1.1, ‘suck’: -1.9, ‘sucked’: -2.0, ‘sucker’: -2.4, ‘suckered’: -2.0, ‘suckering’: -2.1, ‘suckers’: -2.3, ‘sucks’: -1.5, ‘sucky’: -1.9, ‘suffer’: -2.5, ‘suffered’: -2.2, ‘sufferer’: -2.0, ‘sufferers’: -2.4, ‘suffering’: -2.1, ‘suffers’: -2.1, ‘suicidal’: -3.5, ‘suicide’: -3.5, ‘suing’: -1.1, ‘sulking’: -1.5, ‘sulky’: -0.8, ‘sullen’: -1.7, ‘sunnier’: 2.3, ‘sunniest’: 2.4, ‘sunny’: 1.8, ‘sunshine’: 2.2, ‘sunshiny’: 1.9, ‘super’: 2.9, ‘superb’: 3.1, ‘superior’: 2.5, ‘superiorities’: 0.8, ‘superiority’: 1.4, ‘superiorly’: 2.2, ‘superiors’: 1.0, ‘support’: 1.7, ‘supported’: 1.3, ‘supporter’: 1.1, ‘supporters’: 1.9, ‘supporting’: 1.9, ‘supportive’: 1.2, ‘supportiveness’: 1.5, ‘supports’: 1.5, ‘supremacies’: 0.8, ‘supremacist’: 0.5, ‘supremacists’: -1.0, ‘supremacy’: 0.2, ‘suprematists’: 0.4, ‘supreme’: 2.6, ‘supremely’: 2.7, ‘supremeness’: 2.3, ‘supremer’: 2.3, ‘supremest’: 2.2, ‘supremo’: 1.9, ‘supremos’: 1.3, ‘sure’: 1.3, ‘surefire’: 1.0, ‘surefooted’: 1.9, ‘surefootedly’: 1.6, ‘surefootedness’: 1.5, ‘surely’: 1.9, ‘sureness’: 2.0, ‘surer’: 1.2, ‘surest’: 1.3, ‘sureties’: 1.3, ‘surety’: 1.0, ‘suretyship’: -0.1, ‘suretyships’: 0.4, ‘surprisal’: 1.5, ‘surprisals’: 0.7, ‘surprise’: 1.1, ‘surprised’: 0.9, ‘surpriser’: 0.6, ‘surprisers’: 0.3, ‘surprises’: 0.9, ‘surprising’: 1.1, ‘surprisingly’: 1.2, ‘survived’: 2.3, ‘surviving’: 1.2, ‘survivor’: 1.5, ‘suspect’: -1.2, ‘suspected’: -0.9, ‘suspecting’: -0.7, ‘suspects’: -1.4, ‘suspend’: -1.3, ‘suspended’: -2.1, ‘suspicion’: -1.6, ‘suspicions’: -1.5, ‘suspicious’: -1.5, ‘suspiciously’: -1.7, ‘suspiciousness’: -1.2, ‘sux’: -1.5, ‘swear’: -0.2, ‘swearing’: -1.0, ‘swears’: 0.2, ‘sweet’: 2.0, ‘sweet&lt;3’: 3.0, ‘sweetheart’: 3.3, ‘sweethearts’: 2.8, ‘sweetie’: 2.2, ‘sweeties’: 2.1, ‘sweetly’: 2.1, ‘sweetness’: 2.2, ‘sweets’: 2.2, ‘swift’: 0.8, ‘swiftly’: 1.2, ‘swindle’: -2.4, ‘swindles’: -1.5, ‘swindling’: -2.0, ‘sympathetic’: 2.3, ‘sympathy’: 1.5, ‘talent’: 1.8, ‘talented’: 2.3, ‘talentless’: -1.6, ‘talents’: 2.0, ‘tantrum’: -1.8, ‘tantrums’: -1.5, ‘tard’: -2.5, ‘tears’: -0.9, ‘teas’: 0.3, ‘tease’: -1.3, ‘teased’: -1.2, ‘teasel’: -0.1, ‘teaseled’: -0.8, ‘teaseler’: -0.8, ‘teaselers’: -1.2, ‘teaseling’: -0.4, ‘teaselled’: -0.4, ‘teaselling’: -0.2, ‘teasels’: -0.1, ‘teaser’: -1.0, ‘teasers’: -0.7, ‘teases’: -1.2, ‘teashops’: 0.2, ‘teasing’: -0.3, ‘teasingly’: -0.4, ‘teaspoon’: 0.2, ‘teaspoonful’: 0.2, ‘teaspoonfuls’: 0.4, ‘teaspoons’: 0.5, ‘teaspoonsful’: 0.3, ‘temper’: -1.8, ‘tempers’: -1.3, ‘tendered’: 0.5, ‘tenderer’: 0.6, ‘tenderers’: 1.2, ‘tenderest’: 1.4, ‘tenderfeet’: -0.4, ‘tenderfoot’: -0.1, ‘tenderfoots’: -0.5, ‘tenderhearted’: 1.5, ‘tenderheartedly’: 2.7, ‘tenderheartedness’: 0.7, ‘tenderheartednesses’: 2.8, ‘tendering’: 0.6, ‘tenderization’: 0.2, ‘tenderize’: 0.1, ‘tenderized’: 0.1, ‘tenderizer’: 0.4, ‘tenderizes’: 0.3, ‘tenderizing’: 0.3, ‘tenderloin’: -0.2, ‘tenderloins’: 0.4, ‘tenderly’: 1.8, ‘tenderness’: 1.8, ‘tendernesses’: 0.9, ‘tenderometer’: 0.2, ‘tenderometers’: 0.2, ‘tenders’: 0.6, ‘tense’: -1.4, ‘tensed’: -1.0, ‘tensely’: -1.2, ‘tenseness’: -1.5, ‘tenser’: -1.5, ‘tenses’: -0.9, ‘tensest’: -1.2, ‘tensing’: -1.0, ‘tension’: -1.3, ‘tensional’: -0.8, ‘tensioned’: -0.4, ‘tensioner’: -1.6, ‘tensioners’: -0.9, ‘tensioning’: -1.4, ‘tensionless’: 0.6, ‘tensions’: -1.7, ‘terrible’: -2.1, ‘terribleness’: -1.9, ‘terriblenesses’: -2.6, ‘terribly’: -2.6, ‘terrific’: 2.1, ‘terrifically’: 1.7, ‘terrified’: -3.0, ‘terrifies’: -2.6, ‘terrify’: -2.3, ‘terrifying’: -2.7, ‘terror’: -2.4, ‘terrorise’: -3.1, ‘terrorised’: -3.3, ‘terrorises’: -3.3, ‘terrorising’: -3.0, ‘terrorism’: -3.6, ‘terrorisms’: -3.2, ‘terrorist’: -3.7, ‘terroristic’: -3.3, ‘terrorists’: -3.1, ‘terrorization’: -2.7, ‘terrorize’: -3.3, ‘terrorized’: -3.1, ‘terrorizes’: -3.1, ‘terrorizing’: -3.0, ‘terrorless’: 0.9, ‘terrors’: -2.6, ‘thank’: 1.5, ‘thanked’: 1.9, ‘thankful’: 2.7, ‘thankfuller’: 1.9, ‘thankfullest’: 2.0, ‘thankfully’: 1.8, ‘thankfulness’: 2.1, ‘thanks’: 1.9, ‘thief’: -2.4, ‘thieve’: -2.2, ‘thieved’: -1.4, ‘thieveries’: -2.1, ‘thievery’: -2.0, ‘thieves’: -2.3, ‘thorny’: -1.1, ‘thoughtful’: 1.6, ‘thoughtfully’: 1.7, ‘thoughtfulness’: 1.9, ‘thoughtless’: -2.0, ‘threat’: -2.4, ‘threaten’: -1.6, ‘threatened’: -2.0, ‘threatener’: -1.4, ‘threateners’: -1.8, ‘threatening’: -2.4, ‘threateningly’: -2.2, ‘threatens’: -1.6, ‘threating’: -2.0, ‘threats’: -1.8, ‘thrill’: 1.5, ‘thrilled’: 1.9, ‘thriller’: 0.4, ‘thrillers’: 0.1, ‘thrilling’: 2.1, ‘thrillingly’: 2.0, ‘thrills’: 1.5, ‘thwarted’: -0.1, ‘thwarting’: -0.7, ‘thwarts’: -0.4, ‘ticked’: -1.8, ‘timid’: -1.0, ‘timider’: -1.0, ‘timidest’: -0.9, ‘timidities’: -0.7, ‘timidity’: -1.3, ‘timidly’: -0.7, ‘timidness’: -1.0, ‘timorous’: -0.8, ‘tired’: -1.9, ‘tits’: -0.9, ‘tolerance’: 1.2, ‘tolerances’: 0.3, ‘tolerant’: 1.1, ‘tolerantly’: 0.4, ‘toothless’: -1.4, ‘top’: 0.8, ‘tops’: 2.3, ‘torn’: -1.0, ‘torture’: -2.9, ‘tortured’: -2.6, ‘torturer’: -2.3, ‘torturers’: -3.5, ‘tortures’: -2.5, ‘torturing’: -3.0, ‘torturous’: -2.7, ‘torturously’: -2.2, ‘totalitarian’: -2.1, ‘totalitarianism’: -2.7, ‘tough’: -0.5, ‘toughed’: 0.7, ‘toughen’: 0.1, ‘toughened’: 0.1, ‘toughening’: 0.9, ‘toughens’: -0.2, ‘tougher’: 0.7, ‘toughest’: -0.3, ‘toughie’: -0.7, ‘toughies’: -0.6, ‘toughing’: -0.5, ‘toughish’: -1.0, ‘toughly’: -1.1, ‘toughness’: -0.2, ‘toughnesses’: 0.3, ‘toughs’: -0.8, ‘toughy’: -0.5, ‘tout’: -0.5, ‘touted’: -0.2, ‘touting’: -0.7, ‘touts’: -0.1, ‘tragedian’: -0.5, ‘tragedians’: -1.0, ‘tragedienne’: -0.4, ‘tragediennes’: -1.4, ‘tragedies’: -1.9, ‘tragedy’: -3.4, ‘tragic’: -2.0, ‘tragical’: -2.4, ‘tragically’: -2.7, ‘tragicomedy’: 0.2, ‘tragicomic’: -0.2, ‘tragics’: -2.2, ‘tranquil’: 0.2, ‘tranquiler’: 1.9, ‘tranquilest’: 1.6, ‘tranquilities’: 1.5, ‘tranquility’: 1.8, ‘tranquilize’: 0.3, ‘tranquilized’: -0.2, ‘tranquilizer’: -0.1, ‘tranquilizers’: -0.4, ‘tranquilizes’: -0.1, ‘tranquilizing’: -0.5, ‘tranquillest’: 0.8, ‘tranquillities’: 0.5, ‘tranquillity’: 1.8, ‘tranquillized’: -0.2, ‘tranquillizer’: -0.1, ‘tranquillizers’: -0.2, ‘tranquillizes’: 0.1, ‘tranquillizing’: 0.8, ‘tranquilly’: 1.2, ‘tranquilness’: 1.5, ‘trap’: -1.3, ‘trapped’: -2.4, ‘trauma’: -1.8, ‘traumas’: -2.2, ‘traumata’: -1.7, ‘traumatic’: -2.7, ‘traumatically’: -2.8, ‘traumatise’: -2.8, ‘traumatised’: -2.4, ‘traumatises’: -2.2, ‘traumatising’: -1.9, ‘traumatism’: -2.4, ‘traumatization’: -3.0, ‘traumatizations’: -2.2, ‘traumatize’: -2.4, ‘traumatized’: -1.7, ‘traumatizes’: -1.4, ‘traumatizing’: -2.3, ‘travesty’: -2.7, ‘treason’: -1.9, ‘treasonous’: -2.7, ‘treasurable’: 2.5, ‘treasure’: 1.2, ‘treasured’: 2.6, ‘treasurer’: 0.5, ‘treasurers’: 0.4, ‘treasurership’: 0.4, ‘treasurerships’: 1.2, ‘treasures’: 1.8, ‘treasuries’: 0.9, ‘treasuring’: 2.1, ‘treasury’: 0.8, ‘treat’: 1.7, ‘tremble’: -1.1, ‘trembled’: -1.1, ‘trembler’: -0.6, ‘tremblers’: -1.0, ‘trembles’: -0.1, ‘trembling’: -1.5, ‘trembly’: -1.2, ‘tremulous’: -1.0, ‘trick’: -0.2, ‘tricked’: -0.6, ‘tricker’: -0.9, ‘trickeries’: -1.2, ‘trickers’: -1.4, ‘trickery’: -1.1, ‘trickie’: -0.4, ‘trickier’: -0.7, ‘trickiest’: -1.2, ‘trickily’: -0.8, ‘trickiness’: -1.2, ‘trickinesses’: -0.4, ‘tricking’: 0.1, ‘trickish’: -1.0, ‘trickishly’: -0.7, ‘trickishness’: -0.4, ‘trickled’: 0.1, ‘trickledown’: -0.7, ‘trickles’: 0.2, ‘trickling’: -0.2, ‘trickly’: -0.3, ‘tricks’: -0.5, ‘tricksier’: -0.5, ‘tricksiness’: -1.0, ‘trickster’: -0.9, ‘tricksters’: -1.3, ‘tricksy’: -0.8, ‘tricky’: -0.6, ‘trite’: -0.8, ‘triumph’: 2.1, ‘triumphal’: 2.0, ‘triumphalisms’: 1.9, ‘triumphalist’: 0.5, ‘triumphalists’: 0.9, ‘triumphant’: 2.4, ‘triumphantly’: 2.3, ‘triumphed’: 2.2, ‘triumphing’: 2.3, ‘triumphs’: 2.0, ‘trivial’: -0.1, ‘trivialise’: -0.8, ‘trivialised’: -0.8, ‘trivialises’: -1.1, ‘trivialising’: -1.4, ‘trivialities’: -1.0, ‘triviality’: -0.5, ‘trivialization’: -0.9, ‘trivializations’: -0.7, ‘trivialize’: -1.1, ‘trivialized’: -0.6, ‘trivializes’: -1.0, ‘trivializing’: -0.6, ‘trivially’: 0.4, ‘trivium’: -0.3, ‘trouble’: -1.7, ‘troubled’: -2.0, ‘troublemaker’: -2.0, ‘troublemakers’: -2.2, ‘troublemaking’: -1.8, ‘troubler’: -1.4, ‘troublers’: -1.9, ‘troubles’: -2.0, ‘troubleshoot’: 0.8, ‘troubleshooter’: 1.0, ‘troubleshooters’: 0.8, ‘troubleshooting’: 0.7, ‘troubleshoots’: 0.5, ‘troublesome’: -2.3, ‘troublesomely’: -1.8, ‘troublesomeness’: -1.9, ‘troubling’: -2.5, ‘troublous’: -2.1, ‘troublously’: -2.1, ‘trueness’: 2.1, ‘truer’: 1.5, ‘truest’: 1.9, ‘truly’: 1.9, ‘trust’: 2.3, ‘trustability’: 2.1, ‘trustable’: 2.3, ‘trustbuster’: -0.5, ‘trusted’: 2.1, ‘trustee’: 1.0, ‘trustees’: 0.3, ‘trusteeship’: 0.5, ‘trusteeships’: 0.6, ‘truster’: 1.9, ‘trustful’: 2.1, ‘trustfully’: 1.5, ‘trustfulness’: 2.1, ‘trustier’: 1.3, ‘trusties’: 1.0, ‘trustiest’: 2.2, ‘trustily’: 1.6, ‘trustiness’: 1.6, ‘trusting’: 1.7, ‘trustingly’: 1.6, ‘trustingness’: 1.6, ‘trustless’: -2.3, ‘trustor’: 0.4, ‘trustors’: 1.2, ‘trusts’: 2.1, ‘trustworthily’: 2.3, ‘trustworthiness’: 1.8, ‘trustworthy’: 2.6, ‘trusty’: 2.2, ‘truth’: 1.3, ‘truthful’: 2.0, ‘truthfully’: 1.9, ‘truthfulness’: 1.7, ‘truths’: 1.8, ‘tumor’: -1.6, ‘turmoil’: -1.5, ‘twat’: -3.4, ‘ugh’: -1.8, ‘uglier’: -2.2, ‘uglies’: -2.0, ‘ugliest’: -2.8, ‘uglification’: -2.2, ‘uglified’: -1.5, ‘uglifies’: -1.8, ‘uglify’: -2.1, ‘uglifying’: -2.2, ‘uglily’: -2.1, ‘ugliness’: -2.7, ‘uglinesses’: -2.5, ‘ugly’: -2.3, ‘unacceptable’: -2.0, ‘unappreciated’: -1.7, ‘unapproved’: -1.4, ‘unattractive’: -1.9, ‘unaware’: -0.8, ‘unbelievable’: 0.8, ‘unbelieving’: -0.8, ‘unbiased’: -0.1, ‘uncertain’: -1.2, ‘uncertainly’: -1.4, ‘uncertainness’: -1.3, ‘uncertainties’: -1.4, ‘uncertainty’: -1.4, ‘unclear’: -1.0, ‘uncomfortable’: -1.6, ‘uncomfortably’: -1.7, ‘uncompelling’: -0.9, ‘unconcerned’: -0.9, ‘unconfirmed’: -0.5, ‘uncontrollability’: -1.7, ‘uncontrollable’: -1.5, ‘uncontrollably’: -1.5, ‘uncontrolled’: -1.0, ‘unconvinced’: -1.6, ‘uncredited’: -1.0, ‘undecided’: -0.9, ‘underestimate’: -1.2, ‘underestimated’: -1.1, ‘underestimates’: -1.1, ‘undermine’: -1.2, ‘undermined’: -1.5, ‘undermines’: -1.4, ‘undermining’: -1.5, ‘undeserving’: -1.9, ‘undesirable’: -1.9, ‘unease’: -1.7, ‘uneasier’: -1.4, ‘uneasiest’: -2.1, ‘uneasily’: -1.4, ‘uneasiness’: -1.6, ‘uneasinesses’: -1.8, ‘uneasy’: -1.6, ‘unemployment’: -1.9, ‘unequal’: -1.4, ‘unequaled’: 0.5, ‘unethical’: -2.3, ‘unfair’: -2.1, ‘unfocused’: -1.7, ‘unfortunate’: -2.0, ‘unfortunately’: -1.4, ‘unfortunates’: -1.9, ‘unfriendly’: -1.5, ‘unfulfilled’: -1.8, ‘ungrateful’: -2.0, ‘ungratefully’: -1.8, ‘ungratefulness’: -1.6, ‘unhappier’: -2.4, ‘unhappiest’: -2.5, ‘unhappily’: -1.9, ‘unhappiness’: -2.4, ‘unhappinesses’: -2.2, ‘unhappy’: -1.8, ‘unhealthy’: -2.4, ‘unified’: 1.6, ‘unimportant’: -1.3, ‘unimpressed’: -1.4, ‘unimpressive’: -1.4, ‘unintelligent’: -2.0, ‘uninvolved’: -2.2, ‘uninvolving’: -2.0, ‘united’: 1.8, ‘unjust’: -2.3, ‘unkind’: -1.6, ‘unlovable’: -2.7, ‘unloved’: -1.9, ‘unlovelier’: -1.9, ‘unloveliest’: -1.9, ‘unloveliness’: -2.0, ‘unlovely’: -2.1, ‘unloving’: -2.3, ‘unmatched’: -0.3, ‘unmotivated’: -1.4, ‘unpleasant’: -2.1, ‘unprofessional’: -2.3, ‘unprotected’: -1.5, ‘unresearched’: -1.1, ‘unsatisfied’: -1.7, ‘unsavory’: -1.9, ‘unsecured’: -1.6, ‘unsettled’: -1.3, ‘unsophisticated’: -1.2, ‘unstable’: -1.5, ‘unstoppable’: -0.8, ‘unsuccessful’: -1.5, ‘unsuccessfully’: -1.7, ‘unsupported’: -1.7, ‘unsure’: -1.0, ‘unsurely’: -1.3, ‘untarnished’: 1.6, ‘unwanted’: -0.9, ‘unwelcome’: -1.7, ‘unworthy’: -2.0, ‘upset’: -1.6, ‘upsets’: -1.5, ‘upsetter’: -1.9, ‘upsetters’: -2.0, ‘upsetting’: -2.1, ‘uptight’: -1.6, ‘uptightness’: -1.2, ‘urgent’: 0.8, ‘useful’: 1.9, ‘usefully’: 1.8, ‘usefulness’: 1.2, ‘useless’: -1.8, ‘uselessly’: -1.5, ‘uselessness’: -1.6, ‘v.v’: -2.9, ‘vague’: -0.4, ‘vain’: -1.8, ‘validate’: 1.5, ‘validated’: 0.9, ‘validates’: 1.4, ‘validating’: 1.4, ‘valuable’: 2.1, ‘valuableness’: 1.7, ‘valuables’: 2.1, ‘valuably’: 2.3, ‘value’: 1.4, ‘valued’: 1.9, ‘values’: 1.7, ‘valuing’: 1.4, ‘vanity’: -0.9, ‘verdict’: 0.6, ‘verdicts’: 0.3, ‘vested’: 0.6, ‘vexation’: -1.9, ‘vexing’: -2.0, ‘vibrant’: 2.4, ‘vicious’: -1.5, ‘viciously’: -1.3, ‘viciousness’: -2.4, ‘viciousnesses’: -0.6, ‘victim’: -1.1, ‘victimhood’: -2.0, ‘victimhoods’: -0.9, ‘victimise’: -1.1, ‘victimised’: -1.5, ‘victimises’: -1.2, ‘victimising’: -2.5, ‘victimization’: -2.3, ‘victimizations’: -1.5, ‘victimize’: -2.5, ‘victimized’: -1.8, ‘victimizer’: -1.8, ‘victimizers’: -1.6, ‘victimizes’: -1.5, ‘victimizing’: -2.6, ‘victimless’: 0.6, ‘victimologies’: -0.6, ‘victimologist’: -0.5, ‘victimologists’: -0.4, ‘victimology’: 0.3, ‘victims’: -1.3, ‘vigilant’: 0.7, ‘vigor’: 1.1, ‘vigorish’: -0.4, ‘vigorishes’: 0.4, ‘vigoroso’: 1.5, ‘vigorously’: 0.5, ‘vigorousness’: 0.4, ‘vigors’: 1.0, ‘vigour’: 0.9, ‘vigours’: 0.4, ‘vile’: -3.1, ‘villain’: -2.6, ‘villainess’: -2.9, ‘villainesses’: -2.0, ‘villainies’: -2.3, ‘villainous’: -2.0, ‘villainously’: -2.9, ‘villainousness’: -2.7, ‘villains’: -3.4, ‘villainy’: -2.6, ‘vindicate’: 0.3, ‘vindicated’: 1.8, ‘vindicates’: 1.6, ‘vindicating’: -1.1, ‘violate’: -2.2, ‘violated’: -2.4, ‘violater’: -2.6, ‘violaters’: -2.4, ‘violates’: -2.3, ‘violating’: -2.5, ‘violation’: -2.2, ‘violations’: -2.4, ‘violative’: -2.4, ‘violator’: -2.4, ‘violators’: -1.9, ‘violence’: -3.1, ‘violent’: -2.9, ‘violently’: -2.8, ‘virtue’: 1.8, ‘virtueless’: -1.4, ‘virtues’: 1.5, ‘virtuosa’: 1.7, ‘virtuosas’: 1.8, ‘virtuose’: 1.0, ‘virtuosi’: 0.9, ‘virtuosic’: 2.2, ‘virtuosity’: 2.1, ‘virtuoso’: 2.0, ‘virtuosos’: 1.8, ‘virtuous’: 2.4, ‘virtuously’: 1.8, ‘virtuousness’: 2.0, ‘virulent’: -2.7, ‘vision’: 1.0, ‘visionary’: 2.4, ‘visioning’: 1.1, ‘visions’: 0.9, ‘vital’: 1.2, ‘vitalise’: 1.1, ‘vitalised’: 0.6, ‘vitalises’: 1.1, ‘vitalising’: 2.1, ‘vitalism’: 0.2, ‘vitalist’: 0.3, ‘vitalists’: 0.3, ‘vitalities’: 1.2, ‘vitality’: 1.3, ‘vitalization’: 1.6, ‘vitalizations’: 0.8, ‘vitalize’: 1.6, ‘vitalized’: 1.5, ‘vitalizes’: 1.4, ‘vitalizing’: 1.3, ‘vitally’: 1.1, ‘vitals’: 1.1, ‘vitamin’: 1.2, ‘vitriolic’: -2.1, ‘vivacious’: 1.8, ‘vociferous’: -0.8, ‘vulnerabilities’: -0.6, ‘vulnerability’: -0.9, ‘vulnerable’: -0.9, ‘vulnerableness’: -1.1, ‘vulnerably’: -1.2, ‘vulture’: -2.0, ‘vultures’: -1.3, ‘w00t’: 2.2, ‘walkout’: -1.3, ‘walkouts’: -0.7, ‘wanker’: -2.5, ‘want’: 0.3, ‘war’: -2.9, ‘warfare’: -1.2, ‘warfares’: -1.8, ‘warm’: 0.9, ‘warmblooded’: 0.2, ‘warmed’: 1.1, ‘warmer’: 1.2, ‘warmers’: 1.0, ‘warmest’: 1.7, ‘warmhearted’: 1.8, ‘warmheartedness’: 2.7, ‘warming’: 0.6, ‘warmish’: 1.4, ‘warmly’: 1.7, ‘warmness’: 1.5, ‘warmonger’: -2.9, ‘warmongering’: -2.5, ‘warmongers’: -2.8, ‘warmouth’: 0.4, ‘warmouths’: -0.8, ‘warms’: 1.1, ‘warmth’: 2.0, ‘warmup’: 0.4, ‘warmups’: 0.8, ‘warn’: -0.4, ‘warned’: -1.1, ‘warning’: -1.4, ‘warnings’: -1.2, ‘warns’: -0.4, ‘warred’: -2.4, ‘warring’: -1.9, ‘wars’: -2.6, ‘warsaw’: -0.1, ‘warsaws’: -0.2, ‘warship’: -0.7, ‘warships’: -0.5, ‘warstle’: 0.1, ‘waste’: -1.8, ‘wasted’: -2.2, ‘wasting’: -1.7, ‘wavering’: -0.6, ‘weak’: -1.9, ‘weaken’: -1.8, ‘weakened’: -1.3, ‘weakener’: -1.6, ‘weakeners’: -1.3, ‘weakening’: -1.3, ‘weakens’: -1.3, ‘weaker’: -1.9, ‘weakest’: -2.3, ‘weakfish’: -0.2, ‘weakfishes’: -0.6, ‘weakhearted’: -1.6, ‘weakish’: -1.2, ‘weaklier’: -1.5, ‘weakliest’: -2.1, ‘weakling’: -1.3, ‘weaklings’: -1.4, ‘weakly’: -1.8, ‘weakness’: -1.8, ‘weaknesses’: -1.5, ‘weakside’: -1.1, ‘wealth’: 2.2, ‘wealthier’: 2.2, ‘wealthiest’: 2.2, ‘wealthily’: 2.0, ‘wealthiness’: 2.4, ‘wealthy’: 1.5, ‘weapon’: -1.2, ‘weaponed’: -1.4, ‘weaponless’: 0.1, ‘weaponry’: -0.9, ‘weapons’: -1.9, ‘weary’: -1.1, ‘weep’: -2.7, ‘weeper’: -1.9, ‘weepers’: -1.1, ‘weepie’: -0.4, ‘weepier’: -1.8, ‘weepies’: -1.6, ‘weepiest’: -2.4, ‘weeping’: -1.9, ‘weepings’: -1.9, ‘weeps’: -1.4, ‘weepy’: -1.3, ‘weird’: -0.7, ‘weirder’: -0.5, ‘weirdest’: -0.9, ‘weirdie’: -1.3, ‘weirdies’: -1.0, ‘weirdly’: -1.2, ‘weirdness’: -0.9, ‘weirdnesses’: -0.7, ‘weirdo’: -1.8, ‘weirdoes’: -1.3, ‘weirdos’: -1.1, ‘weirds’: -0.6, ‘weirdy’: -0.9, ‘welcome’: 2.0, ‘welcomed’: 1.4, ‘welcomely’: 1.9, ‘welcomeness’: 2.0, ‘welcomer’: 1.4, ‘welcomers’: 1.9, ‘welcomes’: 1.7, ‘welcoming’: 1.9, ‘well’: 1.1, ‘welladay’: 0.3, ‘wellaway’: -0.8, ‘wellborn’: 1.8, ‘welldoer’: 2.5, ‘welldoers’: 1.6, ‘welled’: 0.4, ‘wellhead’: 0.1, ‘wellheads’: 0.5, ‘wellhole’: -0.1, ‘wellies’: 0.4, ‘welling’: 1.6, ‘wellness’: 1.9, ‘wells’: 1.0, ‘wellsite’: 0.5, ‘wellspring’: 1.5, ‘wellsprings’: 1.4, ‘welly’: 0.2, ‘wept’: -2.0, ‘whimsical’: 0.3, ‘whine’: -1.5, ‘whined’: -0.9, ‘whiner’: -1.2, ‘whiners’: -0.6, ‘whines’: -1.8, ‘whiney’: -1.3, ‘whining’: -0.9, ‘whitewash’: 0.1, ‘whore’: -3.3, ‘whored’: -2.8, ‘whoredom’: -2.1, ‘whoredoms’: -2.4, ‘whorehouse’: -1.1, ‘whorehouses’: -1.9, ‘whoremaster’: -1.9, ‘whoremasters’: -1.5, ‘whoremonger’: -2.6, ‘whoremongers’: -2.0, ‘whores’: -3.0, ‘whoreson’: -2.2, ‘whoresons’: -2.5, ‘wicked’: -2.4, ‘wickeder’: -2.2, ‘wickedest’: -2.9, ‘wickedly’: -2.1, ‘wickedness’: -2.1, ‘wickednesses’: -2.2, ‘widowed’: -2.1, ‘willingness’: 1.1, ‘wimp’: -1.4, ‘wimpier’: -1.0, ‘wimpiest’: -0.9, ‘wimpiness’: -1.2, ‘wimpish’: -1.6, ‘wimpishness’: -0.2, ‘wimple’: -0.2, ‘wimples’: -0.3, ‘wimps’: -1.0, ‘wimpy’: -0.9, ‘win’: 2.8, ‘winnable’: 1.8, ‘winned’: 1.8, ‘winner’: 2.8, ‘winners’: 2.1, ‘winning’: 2.4, ‘winningly’: 2.3, ‘winnings’: 2.5, ‘winnow’: -0.3, ‘winnower’: -0.1, ‘winnowers’: -0.2, ‘winnowing’: -0.1, ‘winnows’: -0.2, ‘wins’: 2.7, ‘wisdom’: 2.4, ‘wise’: 2.1, ‘wiseacre’: -1.2, ‘wiseacres’: -0.1, ‘wiseass’: -1.8, ‘wiseasses’: -1.5, ‘wisecrack’: -0.1, ‘wisecracked’: -0.5, ‘wisecracker’: -0.1, ‘wisecrackers’: 0.1, ‘wisecracking’: -0.6, ‘wisecracks’: -0.3, ‘wised’: 1.5, ‘wiseguys’: 0.3, ‘wiselier’: 0.9, ‘wiseliest’: 1.6, ‘wisely’: 1.8, ‘wiseness’: 1.9, ‘wisenheimer’: -1.0, ‘wisenheimers’: -1.4, ‘wisents’: 0.4, ‘wiser’: 1.2, ‘wises’: 1.3, ‘wisest’: 2.1, ‘wisewomen’: 1.3, ‘wish’: 1.7, ‘wishes’: 0.6, ‘wishing’: 0.9, ‘witch’: -1.5, ‘withdrawal’: 0.1, ‘woe’: -1.8, ‘woebegone’: -2.6, ‘woebegoneness’: -1.1, ‘woeful’: -1.9, ‘woefully’: -1.7, ‘woefulness’: -2.1, ‘woes’: -1.9, ‘woesome’: -1.2, ‘won’: 2.7, ‘wonderful’: 2.7, ‘wonderfully’: 2.9, ‘wonderfulness’: 2.9, ‘woo’: 2.1, ‘woohoo’: 2.3, ‘woot’: 1.8, ‘worn’: -1.2, ‘worried’: -1.2, ‘worriedly’: -2.0, ‘worrier’: -1.8, ‘worriers’: -1.7, ‘worries’: -1.8, ‘worriment’: -1.5, ‘worriments’: -1.9, ‘worrisome’: -1.7, ‘worrisomely’: -2.0, ‘worrisomeness’: -1.9, ‘worrit’: -2.1, ‘worrits’: -1.2, ‘worry’: -1.9, ‘worrying’: -1.4, ‘worrywart’: -1.8, ‘worrywarts’: -1.5, ‘worse’: -2.1, ‘worsen’: -2.3, ‘worsened’: -1.9, ‘worsening’: -2.0, ‘worsens’: -2.1, ‘worser’: -2.0, ‘worship’: 1.2, ‘worshiped’: 2.4, ‘worshiper’: 1.0, ‘worshipers’: 0.9, ‘worshipful’: 0.7, ‘worshipfully’: 1.1, ‘worshipfulness’: 1.6, ‘worshiping’: 1.0, ‘worshipless’: -0.6, ‘worshipped’: 2.7, ‘worshipper’: 0.6, ‘worshippers’: 0.8, ‘worshipping’: 1.6, ‘worships’: 1.4, ‘worst’: -3.1, ‘worth’: 0.9, ‘worthless’: -1.9, ‘worthwhile’: 1.4, ‘worthy’: 1.9, ‘wow’: 2.8, ‘wowed’: 2.6, ‘wowing’: 2.5, ‘wows’: 2.0, ‘wowser’: -1.1, ‘wowsers’: 1.0, ‘wrathful’: -2.7, ‘wreck’: -1.9, ‘wrong’: -2.1, ‘wronged’: -1.9, ‘yay’: 2.4, ‘yeah’: 1.2, ‘yearning’: 0.5, ‘yeees’: 1.7, ‘yep’: 1.2, ‘yes’: 1.7, ‘youthful’: 1.3, ‘yucky’: -1.8, ‘yummy’: 2.4, ‘zealot’: -1.9, ‘zealots’: -0.8, ‘zealous’: 0.5, ‘{:’: 1.8, ‘|-0’: -1.2, ‘|-:’: -0.8, ‘|-:&gt;’: -1.6, ‘|-o’: -1.2, ‘|:’: -0.5, ‘|;-)’: 2.2, ‘|=’: -0.4, ‘|^:’: -1.1, ‘|o:’: -0.9, ‘||-:’: -2.3, ‘}:’: -2.1, ‘}:(’: -2.0, ‘}:)’: 0.4, ‘}:-(’: -2.1, ‘}:-)’: 0.3} Only three N-Gram in the lexicon [ (tok,score) for tok, score in vadersa.lexicon.items() if &quot; &quot; in tok] [(“( ‘}{’ )”, 1.6), (“can’t stand”, -2.0), (‘fed up’, -1.8), (‘screwed up’, -1.5)] If stemming or lemmatization is used, stem/lemmatize the vader lexicon too [ (tok,score) for tok, score in vadersa.lexicon.items() if &quot;lov&quot; in tok] [(‘beloved’, 2.3), (‘lovable’, 3.0), (‘love’, 3.2), (‘loved’, 2.9), (‘lovelies’, 2.2), (‘lovely’, 2.8), (‘lover’, 2.8), (‘loverly’, 2.8), (‘lovers’, 2.4), (‘loves’, 2.7), (‘loving’, 2.9), (‘lovingly’, 3.2), (‘lovingness’, 2.7), (‘unlovable’, -2.7), (‘unloved’, -1.9), (‘unlovelier’, -1.9), (‘unloveliest’, -1.9), (‘unloveliness’, -2.0), (‘unlovely’, -2.1), (‘unloving’, -2.3)] 18.7.1.2 Polarity Scoring Scoring result is a dictionary of: neg neu pos compound neg, neu, pos adds up to 1.0 corpus = [&quot;Python is a very useful but hell difficult to learn&quot;, &quot;:) :) :(&quot;] for doc in corpus: print(doc, &quot;--&gt;&quot;, vadersa.polarity_scores(doc) ) Python is a very useful but hell difficult to learn –&gt; {‘neg’: 0.554, ‘neu’: 0.331, ‘pos’: 0.116, ‘compound’: -0.8735} :) :) :( –&gt; {‘neg’: 0.326, ‘neu’: 0.0, ‘pos’: 0.674, ‘compound’: 0.4767} 18.8 Naive Bayes 18.8.1 Libraries from nlpia.data.loaders import get_data INFO:nlpia.constants:Starting logger in nlpia.constants… INFO:nlpia.loaders:No BIGDATA index found in C:3-packages_info.csv so copy C:3-packages_info.latest.csv to C:3-packages_info.csv if you want to “freeze” it. INFO:nlpia.futil:Reading CSV with read_csv(*('C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\nlpia\\\\data\\\\mavis-batey-greetings.csv',), **{'low_memory': False})… INFO:nlpia.futil:Reading CSV with read_csv(*('C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\nlpia\\\\data\\\\sms-spam.csv',), **{'low_memory': False})… from nltk.tokenize.casual import casual_tokenize from collections import Counter 18.8.2 The Data movies = get_data(&#39;hutto_movies&#39;) # download data INFO:nlpia.futil:Reading CSV with read_csv(*('C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\nlpia\\\\data\\\\hutto_ICWSM_2014/movieReviewSnippets_GroundTruth.csv.gz',), **{'nrows': None, 'low_memory': False})… print(movies.head(), &#39;\\n\\n&#39;, movies.describe()) sentiment text id 1 2.266667 The Rock is destined to be the 21st Century’s … 2 3.533333 The gorgeously elaborate continuation of ’’The… 3 -0.600000 Effective but too tepid biopic 4 1.466667 If you sometimes like to go to the movies to h… 5 1.733333 Emerges as something rare, an issue movie that… sentiment count 10605.000000 mean 0.004831 std 1.922050 min -3.875000 25% -1.769231 50% -0.080000 75% 1.833333 max 3.941176 18.8.3 Bag of Words Tokenize each record, remove single character token, then convert into list of counters (words-frequency pair). Each item in the list is a counter, which represent word frequency within the record bag_of_words = [] for text in movies.text: tokens = casual_tokenize(text, reduce_len=True, strip_handles=True) # tokenize tokens = [x for x in tokens if len(x)&gt;1] ## remove single char token bag_of_words.append( Counter(tokens, strip_handles=True) ## add to our BoW ) unique_words = list( set([ y for x in bag_of_words for y in x.keys()]) ) print(&quot;Total Rows: &quot;, len(bag_of_words),&#39;\\n\\n&#39;, &#39;Row 1 BoW: &#39;,bag_of_words[:1],&#39;\\n\\n&#39;, # see the first two records &#39;Row 2 BoW: &#39;, bag_of_words[:2], &#39;\\n\\n&#39;, &#39;Total Unique Words: &#39;, len(unique_words)) Total Rows: 10605 Row 1 BoW: [Counter({‘to’: 2, ‘The’: 1, ‘Rock’: 1, ‘is’: 1, ‘destined’: 1, ‘be’: 1, ‘the’: 1, ‘21st’: 1, “Century’s”: 1, ‘new’: 1, ‘Conan’: 1, ‘and’: 1, ‘that’: 1, “he’s”: 1, ‘going’: 1, ‘make’: 1, ‘splash’: 1, ‘even’: 1, ‘greater’: 1, ‘than’: 1, ‘Arnold’: 1, ‘Schwarzenegger’: 1, ‘Jean’: 1, ‘Claud’: 1, ‘Van’: 1, ‘Damme’: 1, ‘or’: 1, ‘Steven’: 1, ‘Segal’: 1, ‘strip_handles’: 1})] Row 2 BoW: [Counter({‘to’: 2, ‘The’: 1, ‘Rock’: 1, ‘is’: 1, ‘destined’: 1, ‘be’: 1, ‘the’: 1, ‘21st’: 1, “Century’s”: 1, ‘new’: 1, ‘Conan’: 1, ‘and’: 1, ‘that’: 1, “he’s”: 1, ‘going’: 1, ‘make’: 1, ‘splash’: 1, ‘even’: 1, ‘greater’: 1, ‘than’: 1, ‘Arnold’: 1, ‘Schwarzenegger’: 1, ‘Jean’: 1, ‘Claud’: 1, ‘Van’: 1, ‘Damme’: 1, ‘or’: 1, ‘Steven’: 1, ‘Segal’: 1, ‘strip_handles’: 1}), Counter({‘of’: 4, ‘The’: 2, ‘gorgeously’: 1, ‘elaborate’: 1, ‘continuation’: 1, ‘Lord’: 1, ‘the’: 1, ‘Rings’: 1, ‘trilogy’: 1, ‘is’: 1, ‘so’: 1, ‘huge’: 1, ‘that’: 1, ‘column’: 1, ‘words’: 1, ‘cannot’: 1, ‘adequately’: 1, ‘describe’: 1, ‘co’: 1, ‘writer’: 1, ‘director’: 1, ‘Peter’: 1, “Jackson’s”: 1, ‘expanded’: 1, ‘vision’: 1, “Tolkien’s”: 1, ‘Middle’: 1, ‘earth’: 1, ‘strip_handles’: 1})] Total Unique Words: 20686 Convert NaN into 0 then all features into integer bows_df = pd.DataFrame.from_records(bag_of_words) bows_df = bows_df.fillna(0).astype(int) # replace NaN with 0, change to integer bows_df.head() . … .. … 007 1.2 … zombies zone zoning zzz élan 0 0 0 0 0 0 … 0 0 0 0 0 1 0 0 0 0 0 … 0 0 0 0 0 2 0 0 0 0 0 … 0 0 0 0 0 3 0 0 0 0 0 … 0 0 0 0 0 4 0 0 0 0 0 … 0 0 0 0 0 [5 rows x 20686 columns] 18.8.4 Build The Model from sklearn.naive_bayes import MultinomialNB train_y = movies.sentiment&gt;0 # label train_X = bows_df # features nb_model = MultinomialNB().fit( train_X, train_y) 18.8.5 Train Set Prediction First, make a prediction on training data, then compare to ground truth. train_predicted = nb_model.predict(bows_df) print(&quot;Accuracy: &quot;, np.mean(train_predicted==train_y).round(4)) Accuracy: 0.9357 "]
]
